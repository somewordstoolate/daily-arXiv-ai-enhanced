{"id": "2505.13480", "pdf": "https://arxiv.org/pdf/2505.13480", "abs": "https://arxiv.org/abs/2505.13480", "authors": ["Avinash Patil", "Siru Tao", "Amardeep Gedhu"], "title": "Evaluating Reasoning LLMs for Suicide Screening with the Columbia-Suicide Severity Rating Scale", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.LG"], "comment": "8 Pages, 6 Figures, 1 Table", "summary": "Suicide prevention remains a critical public health challenge. While online\nplatforms such as Reddit's r/SuicideWatch have historically provided spaces for\nindividuals to express suicidal thoughts and seek community support, the advent\nof large language models (LLMs) introduces a new paradigm-where individuals may\nbegin disclosing ideation to AI systems instead of humans. This study evaluates\nthe capability of LLMs to perform automated suicide risk assessment using the\nColumbia-Suicide Severity Rating Scale (C-SSRS). We assess the zero-shot\nperformance of six models-including Claude, GPT, Mistral, and LLaMA-in\nclassifying posts across a 7-point severity scale (Levels 0-6). Results\nindicate that Claude and GPT closely align with human annotations, while\nMistral achieves the lowest ordinal prediction error. Most models exhibit\nordinal sensitivity, with misclassifications typically occurring between\nadjacent severity levels. We further analyze confusion patterns,\nmisclassification sources, and ethical considerations, underscoring the\nimportance of human oversight, transparency, and cautious deployment. Full code\nand supplementary materials are available at\nhttps://github.com/av9ash/llm_cssrs_code.", "AI": {"content": "```json\n{\n  \"tldr\": \"\u8be5\u7814\u7a76\u8bc4\u4f30\u4e866\u79cd\u5927\u8bed\u8a00\u6a21\u578b\u5728\u81ea\u6740\u98ce\u9669\u8bc4\u4f30\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0Claude\u548cGPT\u6700\u63a5\u8fd1\u4eba\u7c7b\u6807\u6ce8\u7ed3\u679c\uff0c\u540c\u65f6\u5f3a\u8c03\u4e86\u4eba\u5de5\u76d1\u7763\u548c\u4f26\u7406\u95ee\u9898\u7684\u91cd\u8981\u6027\u3002\",\n  \"motivation\": \"\u968f\u7740\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u666e\u53ca\uff0c\u4eba\u4eec\u53ef\u80fd\u5411AI\u800c\u975e\u4eba\u7c7b\u8868\u9732\u81ea\u6740\u503e\u5411\uff0c\u7814\u7a76\u65e8\u5728\u8bc4\u4f30AI\u6a21\u578b\u4f7f\u7528\u54e5\u4f26\u6bd4\u4e9a\u81ea\u6740\u4e25\u91cd\u7a0b\u5ea6\u8bc4\u5b9a\u91cf\u8868\u8fdb\u884c\u81ea\u52a8\u98ce\u9669\u8bc4\u4f30\u7684\u80fd\u529b\u3002\",\n  \"method\": \"\u4f7f\u7528\u96f6\u6837\u672c\u5b66\u4e60\u65b9\u6cd5\u6d4b\u8bd56\u4e2a\u6a21\u578b\uff08Claude\u3001GPT\u3001Mistral\u548cLLaMA\u7b49\uff09\u5bf97\u7ea7\u81ea\u6740\u4e25\u91cd\u7a0b\u5ea6\u5e16\u5b50\u7684\u5206\u7c7b\u80fd\u529b\u3002\",\n  \"result\": \"Claude\u548cGPT\u4e0e\u4eba\u7c7b\u6807\u6ce8\u7ed3\u679c\u6700\u4e3a\u63a5\u8fd1\uff0cMistral\u7684\u5e8f\u6570\u9884\u6d4b\u8bef\u5dee\u6700\u4f4e\uff0c\u591a\u6570\u6a21\u578b\u7684\u9519\u8bef\u5206\u7c7b\u96c6\u4e2d\u5728\u76f8\u90bb\u4e25\u91cd\u7b49\u7ea7\u4e4b\u95f4\u3002\",\n  \"conclusion\": \"AI\u6a21\u578b\u5728\u81ea\u6740\u98ce\u9669\u8bc4\u4f30\u4e2d\u5c55\u73b0\u51fa\u6f5c\u529b\uff0c\u4f46\u9700\u8981\u4eba\u5de5\u76d1\u7763\u3001\u900f\u660e\u5ea6\u548c\u8c28\u614e\u90e8\u7f72\u6765\u786e\u4fdd\u5e94\u7528\u5b89\u5168\u6027\u3002\"\n}\n```", "additional_kwargs": {"refusal": null}, "response_metadata": {"token_usage": {"completion_tokens": 201, "prompt_tokens": 573, "total_tokens": 774, "completion_tokens_details": null, "prompt_tokens_details": null}, "model_name": "deepseek/deepseek-chat-v3-0324:free", "system_fingerprint": null, "id": "gen-1747817461-FSrx1ulUd0OawFxAAX8n", "finish_reason": "stop", "logprobs": null}, "type": "ai", "name": null, "id": "run-9286cea7-6660-4604-89d3-9ebd0d1eeb5b-0", "example": false, "tool_calls": [], "invalid_tool_calls": [], "usage_metadata": {"input_tokens": 573, "output_tokens": 201, "total_tokens": 774, "input_token_details": {}, "output_token_details": {}}}}
{"id": "2505.13483", "pdf": "https://arxiv.org/pdf/2505.13483", "abs": "https://arxiv.org/abs/2505.13483", "authors": ["Xingyuan Lu", "Yuxi Liu", "Dongyu Zhang", "Zhiyao Wu", "Jing Ren", "Feng Xia"], "title": "EmoMeta: A Multimodal Dataset for Fine-grained Emotion Classification in Chinese Metaphors", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Metaphors play a pivotal role in expressing emotions, making them crucial for\nemotional intelligence. The advent of multimodal data and widespread\ncommunication has led to a proliferation of multimodal metaphors, amplifying\nthe complexity of emotion classification compared to single-mode scenarios.\nHowever, the scarcity of research on constructing multimodal metaphorical\nfine-grained emotion datasets hampers progress in this domain. Moreover,\nexisting studies predominantly focus on English, overlooking potential\nvariations in emotional nuances across languages. To address these gaps, we\nintroduce a multimodal dataset in Chinese comprising 5,000 text-image pairs of\nmetaphorical advertisements. Each entry is meticulously annotated for metaphor\noccurrence, domain relations and fine-grained emotion classification\nencompassing joy, love, trust, fear, sadness, disgust, anger, surprise,\nanticipation, and neutral. Our dataset is publicly accessible\n(https://github.com/DUTIR-YSQ/EmoMeta), facilitating further advancements in\nthis burgeoning field.", "AI": {"content": "```json\n{\n  \"tldr\": \"\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4e2d\u6587\u591a\u6a21\u6001\u9690\u55bb\u5e7f\u544a\u6570\u636e\u96c6\uff0c\u7528\u4e8e\u7ec6\u7c92\u5ea6\u60c5\u611f\u5206\u7c7b\uff0c\u586b\u8865\u4e86\u8be5\u9886\u57df\u7684\u7814\u7a76\u7a7a\u767d\u3002\",\n  \"motivation\": \"\u5f53\u524d\u591a\u6a21\u6001\u9690\u55bb\u60c5\u611f\u5206\u7c7b\u7814\u7a76\u4e0d\u8db3\uff0c\u4e14\u4e3b\u8981\u96c6\u4e2d\u5728\u82f1\u8bed\uff0c\u7f3a\u4e4f\u4e2d\u6587\u76f8\u5173\u7814\u7a76\uff0c\u56e0\u6b64\u9700\u8981\u6784\u5efa\u4e00\u4e2a\u7ec6\u7c92\u5ea6\u7684\u4e2d\u6587\u591a\u6a21\u6001\u9690\u55bb\u60c5\u611f\u6570\u636e\u96c6\u3002\",\n  \"method\": \"\u6784\u5efa\u4e86\u4e00\u4e2a\u5305\u542b5000\u4e2a\u6587\u672c-\u56fe\u50cf\u5bf9\u7684\u4e2d\u6587\u591a\u6a21\u6001\u9690\u55bb\u5e7f\u544a\u6570\u636e\u96c6\uff0c\u6bcf\u4e2a\u6837\u672c\u6807\u6ce8\u4e86\u9690\u55bb\u51fa\u73b0\u3001\u9886\u57df\u5173\u7cfb\u548c\u7ec6\u7c92\u5ea6\u60c5\u611f\u5206\u7c7b\u3002\",\n  \"result\": \"\u6570\u636e\u96c6\u516c\u5f00\u53ef\u7528\uff0c\u652f\u6301\u5305\u62ec\u559c\u60a6\u3001\u7231\u3001\u4fe1\u4efb\u3001\u6050\u60e7\u3001\u60b2\u4f24\u3001\u538c\u6076\u3001\u6124\u6012\u3001\u60ca\u8bb6\u3001\u671f\u5f85\u548c\u4e2d\u6027\u5728\u5185\u768410\u79cd\u60c5\u611f\u5206\u7c7b\u3002\",\n  \"conclusion\": \"\u8be5\u6570\u636e\u96c6\u7684\u53d1\u5e03\u5c06\u4fc3\u8fdb\u591a\u6a21\u6001\u9690\u55bb\u60c5\u611f\u5206\u7c7b\u9886\u57df\u7684\u7814\u7a76\uff0c\u5c24\u5176\u662f\u5728\u4e2d\u6587\u8bed\u5883\u4e0b\u7684\u5e94\u7528\u3002\"\n}\n```", "additional_kwargs": {"refusal": null}, "response_metadata": {"token_usage": {"completion_tokens": 180, "prompt_tokens": 516, "total_tokens": 696, "completion_tokens_details": null, "prompt_tokens_details": null}, "model_name": "deepseek/deepseek-chat-v3-0324:free", "system_fingerprint": null, "id": "gen-1747817467-VVluGCJUW6LtE17I2IT4", "finish_reason": "stop", "logprobs": null}, "type": "ai", "name": null, "id": "run-86f21c20-0b41-438c-9944-f1aea250f287-0", "example": false, "tool_calls": [], "invalid_tool_calls": [], "usage_metadata": {"input_tokens": 516, "output_tokens": 180, "total_tokens": 696, "input_token_details": {}, "output_token_details": {}}}}
{"id": "2505.13487", "pdf": "https://arxiv.org/pdf/2505.13487", "abs": "https://arxiv.org/abs/2505.13487", "authors": ["Ashwin Kumar", "Yuzi He", "Aram H. Markosyan", "Bobbie Chern", "Imanol Arrieta-Ibarra"], "title": "Detecting Prefix Bias in LLM-based Reward Models", "categories": ["cs.CL"], "comment": null, "summary": "Reinforcement Learning with Human Feedback (RLHF) has emerged as a key\nparadigm for task-specific fine-tuning of language models using human\npreference data. While numerous publicly available preference datasets provide\npairwise comparisons of responses, the potential for biases in the resulting\nreward models remains underexplored. In this work, we introduce novel methods\nto detect and evaluate prefix bias -- a systematic shift in model preferences\ntriggered by minor variations in query prefixes -- in LLM-based reward models\ntrained on such datasets. We leverage these metrics to reveal significant\nbiases in preference models across racial and gender dimensions. Our\ncomprehensive evaluation spans diverse open-source preference datasets and\nreward model architectures, demonstrating susceptibility to this kind of bias\nregardless of the underlying model architecture. Furthermore, we propose a data\naugmentation strategy to mitigate these biases, showing its effectiveness in\nreducing the impact of prefix bias. Our findings highlight the critical need\nfor bias-aware dataset design and evaluation in developing fair and reliable\nreward models, contributing to the broader discourse on fairness in AI.", "AI": {"content": "23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n23:23:23\n", "additional_kwargs": {"refusal": null}, "response_metadata": {"token_usage": {"completion_tokens": 3251, "prompt_tokens": 542, "total_tokens": 3793, "completion_tokens_details": null, "prompt_tokens_details": null}, "model_name": "deepseek/deepseek-chat-v3-0324:free", "system_fingerprint": null, "id": "gen-1747817486-hrQqN0OHQ9nuyYQMiFe5", "finish_reason": null, "logprobs": null}, "type": "ai", "name": null, "id": "run-8f4f2337-7cba-47f6-af49-dee4c10498ba-0", "example": false, "tool_calls": [], "invalid_tool_calls": [], "usage_metadata": {"input_tokens": 542, "output_tokens": 3251, "total_tokens": 3793, "input_token_details": {}, "output_token_details": {}}}}
{"id": "2505.13488", "pdf": "https://arxiv.org/pdf/2505.13488", "abs": "https://arxiv.org/abs/2505.13488", "authors": ["Federico Germani", "Giovanni Spitale"], "title": "Source framing triggers systematic evaluation bias in Large Language Models", "categories": ["cs.CL", "cs.CY"], "comment": null, "summary": "Large Language Models (LLMs) are increasingly used not only to generate text\nbut also to evaluate it, raising urgent questions about whether their judgments\nare consistent, unbiased, and robust to framing effects. In this study, we\nsystematically examine inter- and intra-model agreement across four\nstate-of-the-art LLMs (OpenAI o3-mini, Deepseek Reasoner, xAI Grok 2, and\nMistral) tasked with evaluating 4,800 narrative statements on 24 different\ntopics of social, political, and public health relevance, for a total of\n192,000 assessments. We manipulate the disclosed source of each statement to\nassess how attribution to either another LLM or a human author of specified\nnationality affects evaluation outcomes. We find that, in the blind condition,\ndifferent LLMs display a remarkably high degree of inter- and intra-model\nagreement across topics. However, this alignment breaks down when source\nframing is introduced. Here we show that attributing statements to Chinese\nindividuals systematically lowers agreement scores across all models, and in\nparticular for Deepseek Reasoner. Our findings reveal that framing effects can\ndeeply affect text evaluation, with significant implications for the integrity,\nneutrality, and fairness of LLM-mediated information systems.", "AI": {"content": "```json\n{\n  \"tldr\": \"\u8be5\u7814\u7a76\u63a2\u8ba8\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u8bc4\u4f30\u6587\u672c\u65f6\u7684\u4e00\u81f4\u6027\u548c\u504f\u89c1\u95ee\u9898\uff0c\u53d1\u73b0\u6a21\u578b\u5728\u533f\u540d\u6761\u4ef6\u4e0b\u9ad8\u5ea6\u4e00\u81f4\uff0c\u4f46\u5728\u5f15\u5165\u6765\u6e90\u6846\u67b6\u540e\uff0c\u7279\u522b\u662f\u6d89\u53ca\u4e2d\u56fd\u4e2a\u4f53\u65f6\uff0c\u4e00\u81f4\u6027\u663e\u8457\u4e0b\u964d\u3002\",\n  \"motivation\": \"\u7814\u7a76\u52a8\u673a\u662f\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u6587\u672c\u8bc4\u4f30\u4e2d\u7684\u4e00\u81f4\u6027\u3001\u504f\u89c1\u548c\u6846\u67b6\u6548\u5e94\uff0c\u4ee5\u786e\u4fdd\u5176\u5728\u4e2d\u7acb\u548c\u516c\u5e73\u6027\u65b9\u9762\u7684\u8868\u73b0\u3002\",\n  \"method\": \"\u7814\u7a76\u901a\u8fc7\u56db\u4e2a\u5148\u8fdb\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8bc4\u4f30\u4e864,800\u6761\u53d9\u8ff0\u6027\u58f0\u660e\uff0c\u5e76\u64cd\u7eb5\u4e86\u6bcf\u6761\u58f0\u660e\u7684\u6765\u6e90\uff0c\u4ee5\u5206\u6790\u6846\u67b6\u6548\u5e94\u5bf9\u8bc4\u4f30\u7ed3\u679c\u7684\u5f71\u54cd\u3002\",\n  \"result\": \"\u7ed3\u679c\u663e\u793a\uff0c\u5728\u533f\u540d\u6761\u4ef6\u4e0b\uff0c\u6a21\u578b\u95f4\u548c\u6a21\u578b\u5185\u9ad8\u5ea6\u4e00\u81f4\uff1b\u4f46\u5f53\u58f0\u660e\u88ab\u6807\u8bb0\u4e3a\u4e2d\u56fd\u4e2a\u4f53\u65f6\uff0c\u6240\u6709\u6a21\u578b\u7684\u4e00\u81f4\u6027\u8bc4\u5206\u5747\u4e0b\u964d\uff0c\u5c24\u5176\u662fDeepseek Reasoner\u3002\",\n  \"conclusion\": \"\u7814\u7a76\u7ed3\u8bba\u6307\u51fa\uff0c\u6846\u67b6\u6548\u5e94\u4f1a\u663e\u8457\u5f71\u54cd\u6587\u672c\u8bc4\u4f30\uff0c\u8fd9\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u4fe1\u606f\u5904\u7406\u4e2d\u7684\u4e2d\u7acb\u6027\u548c\u516c\u5e73\u6027\u63d0\u51fa\u4e86\u91cd\u8981\u6311\u6218\u3002\"\n}\n```", "additional_kwargs": {"refusal": null}, "response_metadata": {"token_usage": {"completion_tokens": 207, "prompt_tokens": 585, "total_tokens": 792, "completion_tokens_details": null, "prompt_tokens_details": null}, "model_name": "deepseek/deepseek-chat-v3-0324:free", "system_fingerprint": null, "id": "gen-1747817606-x87phbgL9I6yCzeNfHjf", "finish_reason": "stop", "logprobs": null}, "type": "ai", "name": null, "id": "run-e5222bad-9503-4d19-81d9-d48f2d02391c-0", "example": false, "tool_calls": [], "invalid_tool_calls": [], "usage_metadata": {"input_tokens": 585, "output_tokens": 207, "total_tokens": 792, "input_token_details": {}, "output_token_details": {}}}}
{"id": "2505.13466", "pdf": "https://arxiv.org/pdf/2505.13466", "abs": "https://arxiv.org/abs/2505.13466", "authors": ["Vu Dinh Xuan", "Hao Vo", "David Murphy", "Hoang D. Nguyen"], "title": "AgentSGEN: Multi-Agent LLM in the Loop for Semantic Collaboration and GENeration of Synthetic Data", "categories": ["cs.AI"], "comment": null, "summary": "The scarcity of data depicting dangerous situations presents a major obstacle\nto training AI systems for safety-critical applications, such as construction\nsafety, where ethical and logistical barriers hinder real-world data\ncollection. This creates an urgent need for an end-to-end framework to generate\nsynthetic data that can bridge this gap. While existing methods can produce\nsynthetic scenes, they often lack the semantic depth required for scene\nsimulations, limiting their effectiveness. To address this, we propose a novel\nmulti-agent framework that employs an iterative, in-the-loop collaboration\nbetween two agents: an Evaluator Agent, acting as an LLM-based judge to enforce\nsemantic consistency and safety-specific constraints, and an Editor Agent,\nwhich generates and refines scenes based on this guidance. Powered by LLM's\ncapabilities to reasoning and common-sense knowledge, this collaborative design\nproduces synthetic images tailored to safety-critical scenarios. Our\nexperiments suggest this design can generate useful scenes based on realistic\nspecifications that address the shortcomings of prior approaches, balancing\nsafety requirements with visual semantics. This iterative process holds promise\nfor delivering robust, aesthetically sound simulations, offering a potential\nsolution to the data scarcity challenge in multimedia safety applications.", "AI": {"content": "```json\n{\n  \"tldr\": \"\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u901a\u8fc7LLM\u9a71\u52a8\u7684\u8bc4\u4f30\u4e0e\u7f16\u8f91\u4ee3\u7406\u534f\u4f5c\u751f\u6210\u5b89\u5168\u5173\u952e\u573a\u666f\u7684\u5408\u6210\u6570\u636e\uff0c\u89e3\u51b3\u6570\u636e\u7a00\u7f3a\u95ee\u9898\u3002\",\n  \"motivation\": \"\u5b89\u5168\u5173\u952e\u5e94\u7528\uff08\u5982\u5efa\u7b51\u65bd\u5de5\uff09\u4e2d\uff0c\u771f\u5b9e\u5371\u9669\u573a\u666f\u6570\u636e\u96be\u4ee5\u83b7\u53d6\uff0c\u73b0\u6709\u5408\u6210\u65b9\u6cd5\u7f3a\u4e4f\u8bed\u4e49\u6df1\u5ea6\uff0c\u4e9f\u9700\u65b0\u65b9\u6cd5\u586b\u8865\u6570\u636e\u7a7a\u767d\u3002\",\n  \"method\": \"\u91c7\u7528\u53cc\u4ee3\u7406\u8fed\u4ee3\u6846\u67b6\uff1a\u8bc4\u4f30\u4ee3\u7406\uff08LLM\uff09\u786e\u4fdd\u8bed\u4e49\u4e00\u81f4\u6027\u4e0e\u5b89\u5168\u7ea6\u675f\uff0c\u7f16\u8f91\u4ee3\u7406\u57fa\u4e8e\u53cd\u9988\u751f\u6210/\u4f18\u5316\u573a\u666f\uff0c\u7ed3\u5408\u5e38\u8bc6\u63a8\u7406\u751f\u6210\u5408\u6210\u56fe\u50cf\u3002\",\n  \"result\": \"\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u80fd\u751f\u6210\u7b26\u5408\u5b89\u5168\u8981\u6c42\u4e14\u8bed\u4e49\u5408\u7406\u7684\u5408\u6210\u573a\u666f\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u6709\u6548\u7f13\u89e3\u6570\u636e\u4e0d\u8db3\u95ee\u9898\u3002\",\n  \"conclusion\": \"\u8be5\u8fed\u4ee3\u6846\u67b6\u4e3a\u591a\u5a92\u4f53\u5b89\u5168\u5e94\u7528\u63d0\u4f9b\u53ef\u9760\u7684\u6570\u636e\u5408\u6210\u65b9\u6848\uff0c\u517c\u5177\u9c81\u68d2\u6027\u4e0e\u89c6\u89c9\u5408\u7406\u6027\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u6f5c\u529b\u3002\"\n}\n```", "additional_kwargs": {"refusal": null}, "response_metadata": {"token_usage": {"completion_tokens": 187, "prompt_tokens": 570, "total_tokens": 757, "completion_tokens_details": null, "prompt_tokens_details": null}, "model_name": "deepseek/deepseek-chat-v3-0324:free", "system_fingerprint": null, "id": "gen-1747817614-bSzlqxarbG4kU2mrkYic", "finish_reason": "stop", "logprobs": null}, "type": "ai", "name": null, "id": "run-444bd13d-2c21-476d-8117-50c7a7dea245-0", "example": false, "tool_calls": [], "invalid_tool_calls": [], "usage_metadata": {"input_tokens": 570, "output_tokens": 187, "total_tokens": 757, "input_token_details": {}, "output_token_details": {}}}}
{"id": "2505.13457", "pdf": "https://arxiv.org/pdf/2505.13457", "abs": "https://arxiv.org/abs/2505.13457", "authors": ["Nathan Faraj"], "title": "Tuning Learning Rates with the Cumulative-Learning Constant", "categories": ["cs.LG"], "comment": "9 pages, 13 figures, 2 tables", "summary": "This paper introduces a novel method for optimizing learning rates in machine\nlearning. A previously unrecognized proportionality between learning rates and\ndataset sizes is discovered, providing valuable insights into how dataset scale\ninfluences training dynamics. Additionally, a cumulative learning constant is\nidentified, offering a framework for designing and optimizing advanced learning\nrate schedules. These findings have the potential to enhance training\nefficiency and performance across a wide range of machine learning\napplications.", "AI": {"content": "```json\n{\n  \"tldr\": \"\u672c\u6587\u63d0\u51fa\u4e86\u4f18\u5316\u673a\u5668\u5b66\u4e60\u5b66\u4e60\u7387\u7684\u65b0\u65b9\u6cd5\uff0c\u53d1\u73b0\u5b66\u4e60\u7387\u4e0e\u6570\u636e\u96c6\u5927\u5c0f\u4e4b\u95f4\u7684\u6bd4\u4f8b\u5173\u7cfb\uff0c\u5e76\u63d0\u51fa\u4e86\u7d2f\u79ef\u5b66\u4e60\u5e38\u6570\u7684\u6846\u67b6\uff0c\u4ee5\u63d0\u5347\u8bad\u7ec3\u6548\u7387\u548c\u6027\u80fd\u3002\",\n  \"motivation\": \"\u7814\u7a76\u65e8\u5728\u89e3\u51b3\u673a\u5668\u5b66\u4e60\u4e2d\u5b66\u4e60\u7387\u4f18\u5316\u7684\u95ee\u9898\uff0c\u63a2\u7d22\u6570\u636e\u96c6\u89c4\u6a21\u5982\u4f55\u5f71\u54cd\u8bad\u7ec3\u52a8\u6001\uff0c\u4ece\u800c\u63d0\u9ad8\u8bad\u7ec3\u6548\u7387\u548c\u6a21\u578b\u6027\u80fd\u3002\",\n  \"method\": \"\u901a\u8fc7\u5206\u6790\u5b66\u4e60\u7387\u4e0e\u6570\u636e\u96c6\u5927\u5c0f\u7684\u6bd4\u4f8b\u5173\u7cfb\uff0c\u5e76\u63d0\u51fa\u7d2f\u79ef\u5b66\u4e60\u5e38\u6570\u7684\u6982\u5ff5\uff0c\u8bbe\u8ba1\u4e86\u4e00\u79cd\u65b0\u7684\u5b66\u4e60\u7387\u8c03\u5ea6\u6846\u67b6\u3002\",\n  \"result\": \"\u7814\u7a76\u53d1\u73b0\u5b66\u4e60\u7387\u4e0e\u6570\u636e\u96c6\u5927\u5c0f\u4e4b\u95f4\u5b58\u5728\u6bd4\u4f8b\u5173\u7cfb\uff0c\u5e76\u63d0\u51fa\u4e86\u7d2f\u79ef\u5b66\u4e60\u5e38\u6570\uff0c\u4e3a\u4f18\u5316\u5b66\u4e60\u7387\u8c03\u5ea6\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002\",\n  \"conclusion\": \"\u8fd9\u4e9b\u53d1\u73b0\u4e3a\u673a\u5668\u5b66\u4e60\u4e2d\u7684\u5b66\u4e60\u7387\u4f18\u5316\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u548c\u5b9e\u8df5\u6846\u67b6\uff0c\u6709\u671b\u5e7f\u6cdb\u5e94\u7528\u4e8e\u63d0\u5347\u8bad\u7ec3\u6548\u7387\u548c\u6a21\u578b\u6027\u80fd\u3002\"\n}\n```", "additional_kwargs": {"refusal": null}, "response_metadata": {"token_usage": {"completion_tokens": 170, "prompt_tokens": 413, "total_tokens": 583, "completion_tokens_details": null, "prompt_tokens_details": null}, "model_name": "deepseek/deepseek-chat-v3-0324:free", "system_fingerprint": null, "id": "gen-1747817623-trkQP1OutDnqt0vRg0qj", "finish_reason": "stop", "logprobs": null}, "type": "ai", "name": null, "id": "run-e3658ff7-7164-4180-abe0-130f5c031a89-0", "example": false, "tool_calls": [], "invalid_tool_calls": [], "usage_metadata": {"input_tokens": 413, "output_tokens": 170, "total_tokens": 583, "input_token_details": {}, "output_token_details": {}}}}
{"id": "2505.13491", "pdf": "https://arxiv.org/pdf/2505.13491", "abs": "https://arxiv.org/abs/2505.13491", "authors": ["Aakash Gupta", "Nataraj Das"], "title": "ProdRev: A DNN framework for empowering customers using generative pre-trained transformers", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "2022 International Conference on Decision Aid Sciences and\n  Applications (DASA)", "summary": "Following the pandemic, customers, preference for using e-commerce has\naccelerated. Since much information is available in multiple reviews (sometimes\nrunning in thousands) for a single product, it can create decision paralysis\nfor the buyer. This scenario disempowers the consumer, who cannot be expected\nto go over so many reviews since its time consuming and can confuse them.\nVarious commercial tools are available, that use a scoring mechanism to arrive\nat an adjusted score. It can alert the user to potential review manipulations.\nThis paper proposes a framework that fine-tunes a generative pre-trained\ntransformer to understand these reviews better. Furthermore, using\n\"common-sense\" to make better decisions. These models have more than 13 billion\nparameters. To fine-tune the model for our requirement, we use the curie engine\nfrom generative pre-trained transformer (GPT3). By using generative models, we\nare introducing abstractive summarization. Instead of using a simple extractive\nmethod of summarizing the reviews. This brings out the true relationship\nbetween the reviews and not simply copy-paste. This introduces an element of\n\"common sense\" for the user and helps them to quickly make the right decisions.\nThe user is provided the pros and cons of the processed reviews. Thus the\nuser/customer can take their own decisions.", "AI": {"content": "```json\n{\n  \"tldr\": \"\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528GPT-3\u5fae\u8c03\u7684\u751f\u6210\u5f0f\u9884\u8bad\u7ec3\u6a21\u578b\uff0c\u7528\u4e8e\u62bd\u8c61\u6982\u62ec\u6d77\u91cf\u7535\u5546\u8bc4\u8bba\uff0c\u5e2e\u52a9\u7528\u6237\u5feb\u901f\u51b3\u7b56\u3002\",\n  \"motivation\": \"\u75ab\u60c5\u540e\u7535\u5546\u8bc4\u8bba\u6570\u91cf\u6fc0\u589e\u5bfc\u81f4\u7528\u6237\u51b3\u7b56\u56f0\u96be\uff0c\u73b0\u6709\u8bc4\u5206\u5de5\u5177\u65e0\u6cd5\u6709\u6548\u5904\u7406\u4fe1\u606f\u8fc7\u8f7d\u95ee\u9898\u3002\",\n  \"method\": \"\u4f7f\u7528130\u4ebf\u53c2\u6570\u7684GPT-3\uff08Curie\u5f15\u64ce\uff09\u8fdb\u884c\u5fae\u8c03\uff0c\u91c7\u7528\u62bd\u8c61\u6458\u8981\u65b9\u6cd5\u5206\u6790\u8bc4\u8bba\u95f4\u7684\u771f\u5b9e\u5173\u8054\u3002\",\n  \"result\": \"\u7cfb\u7edf\u80fd\u751f\u6210\u5e26'\u5e38\u8bc6'\u5224\u65ad\u7684\u8bc4\u8bba\u6458\u8981\uff0c\u6e05\u6670\u5448\u73b0\u4ea7\u54c1\u4f18\u7f3a\u70b9\uff0c\u8f85\u52a9\u7528\u6237\u51b3\u7b56\u3002\",\n  \"conclusion\": \"\u751f\u6210\u5f0f\u6a21\u578b\u6bd4\u4f20\u7edf\u63d0\u53d6\u5f0f\u65b9\u6cd5\u66f4\u80fd\u6709\u6548\u89e3\u51b3\u8bc4\u8bba\u8fc7\u8f7d\u95ee\u9898\uff0c\u8d4b\u4e88\u6d88\u8d39\u8005\u66f4\u9ad8\u6548\u7684\u51b3\u7b56\u80fd\u529b\u3002\"\n}\n```", "additional_kwargs": {"refusal": null}, "response_metadata": {"token_usage": {"completion_tokens": 163, "prompt_tokens": 591, "total_tokens": 754, "completion_tokens_details": null, "prompt_tokens_details": null}, "model_name": "deepseek/deepseek-chat-v3-0324:free", "system_fingerprint": null, "id": "gen-1747817628-ypSC337Z068qA6iTsDvr", "finish_reason": "stop", "logprobs": null}, "type": "ai", "name": null, "id": "run-14f24fa2-41e1-42c8-837d-7a9837cd3c14-0", "example": false, "tool_calls": [], "invalid_tool_calls": [], "usage_metadata": {"input_tokens": 591, "output_tokens": 163, "total_tokens": 754, "input_token_details": {}, "output_token_details": {}}}}
{"id": "2505.13484", "pdf": "https://arxiv.org/pdf/2505.13484", "abs": "https://arxiv.org/abs/2505.13484", "authors": ["Rene Heesch", "Sebastian Eilermann", "Alexander Windmann", "Alexander Diedrich", "Philipp Rosenthal", "Oliver Niggemann"], "title": "Evaluating Large Language Models for Real-World Engineering Tasks", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) are transformative not only for daily activities\nbut also for engineering tasks. However, current evaluations of LLMs in\nengineering exhibit two critical shortcomings: (i) the reliance on simplified\nuse cases, often adapted from examination materials where correctness is easily\nverifiable, and (ii) the use of ad hoc scenarios that insufficiently capture\ncritical engineering competencies. Consequently, the assessment of LLMs on\ncomplex, real-world engineering problems remains largely unexplored. This paper\naddresses this gap by introducing a curated database comprising over 100\nquestions derived from authentic, production-oriented engineering scenarios,\nsystematically designed to cover core competencies such as product design,\nprognosis, and diagnosis. Using this dataset, we evaluate four state-of-the-art\nLLMs, including both cloud-based and locally hosted instances, to\nsystematically investigate their performance on complex engineering tasks. Our\nresults show that LLMs demonstrate strengths in basic temporal and structural\nreasoning but struggle significantly with abstract reasoning, formal modeling,\nand context-sensitive engineering logic.", "AI": {"content": "```json\n{\n  \"tldr\": \"\u8bba\u6587\u6307\u51fa\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b(LLM)\u5728\u5de5\u7a0b\u9886\u57df\u7684\u8bc4\u4f30\u5b58\u5728\u7b80\u5316\u7528\u4f8b\u548c\u4e34\u65f6\u573a\u666f\u7684\u95ee\u9898\uff0c\u901a\u8fc7\u6784\u5efa\u771f\u5b9e\u5de5\u7a0b\u573a\u666f\u6570\u636e\u5e93\u8bc4\u4f30\u4e86\u56db\u6b3eLLM\uff0c\u53d1\u73b0\u5176\u5728\u57fa\u7840\u63a8\u7406\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u62bd\u8c61\u63a8\u7406\u548c\u5de5\u7a0b\u903b\u8f91\u65b9\u9762\u4e0d\u8db3\u3002\",\n  \"motivation\": \"\u5f53\u524dLLM\u5728\u5de5\u7a0b\u9886\u57df\u7684\u8bc4\u4f30\u8fc7\u4e8e\u4f9d\u8d56\u7b80\u5316\u7528\u4f8b\u548c\u4e34\u65f6\u573a\u666f\uff0c\u672a\u80fd\u5145\u5206\u68c0\u9a8c\u5176\u5728\u590d\u6742\u771f\u5b9e\u5de5\u7a0b\u95ee\u9898\u4e2d\u7684\u80fd\u529b\u3002\u8be5\u7814\u7a76\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002\",\n  \"method\": \"\u6784\u5efa\u5305\u542b100\u591a\u4e2a\u771f\u5b9e\u5de5\u7a0b\u573a\u666f\u95ee\u9898\u7684\u6570\u636e\u5e93\uff0c\u7cfb\u7edf\u6027\u8986\u76d6\u6838\u5fc3\u5de5\u7a0b\u80fd\u529b\uff0c\u5e76\u8bc4\u4f30\u56db\u6b3e\u5148\u8fdbLLM\u7684\u8868\u73b0\u3002\",\n  \"result\": \"LLM\u5728\u57fa\u7840\u65f6\u95f4\u548c\u7ed3\u6784\u63a8\u7406\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u62bd\u8c61\u63a8\u7406\u3001\u5f62\u5f0f\u5316\u5efa\u6a21\u548c\u4e0a\u4e0b\u6587\u654f\u611f\u5de5\u7a0b\u903b\u8f91\u65b9\u9762\u5b58\u5728\u663e\u8457\u56f0\u96be\u3002\",\n  \"conclusion\": \"\u7814\u7a76\u8868\u660e\u9700\u5f00\u53d1\u66f4\u5168\u9762\u7684\u8bc4\u4f30\u65b9\u6cd5\u4ee5\u68c0\u9a8cLLM\u5728\u590d\u6742\u5de5\u7a0b\u4efb\u52a1\u4e2d\u7684\u771f\u5b9e\u80fd\u529b\uff0c\u5f53\u524d\u6a21\u578b\u4ecd\u6709\u660e\u663e\u5c40\u9650\u6027\u3002\"\n}\n```", "additional_kwargs": {"refusal": null}, "response_metadata": {"token_usage": {"completion_tokens": 203, "prompt_tokens": 536, "total_tokens": 739, "completion_tokens_details": null, "prompt_tokens_details": null}, "model_name": "deepseek/deepseek-chat-v3-0324:free", "system_fingerprint": null, "id": "gen-1747817632-Mc64gc5Vq1kiv2O9F8y1", "finish_reason": "stop", "logprobs": null}, "type": "ai", "name": null, "id": "run-688ca1e7-2365-4f30-a6b3-66494a982618-0", "example": false, "tool_calls": [], "invalid_tool_calls": [], "usage_metadata": {"input_tokens": 536, "output_tokens": 203, "total_tokens": 739, "input_token_details": {}, "output_token_details": {}}}}
{"id": "2505.13461", "pdf": "https://arxiv.org/pdf/2505.13461", "abs": "https://arxiv.org/abs/2505.13461", "authors": ["Junye Jiang", "Yaan Zhou", "Yuanhao Gong", "Haoxuan Yuan", "Shuanglong Liu"], "title": "FPGA-based Acceleration for Convolutional Neural Networks: A Comprehensive Review", "categories": ["cs.LG", "cs.AR", "C.3"], "comment": "19 pages, 3 figures", "summary": "Convolutional Neural Networks (CNNs) are fundamental to deep learning,\ndriving applications across various domains. However, their growing complexity\nhas significantly increased computational demands, necessitating efficient\nhardware accelerators. Field-Programmable Gate Arrays (FPGAs) have emerged as a\nleading solution, offering reconfigurability, parallelism, and energy\nefficiency. This paper provides a comprehensive review of FPGA-based hardware\naccelerators specifically designed for CNNs. It presents and summarizes the\nperformance evaluation framework grounded in existing studies and explores key\noptimization strategies, such as parallel computing, dataflow optimization, and\nhardware-software co-design. It also compares various FPGA architectures in\nterms of latency, throughput, compute efficiency, power consumption, and\nresource utilization. Finally, the paper highlights future challenges and\nopportunities, emphasizing the potential for continued innovation in this\nfield.", "AI": {"content": "|---\ntldr: \u672c\u6587\u5bf9\u57fa\u4e8eFPGA\u7684CNN\u786c\u4ef6\u52a0\u901f\u5668\u8fdb\u884c\u4e86\u5168\u9762\u7efc\u8ff0\uff0c\u603b\u7ed3\u4e86\u6027\u80fd\u8bc4\u4f30\u6846\u67b6\u548c\u4f18\u5316\u7b56\u7565\uff0c\u5e76\u6bd4\u8f83\u4e86\u4e0d\u540cFPGA\u67b6\u6784\u7684\u6027\u80fd\u3002\nmotivation: \u968f\u7740\u5377\u79ef\u795e\u7ecf\u7f51\u7edc(CNN)\u590d\u6742\u5ea6\u7684\u589e\u52a0\uff0c\u8ba1\u7b97\u9700\u6c42\u6025\u5267\u4e0a\u5347\uff0c\u9700\u8981\u9ad8\u6548\u7684\u786c\u4ef6\u52a0\u901f\u5668\u3002FPGA\u56e0\u5176\u53ef\u91cd\u6784\u6027\u3001\u5e76\u884c\u6027\u548c\u80fd\u6548\u6210\u4e3a\u7406\u60f3\u9009\u62e9\u3002\nmethod: \u672c\u6587\u7efc\u8ff0\u4e86FPGA\u52a0\u901fCNN\u7684\u4f18\u5316\u7b56\u7565\uff0c\u5305\u62ec\u5e76\u884c\u8ba1\u7b97\u3001\u6570\u636e\u6d41\u4f18\u5316\u548c\u8f6f\u786c\u4ef6\u534f\u540c\u8bbe\u8ba1\uff0c\u5e76\u6bd4\u8f83\u4e86\u4e0d\u540cFPGA\u67b6\u6784\u7684\u6027\u80fd\u3002\nresult: \u7814\u7a76\u603b\u7ed3\u4e86FPGA\u52a0\u901fCNN\u7684\u6027\u80fd\u8bc4\u4f30\u6846\u67b6\uff0c\u6bd4\u8f83\u4e86\u5ef6\u8fdf\u3001\u541e\u5410\u91cf\u3001\u8ba1\u7b97\u6548\u7387\u3001\u529f\u8017\u548c\u8d44\u6e90\u5229\u7528\u7387\u7b49\u6307\u6807\u3002\nconclusion: \u672c\u6587\u4e3aFPGA\u52a0\u901fCNN\u7684\u7814\u7a76\u63d0\u4f9b\u4e86\u5168\u9762\u7efc\u8ff0\uff0c\u5e76\u6307\u51fa\u4e86\u672a\u6765\u7814\u7a76\u7684\u65b9\u5411\u548c\u673a\u9047\u3002", "additional_kwargs": {"refusal": null}, "response_metadata": {"token_usage": {"completion_tokens": 168, "prompt_tokens": 502, "total_tokens": 670, "completion_tokens_details": null, "prompt_tokens_details": null}, "model_name": "deepseek/deepseek-chat-v3-0324:free", "system_fingerprint": null, "id": "gen-1747817639-PRk2ykRz5cCfZKymkWqW", "finish_reason": "stop", "logprobs": null}, "type": "ai", "name": null, "id": "run-84a3e551-c3a8-4ce9-a7bf-3349446bddf6-0", "example": false, "tool_calls": [], "invalid_tool_calls": [], "usage_metadata": {"input_tokens": 502, "output_tokens": 168, "total_tokens": 670, "input_token_details": {}, "output_token_details": {}}}}
{"id": "2505.13492", "pdf": "https://arxiv.org/pdf/2505.13492", "abs": "https://arxiv.org/abs/2505.13492", "authors": ["Weiming Zhang", "Lingyue Fu", "Qingyao Li", "Kounianhua Du", "Jianghao Lin", "Jingwei Yu", "Wei Xia", "Weinan Zhang", "Ruiming Tang", "Yong Yu"], "title": "LLM4CD: Leveraging Large Language Models for Open-World Knowledge Augmented Cognitive Diagnosis", "categories": ["cs.CL"], "comment": null, "summary": "Cognitive diagnosis (CD) plays a crucial role in intelligent education,\nevaluating students' comprehension of knowledge concepts based on their test\nhistories. However, current CD methods often model students, exercises, and\nknowledge concepts solely on their ID relationships, neglecting the abundant\nsemantic relationships present within educational data space. Furthermore,\ncontemporary intelligent tutoring systems (ITS) frequently involve the addition\nof new students and exercises, a situation that ID-based methods find\nchallenging to manage effectively. The advent of large language models (LLMs)\noffers the potential for overcoming this challenge with open-world knowledge.\nIn this paper, we propose LLM4CD, which Leverages Large Language Models for\nOpen-World Knowledge Augmented Cognitive Diagnosis. Our method utilizes the\nopen-world knowledge of LLMs to construct cognitively expressive textual\nrepresentations, which are then encoded to introduce rich semantic information\ninto the CD task. Additionally, we propose an innovative bi-level encoder\nframework that models students' test histories through two levels of encoders:\na macro-level cognitive text encoder and a micro-level knowledge state encoder.\nThis approach substitutes traditional ID embeddings with semantic\nrepresentations, enabling the model to accommodate new students and exercises\nwith open-world knowledge and address the cold-start problem. Extensive\nexperimental results demonstrate that our proposed method consistently\noutperforms previous CD models on multiple real-world datasets, validating the\neffectiveness of leveraging LLMs to introduce rich semantic information into\nthe CD task.", "AI": {"content": "```json\n{\n  \"tldr\": \"\u8bba\u6587\u63d0\u51faLLM4CD\u65b9\u6cd5\uff0c\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u5f00\u653e\u4e16\u754c\u77e5\u8bc6\u589e\u5f3a\u8ba4\u77e5\u8bca\u65ad\uff0c\u901a\u8fc7\u6784\u5efa\u8ba4\u77e5\u8868\u8fbe\u6027\u6587\u672c\u8868\u793a\u548c\u53cc\u7ea7\u7f16\u7801\u5668\u6846\u67b6\uff0c\u89e3\u51b3\u4f20\u7edf\u8ba4\u77e5\u8bca\u65ad\u65b9\u6cd5\u5728\u5904\u7406\u65b0\u5b66\u751f\u548c\u7ec3\u4e60\u65f6\u7684\u5c40\u9650\u6027\u3002\",\n  \"motivation\": \"\u5f53\u524d\u8ba4\u77e5\u8bca\u65ad\u65b9\u6cd5\u4e3b\u8981\u4f9d\u8d56ID\u5173\u7cfb\u5efa\u6a21\uff0c\u5ffd\u89c6\u4e86\u6559\u80b2\u6570\u636e\u7a7a\u95f4\u4e2d\u7684\u4e30\u5bcc\u8bed\u4e49\u5173\u7cfb\uff0c\u4e14\u96be\u4ee5\u6709\u6548\u5904\u7406\u65b0\u5b66\u751f\u548c\u7ec3\u4e60\u7684\u52a0\u5165\u3002\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u51fa\u73b0\u4e3a\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u63d0\u4f9b\u4e86\u53ef\u80fd\u3002\",\n  \"method\": \"LLM4CD\u5229\u7528LLM\u7684\u5f00\u653e\u4e16\u754c\u77e5\u8bc6\u6784\u5efa\u8ba4\u77e5\u8868\u8fbe\u6027\u6587\u672c\u8868\u793a\uff0c\u5e76\u901a\u8fc7\u53cc\u7ea7\u7f16\u7801\u5668\u6846\u67b6\uff08\u5b8f\u89c2\u8ba4\u77e5\u6587\u672c\u7f16\u7801\u5668\u548c\u5fae\u89c2\u77e5\u8bc6\u72b6\u6001\u7f16\u7801\u5668\uff09\u5bf9\u5b66\u751f\u7684\u6d4b\u8bd5\u5386\u53f2\u8fdb\u884c\u5efa\u6a21\uff0c\u66ff\u4ee3\u4f20\u7edf\u7684ID\u5d4c\u5165\u3002\",\n  \"result\": \"\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cLLM4CD\u5728\u591a\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u4f18\u4e8e\u73b0\u6709\u8ba4\u77e5\u8bca\u65ad\u6a21\u578b\uff0c\u9a8c\u8bc1\u4e86\u5229\u7528LLM\u5f15\u5165\u4e30\u5bcc\u8bed\u4e49\u4fe1\u606f\u7684\u6709\u6548\u6027\u3002\",\n  \"conclusion\": \"LLM4CD\u901a\u8fc7\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u5f00\u653e\u4e16\u754c\u77e5\u8bc6\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u8ba4\u77e5\u8bca\u65ad\u4e2d\u7684\u8bed\u4e49\u4fe1\u606f\u4e0d\u8db3\u548c\u65b0\u5b66\u751f\u3001\u7ec3\u4e60\u5904\u7406\u95ee\u9898\uff0c\u4e3a\u667a\u80fd\u6559\u80b2\u7cfb\u7edf\u63d0\u4f9b\u4e86\u66f4\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002\"\n}\n```", "additional_kwargs": {"refusal": null}, "response_metadata": {"token_usage": {"completion_tokens": 246, "prompt_tokens": 621, "total_tokens": 867, "completion_tokens_details": null, "prompt_tokens_details": null}, "model_name": "deepseek/deepseek-chat-v3-0324:free", "system_fingerprint": null, "id": "gen-1747817643-32D88LnnIPJZ6Sy9DUcs", "finish_reason": "stop", "logprobs": null}, "type": "ai", "name": null, "id": "run-5abcf84f-eb50-413e-9586-25c0ad58ac11-0", "example": false, "tool_calls": [], "invalid_tool_calls": [], "usage_metadata": {"input_tokens": 621, "output_tokens": 246, "total_tokens": 867, "input_token_details": {}, "output_token_details": {}}}}
{"id": "2505.13489", "pdf": "https://arxiv.org/pdf/2505.13489", "abs": "https://arxiv.org/abs/2505.13489", "authors": ["Wenkang Han", "Wang Lin", "Liya Hu", "Zhenlong Dai", "Yiyun Zhou", "Mengze Li", "Zemin Liu", "Chang Yao", "Jingyuan Chen"], "title": "Contrastive Cross-Course Knowledge Tracing via Concept Graph Guided Knowledge Transfer", "categories": ["cs.AI", "cs.CL"], "comment": "Accepted by IJCAI 2025", "summary": "Knowledge tracing (KT) aims to predict learners' future performance based on\nhistorical learning interactions. However, existing KT models predominantly\nfocus on data from a single course, limiting their ability to capture a\ncomprehensive understanding of learners' knowledge states. In this paper, we\npropose TransKT, a contrastive cross-course knowledge tracing method that\nleverages concept graph guided knowledge transfer to model the relationships\nbetween learning behaviors across different courses, thereby enhancing\nknowledge state estimation. Specifically, TransKT constructs a cross-course\nconcept graph by leveraging zero-shot Large Language Model (LLM) prompts to\nestablish implicit links between related concepts across different courses.\nThis graph serves as the foundation for knowledge transfer, enabling the model\nto integrate and enhance the semantic features of learners' interactions across\ncourses. Furthermore, TransKT includes an LLM-to-LM pipeline for incorporating\nsummarized semantic features, which significantly improves the performance of\nGraph Convolutional Networks (GCNs) used for knowledge transfer. Additionally,\nTransKT employs a contrastive objective that aligns single-course and\ncross-course knowledge states, thereby refining the model's ability to provide\na more robust and accurate representation of learners' overall knowledge\nstates.", "AI": {"content": "```json\n{\n  \"tldr\": \"TransKT\u63d0\u51fa\u4e00\u79cd\u8de8\u8bfe\u7a0b\u77e5\u8bc6\u8ffd\u8e2a\u65b9\u6cd5\uff0c\u5229\u7528\u6982\u5ff5\u56fe\u548c\u5bf9\u6bd4\u5b66\u4e60\u63d0\u5347\u5b66\u4e60\u8005\u77e5\u8bc6\u72b6\u6001\u5efa\u6a21\u3002\",\n  \"motivation\": \"\u73b0\u6709\u77e5\u8bc6\u8ffd\u8e2a\u6a21\u578b\u4ec5\u5173\u6ce8\u5355\u4e00\u8bfe\u7a0b\u6570\u636e\uff0c\u65e0\u6cd5\u5168\u9762\u6355\u6349\u5b66\u4e60\u8005\u7684\u8de8\u8bfe\u7a0b\u77e5\u8bc6\u72b6\u6001\u3002\",\n  \"method\": \"1) \u4f7f\u7528\u96f6\u6837\u672c\u5927\u8bed\u8a00\u6a21\u578b\u6784\u5efa\u8de8\u8bfe\u7a0b\u6982\u5ff5\u56fe 2) \u8bbe\u8ba1LLM-to-LM\u7ba1\u9053\u6574\u5408\u8bed\u4e49\u7279\u5f81 3) \u91c7\u7528\u5bf9\u6bd4\u5b66\u4e60\u5bf9\u9f50\u5355\u8bfe\u7a0b\u4e0e\u8de8\u8bfe\u7a0b\u77e5\u8bc6\u72b6\u6001\",\n  \"result\": \"\u901a\u8fc7\u8de8\u8bfe\u7a0b\u77e5\u8bc6\u8fc1\u79fb\u548c\u8bed\u4e49\u7279\u5f81\u589e\u5f3a\uff0c\u663e\u8457\u63d0\u5347\u4e86\u56fe\u5377\u79ef\u7f51\u7edc\u7684\u77e5\u8bc6\u8ffd\u8e2a\u6027\u80fd\u3002\",\n  \"conclusion\": \"TransKT\u80fd\u66f4\u5168\u9762\u3001\u51c6\u786e\u5730\u8868\u5f81\u5b66\u4e60\u8005\u7684\u6574\u4f53\u77e5\u8bc6\u72b6\u6001\uff0c\u4e3a\u8de8\u8bfe\u7a0b\u5b66\u4e60\u5206\u6790\u63d0\u4f9b\u65b0\u601d\u8def\u3002\"\n}\n```", "additional_kwargs": {"refusal": null}, "response_metadata": {"token_usage": {"completion_tokens": 168, "prompt_tokens": 570, "total_tokens": 738, "completion_tokens_details": null, "prompt_tokens_details": null}, "model_name": "deepseek/deepseek-chat-v3-0324:free", "system_fingerprint": null, "id": "gen-1747817677-kjEXxLlRbdnIYMPMQDem", "finish_reason": "stop", "logprobs": null}, "type": "ai", "name": null, "id": "run-7c9f74b4-fd2e-4e67-bcb4-5ca77708b0f8-0", "example": false, "tool_calls": [], "invalid_tool_calls": [], "usage_metadata": {"input_tokens": 570, "output_tokens": 168, "total_tokens": 738, "input_token_details": {}, "output_token_details": {}}}}
{"id": "2505.13462", "pdf": "https://arxiv.org/pdf/2505.13462", "abs": "https://arxiv.org/abs/2505.13462", "authors": ["Thien Nguyen", "William Guicquero"], "title": "End-to-end fully-binarized network design: from Generic Learned Thermometer to Block Pruning", "categories": ["cs.LG", "cs.AR", "cs.CV", "eess.IV", "stat.ML"], "comment": "Accepted to IEEE AICAS 2025", "summary": "Existing works on Binary Neural Network (BNN) mainly focus on model's weights\nand activations while discarding considerations on the input raw data. This\narticle introduces Generic Learned Thermometer (GLT), an encoding technique to\nimprove input data representation for BNN, relying on learning non linear\nquantization thresholds. This technique consists in multiple data binarizations\nwhich can advantageously replace a conventional Analog to Digital Conversion\n(ADC) that uses natural binary coding. Additionally, we jointly propose a\ncompact topology with light-weight grouped convolutions being trained thanks to\nblock pruning and Knowledge Distillation (KD), aiming at reducing furthermore\nthe model size so as its computational complexity. We show that GLT brings\nversatility to the BNN by intrinsically performing global tone mapping,\nenabling significant accuracy gains in practice (demonstrated by simulations on\nthe STL-10 and VWW datasets). Moreover, when combining GLT with our proposed\nblock-pruning technique, we successfully achieve lightweight (under 1Mb),\nfully-binarized models with limited accuracy degradation while being suitable\nfor in-sensor always-on inference use cases.", "AI": {"content": "```json\n{\n  \"tldr\": \"\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aGLT\u7684\u7f16\u7801\u6280\u672f\uff0c\u901a\u8fc7\u591a\u503c\u4e8c\u503c\u5316\u6539\u8fdbBNN\u7684\u8f93\u5165\u6570\u636e\u8868\u793a\uff0c\u7ed3\u5408\u8f7b\u91cf\u7ea7\u5206\u7ec4\u5377\u79ef\u548c\u77e5\u8bc6\u84b8\u998f\uff0c\u663e\u8457\u63d0\u5347\u6a21\u578b\u7cbe\u5ea6\u5e76\u964d\u4f4e\u8ba1\u7b97\u590d\u6742\u5ea6\u3002\",\n  \"motivation\": \"\u73b0\u6709BNN\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u6a21\u578b\u6743\u91cd\u548c\u6fc0\u6d3b\u51fd\u6570\uff0c\u800c\u5ffd\u7565\u4e86\u8f93\u5165\u539f\u59cb\u6570\u636e\u7684\u4f18\u5316\u3002\u672c\u6587\u65e8\u5728\u901a\u8fc7\u6539\u8fdb\u8f93\u5165\u6570\u636e\u8868\u793a\uff0c\u63d0\u5347BNN\u7684\u6027\u80fd\u3002\",\n  \"method\": \"\u63d0\u51faGLT\u7f16\u7801\u6280\u672f\uff0c\u5229\u7528\u975e\u7ebf\u6027\u91cf\u5316\u9608\u503c\u8fdb\u884c\u591a\u503c\u4e8c\u503c\u5316\uff0c\u66ff\u4ee3\u4f20\u7edf\u7684ADC\uff1b\u7ed3\u5408\u8f7b\u91cf\u7ea7\u5206\u7ec4\u5377\u79ef\u3001\u5757\u526a\u679d\u548c\u77e5\u8bc6\u84b8\u998f\uff0c\u8fdb\u4e00\u6b65\u964d\u4f4e\u6a21\u578b\u590d\u6742\u5ea6\u548c\u8ba1\u7b97\u91cf\u3002\",\n  \"result\": \"\u5b9e\u9a8c\u8868\u660e\uff0cGLT\u80fd\u663e\u8457\u63d0\u5347BNN\u5728STL-10\u548cVWW\u6570\u636e\u96c6\u4e0a\u7684\u7cbe\u5ea6\uff0c\u7ed3\u5408\u5757\u526a\u679d\u6280\u672f\u540e\uff0c\u5b9e\u73b0\u4e86\u6a21\u578b\u5927\u5c0f\u5c0f\u4e8e1MB\u7684\u5168\u4e8c\u503c\u5316\u6a21\u578b\uff0c\u9002\u7528\u4e8e\u4f20\u611f\u5668\u5185\u6301\u7eed\u63a8\u7406\u573a\u666f\u3002\",\n  \"conclusion\": \"GLT\u6280\u672f\u6709\u6548\u4f18\u5316\u4e86BNN\u7684\u8f93\u5165\u6570\u636e\u8868\u793a\uff0c\u7ed3\u5408\u8f7b\u91cf\u7ea7\u8bbe\u8ba1\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6027\u80fd\u3001\u4f4e\u590d\u6742\u5ea6\u7684\u5168\u4e8c\u503c\u5316\u6a21\u578b\uff0c\u9002\u7528\u4e8e\u5b9e\u9645\u5e94\u7528\u573a\u666f\u3002\"\n}\n```", "additional_kwargs": {"refusal": null}, "response_metadata": {"token_usage": {"completion_tokens": 244, "prompt_tokens": 552, "total_tokens": 796, "completion_tokens_details": null, "prompt_tokens_details": null}, "model_name": "deepseek/deepseek-chat-v3-0324:free", "system_fingerprint": null, "id": "gen-1747817682-KphUGQC2BnEvfw1QQOcr", "finish_reason": "stop", "logprobs": null}, "type": "ai", "name": null, "id": "run-811a1f68-2b9c-4cfa-945e-2fc63bb1b7b8-0", "example": false, "tool_calls": [], "invalid_tool_calls": [], "usage_metadata": {"input_tokens": 552, "output_tokens": 244, "total_tokens": 796, "input_token_details": {}, "output_token_details": {}}}}
{"id": "2505.13498", "pdf": "https://arxiv.org/pdf/2505.13498", "abs": "https://arxiv.org/abs/2505.13498", "authors": ["Khanh-Tung Tran", "Barry O'Sullivan", "Hoang D. Nguyen"], "title": "IRLBench: A Multi-modal, Culturally Grounded, Parallel Irish-English Benchmark for Open-Ended LLM Reasoning Evaluation", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Recent advances in Large Language Models (LLMs) have demonstrated promising\nknowledge and reasoning abilities, yet their performance in multilingual and\nlow-resource settings remains underexplored. Existing benchmarks often exhibit\ncultural bias, restrict evaluation to text-only, rely on multiple-choice\nformats, and, more importantly, are limited for extremely low-resource\nlanguages. To address these gaps, we introduce IRLBench, presented in parallel\nEnglish and Irish, which is considered definitely endangered by UNESCO. Our\nbenchmark consists of 12 representative subjects developed from the 2024 Irish\nLeaving Certificate exams, enabling fine-grained analysis of model capabilities\nacross domains. By framing the task as long-form generation and leveraging the\nofficial marking scheme, it does not only support a comprehensive evaluation of\ncorrectness but also language fidelity. Our extensive experiments of leading\nclosed-source and open-source LLMs reveal a persistent performance gap between\nEnglish and Irish, in which models produce valid Irish responses less than 80\\%\nof the time, and answer correctly 55.8\\% of the time compared to 76.2\\% in\nEnglish for the best-performing model. We release IRLBench\n(https://huggingface.co/datasets/ReliableAI/IRLBench) and an accompanying\nevaluation codebase (https://github.com/ReML-AI/IRLBench) to enable future\nresearch on robust, culturally aware multilingual AI development.", "AI": {"content": "```json\n{\n  \"tldr\": \"\u8be5\u8bba\u6587\u63d0\u51fa\u4e86IRLBench\uff0c\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4f4e\u8d44\u6e90\u8bed\u8a00\uff08\u7231\u5c14\u5170\u8bed\uff09\u4e0a\u6027\u80fd\u7684\u65b0\u57fa\u51c6\uff0c\u63ed\u793a\u4e86\u82f1\u8bed\u4e0e\u7231\u5c14\u5170\u8bed\u4e4b\u95f4\u7684\u6027\u80fd\u5dee\u8ddd\u3002\",\n  \"motivation\": \"\u73b0\u6709\u7684\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4f4e\u8d44\u6e90\u8bed\u8a00\u548c\u6587\u5316\u591a\u6837\u6027\u65b9\u9762\u7684\u6027\u80fd\u672a\u88ab\u5145\u5206\u8bc4\u4f30\uff0c\u4e14\u73b0\u6709\u57fa\u51c6\u5b58\u5728\u6587\u5316\u504f\u89c1\u3001\u4ec5\u9650\u6587\u672c\u8bc4\u4f30\u3001\u4f9d\u8d56\u591a\u9879\u9009\u62e9\u683c\u5f0f\u7b49\u95ee\u9898\u3002\",\n  \"method\": \"\u901a\u8fc7\u4f7f\u7528\u7231\u5c14\u5170\u9ad8\u4e2d\u6bd5\u4e1a\u8003\u8bd5\u5185\u5bb9\u6784\u5efaIRLBench\u57fa\u51c6\uff0c\u4ee5\u957f\u6587\u672c\u751f\u6210\u4efb\u52a1\u548c\u5b98\u65b9\u8bc4\u5206\u6807\u51c6\u8bc4\u4f30\u6a21\u578b\u7684\u6b63\u786e\u6027\u548c\u8bed\u8a00\u4fdd\u771f\u5ea6\u3002\",\n  \"result\": \"\u5b9e\u9a8c\u663e\u793a\uff0c\u8868\u73b0\u6700\u4f73\u7684\u6a21\u578b\u5728\u7231\u5c14\u5170\u8bed\u4e0a\u7684\u51c6\u786e\u7387\u4e3a55.8%\uff0c\u8fdc\u4f4e\u4e8e\u82f1\u8bed\u768476.2%\uff0c\u4e14\u6a21\u578b\u751f\u6210\u6709\u6548\u7231\u5c14\u5170\u8bed\u7684\u9891\u7387\u4e0d\u8db380%\u3002\",\n  \"conclusion\": \"\u8bba\u6587\u5f3a\u8c03\u9700\u8981\u66f4\u7a33\u5065\u3001\u6587\u5316\u654f\u611f\u7684\u8de8\u8bed\u8a00AI\u53d1\u5c55\uff0c\u5e76\u5f00\u6e90\u4e86IRLBench\u57fa\u51c6\u548c\u8bc4\u4f30\u4ee3\u7801\u4ee5\u4fc3\u8fdb\u672a\u6765\u7814\u7a76\u3002\"\n}\n```", "additional_kwargs": {"refusal": null}, "response_metadata": {"token_usage": {"completion_tokens": 204, "prompt_tokens": 623, "total_tokens": 827, "completion_tokens_details": null, "prompt_tokens_details": null}, "model_name": "deepseek/deepseek-chat-v3-0324:free", "system_fingerprint": null, "id": "gen-1747817710-gR1EKo9MjWCwbtDHe2p5", "finish_reason": "stop", "logprobs": null}, "type": "ai", "name": null, "id": "run-0903ee1e-c587-4e90-a254-00b096c4ba34-0", "example": false, "tool_calls": [], "invalid_tool_calls": [], "usage_metadata": {"input_tokens": 623, "output_tokens": 204, "total_tokens": 827, "input_token_details": {}, "output_token_details": {}}}}
{"id": "2505.13496", "pdf": "https://arxiv.org/pdf/2505.13496", "abs": "https://arxiv.org/abs/2505.13496", "authors": ["Przemek Pospieszny", "Wojciech Mormul", "Karolina Szyndler", "Sanjeev Kumar"], "title": "ADALog: Adaptive Unsupervised Anomaly detection in Logs with Self-attention Masked Language Model", "categories": ["cs.AI", "cs.LG", "I.2.6; I.2.7; I.5.1; C.2.4"], "comment": "Conference paper accepted at ICMLT 2025; to appear in the IEEE\n  Conference Proceedings", "summary": "Modern software systems generate extensive heterogeneous log data with\ndynamic formats, fragmented event sequences, and varying temporal patterns,\nmaking anomaly detection both crucial and challenging. To address these\ncomplexities, we propose ADALog, an adaptive, unsupervised anomaly detection\nframework designed for practical applicability across diverse real-world\nenvironments. Unlike traditional methods reliant on log parsing, strict\nsequence dependencies, or labeled data, ADALog operates on individual\nunstructured logs, extracts intra-log contextual relationships, and performs\nadaptive thresholding on normal data. The proposed approach utilizes a\ntransformer-based, pretrained bidirectional encoder with a masked language\nmodeling task, fine-tuned on normal logs to capture domain-specific syntactic\nand semantic patterns essential for accurate anomaly detection. Anomalies are\nidentified via token-level reconstruction probabilities, aggregated into\nlog-level scores, with adaptive percentile-based thresholding calibrated only\non normal data. This allows the model to dynamically adapt to evolving system\nbehaviors while avoiding rigid, heuristic-based thresholds common in\ntraditional systems. We evaluate ADALog on benchmark datasets BGL, Thunderbird,\nand Spirit, showing strong generalization and competitive performance compared\nto state-of-the-art supervised and unsupervised methods. Additional ablation\nstudies examine the effects of masking, fine-tuning, and token positioning on\nmodel behavior and interpretability.", "AI": {"content": "Here is the JSON instance based on the provided abstract:\n\n```json\n{\n  \"tldr\": \"ADALog is an adaptive, unsupervised anomaly detection framework for diverse real-world environments, using a transformer-based model to detect anomalies in unstructured logs without labeled data.\",\n  \"motivation\": \"Modern software systems generate complex and varied log data, making anomaly detection challenging. Traditional methods rely on structured logs, strict sequences, or labeled data, which are often unavailable or impractical.\",\n  \"method\": \"ADALog uses a transformer-based, pretrained bidirectional encoder with masked language modeling, fine-tuned on normal logs. It extracts intra-log context, computes token-level reconstruction probabilities, and applies adaptive thresholding on normal data to detect anomalies.\",\n  \"result\": \"ADALog demonstrates strong generalization and competitive performance on benchmark datasets (BGL, Thunderbird, Spirit) compared to state-of-the-art supervised and unsupervised methods. Ablation studies analyze the impact of masking, fine-tuning, and token positioning.\",\n  \"conclusion\": \"ADALog effectively addresses the challenges of anomaly detection in dynamic, unstructured log data by leveraging adaptive, unsupervised learning, and outperforms traditional methods without relying on labeled data or rigid thresholds.\"\n}\n```", "additional_kwargs": {"refusal": null}, "response_metadata": {"token_usage": {"completion_tokens": 248, "prompt_tokens": 590, "total_tokens": 838, "completion_tokens_details": null, "prompt_tokens_details": null}, "model_name": "deepseek/deepseek-chat-v3-0324:free", "system_fingerprint": null, "id": "gen-1747817719-oR2huZJdFP8bD5GN0lKO", "finish_reason": "stop", "logprobs": null}, "type": "ai", "name": null, "id": "run-b1b9e5e8-7378-480c-adc9-eb92df0f2267-0", "example": false, "tool_calls": [], "invalid_tool_calls": [], "usage_metadata": {"input_tokens": 590, "output_tokens": 248, "total_tokens": 838, "input_token_details": {}, "output_token_details": {}}}}
{"id": "2505.13463", "pdf": "https://arxiv.org/pdf/2505.13463", "abs": "https://arxiv.org/abs/2505.13463", "authors": ["Paolo Guida", "William L. Roberts"], "title": "Predicting The Evolution of Interfaces with Fourier Neural Operators", "categories": ["cs.LG", "physics.flu-dyn"], "comment": null, "summary": "Recent progress in AI has established neural operators as powerful tools that\ncan predict the evolution of partial differential equations, such as the\nNavier-Stokes equations. Some complex problems rely on sophisticated algorithms\nto deal with strong discontinuities in the computational domain. For example,\nliquid-vapour multiphase flows are a challenging problem in many\nconfigurations, particularly those involving large density gradients or phase\nchange. The complexity mentioned above has not allowed for fine control of fast\nindustrial processes or applications because computational fluid dynamics (CFD)\nmodels do not have a quick enough forecasting ability. This work demonstrates\nthat the time scale of neural operators-based predictions is comparable to the\ntime scale of multi-phase applications, thus proving they can be used to\ncontrol processes that require fast response. Neural Operators can be trained\nusing experimental data, simulations or a combination. In the following, neural\noperators were trained in volume of fluid simulations, and the resulting\npredictions showed very high accuracy, particularly in predicting the evolution\nof the liquid-vapour interface, one of the most critical tasks in a multi-phase\nprocess controller.", "AI": {"content": "```json\n{\n  \"tldr\": \"\u8bba\u6587\u63a2\u8ba8\u4e86AI\u5728\u9884\u6d4b\u591a\u76f8\u6d41\uff08\u5982\u6db2-\u6c7d\u76f8\u53d8\uff09\u4e2d\u7684\u5e94\u7528\uff0c\u5c55\u793a\u4e86\u57fa\u4e8e\u795e\u7ecf\u7b97\u5b50\u7684\u65b9\u6cd5\u5728\u5feb\u901f\u9884\u6d4b\u548c\u63a7\u5236\u590d\u6742\u6d41\u4f53\u52a8\u529b\u5b66\u8fc7\u7a0b\u4e2d\u7684\u6f5c\u529b\u3002\",\n  \"motivation\": \"\u5f53\u524d\u8ba1\u7b97\u6d41\u4f53\u52a8\u529b\u5b66\uff08CFD\uff09\u6a21\u578b\u5728\u591a\u76f8\u6d41\u95ee\u9898\u4e2d\uff0c\u7279\u522b\u662f\u6d89\u53ca\u5927\u5bc6\u5ea6\u68af\u5ea6\u6216\u76f8\u53d8\u65f6\uff0c\u9884\u6d4b\u901f\u5ea6\u4e0d\u8db3\u4ee5\u6ee1\u8db3\u5feb\u901f\u5de5\u4e1a\u5e94\u7528\u7684\u9700\u6c42\u3002\",\n  \"method\": \"\u7814\u7a76\u91c7\u7528\u795e\u7ecf\u7b97\u5b50\uff0c\u901a\u8fc7\u5b9e\u9a8c\u6570\u636e\u6216\u6a21\u62df\u6570\u636e\u8fdb\u884c\u8bad\u7ec3\uff0c\u7279\u522b\u5173\u6ce8\u6db2-\u6c7d\u754c\u9762\u7684\u4f53\u79ef\u6d41\u4f53\u6a21\u62df\u3002\",\n  \"result\": \"\u795e\u7ecf\u7b97\u5b50\u5728\u9884\u6d4b\u6db2-\u6c7d\u754c\u9762\u6f14\u53d8\u65b9\u9762\u8868\u73b0\u51fa\u9ad8\u7cbe\u5ea6\uff0c\u8bc1\u5b9e\u5176\u53ef\u7528\u4e8e\u9700\u8981\u5feb\u901f\u54cd\u5e94\u7684\u591a\u76f8\u6d41\u8fc7\u7a0b\u63a7\u5236\u3002\",\n  \"conclusion\": \"\u795e\u7ecf\u7b97\u5b50\u4e3a\u591a\u76f8\u6d41\u95ee\u9898\u7684\u5feb\u901f\u9884\u6d4b\u548c\u63a7\u5236\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u65b9\u6cd5\uff0c\u7279\u522b\u662f\u5728\u5904\u7406\u590d\u6742\u754c\u9762\u52a8\u6001\u65f6\u3002\"\n}\n```", "additional_kwargs": {"refusal": null}, "response_metadata": {"token_usage": {"completion_tokens": 184, "prompt_tokens": 548, "total_tokens": 732, "completion_tokens_details": null, "prompt_tokens_details": null}, "model_name": "deepseek/deepseek-chat-v3-0324:free", "system_fingerprint": null, "id": "gen-1747817749-I5H1BGSQY8tr2u7el1sN", "finish_reason": "stop", "logprobs": null}, "type": "ai", "name": null, "id": "run-2073a574-32d6-43c0-9ed2-f06991521605-0", "example": false, "tool_calls": [], "invalid_tool_calls": [], "usage_metadata": {"input_tokens": 548, "output_tokens": 184, "total_tokens": 732, "input_token_details": {}, "output_token_details": {}}}}
{"id": "2505.13500", "pdf": "https://arxiv.org/pdf/2505.13500", "abs": "https://arxiv.org/abs/2505.13500", "authors": ["Prithviraj Singh Shahani", "Matthias Scheutz"], "title": "Noise Injection Systemically Degrades Large Language Model Safety Guardrails", "categories": ["cs.CL", "cs.AI"], "comment": "9 pages,3 figures", "summary": "Safety guardrails in large language models (LLMs) are a critical component in\npreventing harmful outputs. Yet, their resilience under perturbation remains\npoorly understood. In this paper, we investigate the robustness of safety\nfine-tuning in LLMs by systematically injecting Gaussian noise into model\nactivations. We show across multiple open-weight models that (1) Gaussian noise\nraises harmful-output rates (p < 0.001) by up to 27%, (2) that deeper safety\nfine-tuning affords no extra protection, and (3) that chain-of-thought\nreasoning remains largely intact. The findings reveal critical vulnerabilities\nin current safety alignment techniques and highlight the potential of\nreasoning-based and reinforcement learning approaches as promising direction\nfor developing more robust AI safety systems. These results have important\nimplications for real-world deployment of LLMs in safety-critical applications\nas these results imply that widely-deployed safety tuning methods can fail even\nwithout adversarial prompts.", "AI": {"content": "```json\n{\n  \"tldr\": \"\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4e2d\u5b89\u5168\u9632\u62a4\u680f\u7684\u9c81\u68d2\u6027\uff0c\u53d1\u73b0\u901a\u8fc7\u5411\u6a21\u578b\u6fc0\u6d3b\u4e2d\u6ce8\u5165\u9ad8\u65af\u566a\u58f0\u53ef\u4ee5\u663e\u8457\u589e\u52a0\u6709\u5bb3\u8f93\u51fa\u7387\uff0c\u4e14\u5f53\u524d\u7684\u5b89\u5168\u5bf9\u9f50\u6280\u672f\u5b58\u5728\u5173\u952e\u6f0f\u6d1e\u3002\",\n  \"motivation\": \"\u8bba\u6587\u7684\u52a8\u673a\u662f\u63a2\u7d22\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4e2d\u5b89\u5168\u9632\u62a4\u680f\u5728\u6270\u52a8\u4e0b\u7684\u9c81\u68d2\u6027\uff0c\u4ee5\u4e86\u89e3\u5f53\u524d\u5b89\u5168\u5fae\u8c03\u6280\u672f\u7684\u6709\u6548\u6027\u53ca\u5176\u6f5c\u5728\u6f0f\u6d1e\u3002\",\n  \"method\": \"\u8bba\u6587\u901a\u8fc7\u5411\u6a21\u578b\u6fc0\u6d3b\u4e2d\u7cfb\u7edf\u5730\u6ce8\u5165\u9ad8\u65af\u566a\u58f0\uff0c\u6d4b\u8bd5\u4e86\u591a\u4e2a\u5f00\u6e90\u6a21\u578b\u7684\u5b89\u5168\u5fae\u8c03\u9c81\u68d2\u6027\u3002\",\n  \"result\": \"\u7814\u7a76\u53d1\u73b0\uff0c\u9ad8\u65af\u566a\u58f0\u53ef\u4ee5\u663e\u8457\u589e\u52a0\u6709\u5bb3\u8f93\u51fa\u7387\uff08\u9ad8\u8fbe27%\uff09\uff0c\u4e14\u66f4\u6df1\u7684\u5b89\u5168\u5fae\u8c03\u65e0\u6cd5\u63d0\u4f9b\u989d\u5916\u4fdd\u62a4\uff0c\u800c\u94fe\u5f0f\u63a8\u7406\u80fd\u529b\u57fa\u672c\u4e0d\u53d7\u5f71\u54cd\u3002\",\n  \"conclusion\": \"\u8bba\u6587\u7ed3\u8bba\u6307\u51fa\u5f53\u524d\u5b89\u5168\u5bf9\u9f50\u6280\u672f\u5b58\u5728\u5173\u952e\u6f0f\u6d1e\uff0c\u5e76\u5efa\u8bae\u57fa\u4e8e\u63a8\u7406\u548c\u5f3a\u5316\u5b66\u4e60\u7684\u65b9\u6cd5\u53ef\u80fd\u4e3a\u5f00\u53d1\u66f4\u9c81\u68d2\u7684AI\u5b89\u5168\u7cfb\u7edf\u63d0\u4f9b\u65b9\u5411\u3002\"\n}\n```", "additional_kwargs": {"refusal": null}, "response_metadata": {"token_usage": {"completion_tokens": 208, "prompt_tokens": 518, "total_tokens": 726, "completion_tokens_details": null, "prompt_tokens_details": null}, "model_name": "deepseek/deepseek-chat-v3-0324:free", "system_fingerprint": null, "id": "gen-1747817765-JgO9QlTFJlr9JzXxC26m", "finish_reason": "stop", "logprobs": null}, "type": "ai", "name": null, "id": "run-f7e42477-90b4-464c-8947-e540241c502a-0", "example": false, "tool_calls": [], "invalid_tool_calls": [], "usage_metadata": {"input_tokens": 518, "output_tokens": 208, "total_tokens": 726, "input_token_details": {}, "output_token_details": {}}}}
{"id": "2505.13511", "pdf": "https://arxiv.org/pdf/2505.13511", "abs": "https://arxiv.org/abs/2505.13511", "authors": ["David Noever", "Forrest McKee"], "title": "Can AI Freelancers Compete? Benchmarking Earnings, Reliability, and Task Success at Scale", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "This study explores Large Language Models (LLMs) as autonomous agents for\nreal-world tasks, including freelance software development. This work presents\na new benchmark that evaluates LLMs on freelance programming and data analysis\ntasks derived from economic data. We construct the benchmark using synthetic\ntasks created from a Kaggle Freelancer dataset of job postings, with all job\nprices standardized to USD (median fixed-project price around $250, and an\naverage of $306). Each task is accompanied by structured input-output test\ncases and an estimated price tag, enabling automated correctness checking and a\nmonetary performance valuation. This approach is inspired by OpenAI's recent\nSWE-Lancer benchmark (1,400 real Upwork tasks worth $1M total). Still, our\nframework simplifies evaluation using programmatically testable tasks and\npredicted price values, making it highly scalable and repeatable. On this\nbenchmark, we evaluate four modern LLMs - Claude 3.5 Haiku, GPT-4o-mini, Qwen\n2.5, and Mistral. We report each model's accuracy (task success rate and\ntest-case pass rate) and the total \"freelance earnings\" it achieves (sum of\nprices of solved tasks). Our results show that Claude 3.5 Haiku performs best,\nearning approximately $1.52 million USD, followed closely by GPT-4o-mini at\n$1.49 million, then Qwen 2.5 ($1.33M) and Mistral ($0.70M). We analyze the\ndistribution of errors per task and observe that the strongest models solve the\nmost tasks and rarely fail completely on any project. We discuss the\nimplications of these results for the feasibility of AI as a freelance\ndeveloper, the advantages and limitations of our automated benchmark approach,\nand the gap between performance on structured tasks versus the true complexity\nof real-world freelance jobs.", "AI": {"content": "```json\n{\n  \"tldr\": \"\u8be5\u7814\u7a76\u63a2\u8ba8\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4f5c\u4e3a\u81ea\u4e3b\u4ee3\u7406\u6267\u884c\u73b0\u5b9e\u4e16\u754c\u4efb\u52a1\uff08\u5305\u62ec\u81ea\u7531\u804c\u4e1a\u8f6f\u4ef6\u5f00\u53d1\uff09\u7684\u80fd\u529b\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u7684\u57fa\u51c6\u6765\u8bc4\u4f30LLM\u5728\u81ea\u7531\u804c\u4e1a\u7f16\u7a0b\u548c\u6570\u636e\u5206\u6790\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u3002\",\n  \"motivation\": \"\u7814\u7a76\u52a8\u673a\u662f\u8bc4\u4f30LLM\u5728\u81ea\u7531\u804c\u4e1a\u8f6f\u4ef6\u5f00\u53d1\u4efb\u52a1\u4e2d\u7684\u5b9e\u9645\u5e94\u7528\u80fd\u529b\uff0c\u4ee5\u4e86\u89e3AI\u662f\u5426\u80fd\u591f\u80dc\u4efb\u81ea\u7531\u804c\u4e1a\u5f00\u53d1\u8005\u7684\u5de5\u4f5c\u3002\",\n  \"method\": \"\u7814\u7a76\u65b9\u6cd5\u5305\u62ec\u6784\u5efa\u4e00\u4e2a\u57fa\u4e8e\u81ea\u7531\u804c\u4e1a\u4efb\u52a1\u7684\u65b0\u57fa\u51c6\uff0c\u4f7f\u7528\u6765\u81eaKaggle\u81ea\u7531\u804c\u4e1a\u8005\u6570\u636e\u96c6\u7684\u5408\u6210\u4efb\u52a1\uff0c\u6bcf\u4e2a\u4efb\u52a1\u90fd\u914d\u6709\u7ed3\u6784\u5316\u8f93\u5165\u8f93\u51fa\u6d4b\u8bd5\u7528\u4f8b\u548c\u4f30\u8ba1\u4ef7\u683c\uff0c\u4ee5\u5b9e\u73b0\u81ea\u52a8\u5316\u6b63\u786e\u6027\u68c0\u67e5\u548c\u8d27\u5e01\u5316\u6027\u80fd\u8bc4\u4f30\u3002\",\n  \"result\": \"\u7814\u7a76\u7ed3\u679c\u663e\u793a\uff0cClaude 3.5 Haiku\u8868\u73b0\u6700\u4f73\uff0c\u8d5a\u53d6\u4e86\u7ea6152\u4e07\u7f8e\u5143\uff0c\u5176\u6b21\u662fGPT-4o-mini\uff08149\u4e07\u7f8e\u5143\uff09\u3001Qwen 2.5\uff08133\u4e07\u7f8e\u5143\uff09\u548cMistral\uff0870\u4e07\u7f8e\u5143\uff09\u3002\u6700\u5f3a\u7684\u6a21\u578b\u80fd\u591f\u5b8c\u6210\u5927\u591a\u6570\u4efb\u52a1\uff0c\u5f88\u5c11\u5b8c\u5168\u5931\u8d25\u3002\",\n  \"conclusion\": \"\u7814\u7a76\u7ed3\u8bba\u662f\uff0cAI\u5728\u81ea\u7531\u804c\u4e1a\u5f00\u53d1\u9886\u57df\u5177\u6709\u4e00\u5b9a\u7684\u53ef\u884c\u6027\uff0c\u4f46\u81ea\u52a8\u5316\u57fa\u51c6\u65b9\u6cd5\u5b58\u5728\u5c40\u9650\u6027\uff0c\u7ed3\u6784\u5316\u4efb\u52a1\u7684\u8868\u73b0\u4e0e\u771f\u5b9e\u81ea\u7531\u804c\u4e1a\u5de5\u4f5c\u7684\u590d\u6742\u6027\u4e4b\u95f4\u4ecd\u6709\u5dee\u8ddd\u3002\"\n}\n```", "additional_kwargs": {"refusal": null}, "response_metadata": {"token_usage": {"completion_tokens": 252, "prompt_tokens": 717, "total_tokens": 969, "completion_tokens_details": null, "prompt_tokens_details": null}, "model_name": "deepseek/deepseek-chat-v3-0324:free", "system_fingerprint": null, "id": "gen-1747817775-2rIHV79gvLiBJASwMowE", "finish_reason": "stop", "logprobs": null}, "type": "ai", "name": null, "id": "run-d6a2485d-a757-4916-b530-9f3e9f26facf-0", "example": false, "tool_calls": [], "invalid_tool_calls": [], "usage_metadata": {"input_tokens": 717, "output_tokens": 252, "total_tokens": 969, "input_token_details": {}, "output_token_details": {}}}}
{"id": "2505.13471", "pdf": "https://arxiv.org/pdf/2505.13471", "abs": "https://arxiv.org/abs/2505.13471", "authors": ["George Bird"], "title": "The Spotlight Resonance Method: Resolving the Alignment of Embedded Activations", "categories": ["cs.LG", "I.2.6; I.5.1"], "comment": "25 pages, 13 figures, 2nd Workshop on Representational Alignment,\n  International Conference on Learning Representations (ICLR)", "summary": "Understanding how deep learning models represent data is currently difficult\ndue to the limited number of methodologies available. This paper demonstrates a\nversatile and novel visualisation tool for determining the axis alignment of\nembedded data at any layer in any deep learning model. In particular, it\nevaluates the distribution around planes defined by the network's privileged\nbasis vectors. This method provides both an atomistic and a holistic, intuitive\nmetric for interpreting the distribution of activations across all planes. It\nensures that both positive and negative signals contribute, treating the\nactivation vector as a whole. Depending on the application, several variations\nof this technique are presented, with a resolution scale hyperparameter to\nprobe different angular scales. Using this method, multiple examples are\nprovided that demonstrate embedded representations tend to be axis-aligned with\nthe privileged basis. This is not necessarily the standard basis, and it is\nfound that activation functions directly result in privileged bases. Hence, it\nprovides a direct causal link between functional form symmetry breaking and\nrepresentational alignment, explaining why representations have a tendency to\nalign with the neuron basis. Therefore, using this method, we begin to answer\nthe fundamental question of what causes the observed tendency of\nrepresentations to align with neurons. Finally, examples of so-called\ngrandmother neurons are found in a variety of networks.", "AI": {"content": "```json\n{\n  \"tldr\": \"\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u53ef\u89c6\u5316\u5de5\u5177\uff0c\u7528\u4e8e\u5206\u6790\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u4e2d\u6570\u636e\u5d4c\u5165\u7684\u8f74\u5bf9\u9f50\u60c5\u51b5\uff0c\u63ed\u793a\u4e86\u6fc0\u6d3b\u51fd\u6570\u5982\u4f55\u5bfc\u81f4\u7279\u6743\u57fa\u7684\u5f62\u6210\uff0c\u5e76\u89e3\u91ca\u4e86\u6570\u636e\u8868\u793a\u503e\u5411\u4e8e\u4e0e\u795e\u7ecf\u5143\u57fa\u5bf9\u9f50\u7684\u539f\u56e0\u3002\",\n  \"motivation\": \"\u5f53\u524d\u7406\u89e3\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5982\u4f55\u8868\u793a\u6570\u636e\u7684\u65b9\u6cd5\u6709\u9650\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u65b0\u7684\u5de5\u5177\u6765\u53ef\u89c6\u5316\u5206\u6790\u6570\u636e\u5d4c\u5165\u7684\u8f74\u5bf9\u9f50\u60c5\u51b5\uff0c\u4ee5\u66f4\u597d\u5730\u7406\u89e3\u6a21\u578b\u7684\u5185\u90e8\u8868\u793a\u673a\u5236\u3002\",\n  \"method\": \"\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u53ef\u89c6\u5316\u5de5\u5177\uff0c\u901a\u8fc7\u8bc4\u4f30\u6570\u636e\u5728\u7279\u6743\u57fa\u5411\u91cf\u5b9a\u4e49\u7684\u5e73\u9762\u4e0a\u7684\u5206\u5e03\uff0c\u5206\u6790\u6570\u636e\u5d4c\u5165\u7684\u8f74\u5bf9\u9f50\u60c5\u51b5\uff0c\u5e76\u63d0\u4f9b\u4e86\u591a\u79cd\u6280\u672f\u53d8\u4f53\u4ee5\u9002\u5e94\u4e0d\u540c\u5e94\u7528\u9700\u6c42\u3002\",\n  \"result\": \"\u7814\u7a76\u53d1\u73b0\uff0c\u6570\u636e\u5d4c\u5165\u503e\u5411\u4e8e\u4e0e\u7279\u6743\u57fa\u5bf9\u9f50\uff0c\u800c\u975e\u6807\u51c6\u57fa\uff0c\u4e14\u6fc0\u6d3b\u51fd\u6570\u76f4\u63a5\u5bfc\u81f4\u4e86\u7279\u6743\u57fa\u7684\u5f62\u6210\uff0c\u4ece\u800c\u89e3\u91ca\u4e86\u6570\u636e\u8868\u793a\u4e0e\u795e\u7ecf\u5143\u57fa\u5bf9\u9f50\u7684\u73b0\u8c61\u3002\",\n  \"conclusion\": \"\u8be5\u7814\u7a76\u63ed\u793a\u4e86\u6fc0\u6d3b\u51fd\u6570\u5982\u4f55\u901a\u8fc7\u5f62\u6210\u7279\u6743\u57fa\u5f71\u54cd\u6570\u636e\u8868\u793a\u7684\u5bf9\u9f50\uff0c\u4e3a\u7406\u89e3\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u7684\u5185\u90e8\u673a\u5236\u63d0\u4f9b\u4e86\u65b0\u7684\u89c6\u89d2\uff0c\u5e76\u53d1\u73b0\u4e86\u591a\u79cd\u7f51\u7edc\u4e2d\u7684\u201c\u7956\u6bcd\u795e\u7ecf\u5143\u201d\u73b0\u8c61\u3002\"\n}\n```", "additional_kwargs": {"refusal": null}, "response_metadata": {"token_usage": {"completion_tokens": 222, "prompt_tokens": 595, "total_tokens": 817, "completion_tokens_details": null, "prompt_tokens_details": null}, "model_name": "deepseek/deepseek-chat-v3-0324:free", "system_fingerprint": null, "id": "gen-1747817801-nVSc2wIe67us9aQCmItX", "finish_reason": "stop", "logprobs": null}, "type": "ai", "name": null, "id": "run-9f2316f6-4022-4d89-a559-0cc01e52ee66-0", "example": false, "tool_calls": [], "invalid_tool_calls": [], "usage_metadata": {"input_tokens": 595, "output_tokens": 222, "total_tokens": 817, "input_token_details": {}, "output_token_details": {}}}}
{"id": "2505.13506", "pdf": "https://arxiv.org/pdf/2505.13506", "abs": "https://arxiv.org/abs/2505.13506", "authors": ["Ruobing Yao", "Yifei Zhang", "Shuang Song", "Neng Gao", "Chenyang Tu"], "title": "EcoSafeRAG: Efficient Security through Context Analysis in Retrieval-Augmented Generation", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Retrieval-Augmented Generation (RAG) compensates for the static knowledge\nlimitations of Large Language Models (LLMs) by integrating external knowledge,\nproducing responses with enhanced factual correctness and query-specific\ncontextualization. However, it also introduces new attack surfaces such as\ncorpus poisoning at the same time. Most of the existing defense methods rely on\nthe internal knowledge of the model, which conflicts with the design concept of\nRAG. To bridge the gap, EcoSafeRAG uses sentence-level processing and\nbait-guided context diversity detection to identify malicious content by\nanalyzing the context diversity of candidate documents without relying on LLM\ninternal knowledge. Experiments show EcoSafeRAG delivers state-of-the-art\nsecurity with plug-and-play deployment, simultaneously improving clean-scenario\nRAG performance while maintaining practical operational costs (relatively\n1.2$\\times$ latency, 48\\%-80\\% token reduction versus Vanilla RAG).", "AI": {"content": "```json\n{\n  \"tldr\": \"EcoSafeRAG\u901a\u8fc7\u53e5\u5b50\u7ea7\u5904\u7406\u548c\u8bf1\u9975\u5f15\u5bfc\u7684\u4e0a\u4e0b\u6587\u591a\u6837\u6027\u68c0\u6d4b\uff0c\u5728\u4e0d\u4f9d\u8d56LLM\u5185\u90e8\u77e5\u8bc6\u7684\u60c5\u51b5\u4e0b\u8bc6\u522b\u6076\u610f\u5185\u5bb9\uff0c\u63d0\u4f9b\u9ad8\u6548RAG\u9632\u5fa1\u65b9\u6848\u3002\",\n  \"motivation\": \"\u73b0\u6709RAG\u9632\u5fa1\u65b9\u6cd5\u4f9d\u8d56\u6a21\u578b\u5185\u90e8\u77e5\u8bc6\uff0c\u4e0eRAG\u8bbe\u8ba1\u7406\u5ff5\u51b2\u7a81\uff0c\u9700\u5f00\u53d1\u4e0d\u4f9d\u8d56\u5185\u90e8\u77e5\u8bc6\u7684\u65b0\u578b\u9632\u5fa1\u673a\u5236\u3002\",\n  \"method\": \"\u91c7\u7528\u53e5\u5b50\u7ea7\u5904\u7406+\u8bf1\u9975\u5f15\u5bfc\u7684\u4e0a\u4e0b\u6587\u591a\u6837\u6027\u68c0\u6d4b\u6280\u672f\u5206\u6790\u5019\u9009\u6587\u6863\u7684\u4e0a\u4e0b\u6587\u591a\u6837\u6027\u3002\",\n  \"result\": \"\u5b9e\u9a8c\u663e\u793aEcoSafeRAG\u5728\u4fdd\u6301\u8fd0\u884c\u6548\u7387(\u5ef6\u8fdf1.2\u500d)\u7684\u540c\u65f6\uff0c\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u5b89\u5168\u6027\uff0c\u5e76\u51cf\u5c1148%-80%\u7684token\u6d88\u8017\u3002\",\n  \"conclusion\": \"EcoSafeRAG\u901a\u8fc7\u521b\u65b0\u68c0\u6d4b\u673a\u5236\uff0c\u5728\u4fdd\u969c\u5b89\u5168\u6027\u7684\u540c\u65f6\u7ef4\u6301RAG\u6027\u80fd\u4e0e\u6548\u7387\uff0c\u5b9e\u73b0\u4e86\u7406\u60f3\u5e73\u8861\u3002\"\n}\n```", "additional_kwargs": {"refusal": null}, "response_metadata": {"token_usage": {"completion_tokens": 185, "prompt_tokens": 518, "total_tokens": 703, "completion_tokens_details": null, "prompt_tokens_details": null}, "model_name": "deepseek/deepseek-chat-v3-0324:free", "system_fingerprint": null, "id": "gen-1747817810-rM1YlKAUEvE7B2tZT11p", "finish_reason": "stop", "logprobs": null}, "type": "ai", "name": null, "id": "run-950e3b98-35e4-4108-a34a-016220f95b4f-0", "example": false, "tool_calls": [], "invalid_tool_calls": [], "usage_metadata": {"input_tokens": 518, "output_tokens": 185, "total_tokens": 703, "input_token_details": {}, "output_token_details": {}}}}
{"id": "2505.13522", "pdf": "https://arxiv.org/pdf/2505.13522", "abs": "https://arxiv.org/abs/2505.13522", "authors": ["Nathalie Sanghikian", "Rafael Meirelles", "Rafael Martinelli", "Anand Subramanian"], "title": "A Heuristic Algorithm Based on Beam Search and Iterated Local Search for the Maritime Inventory Routing Problem", "categories": ["cs.AI", "math.OC"], "comment": null, "summary": "Maritime Inventory Routing Problem (MIRP) plays a crucial role in the\nintegration of global maritime commerce levels. However, there are still no\nwell-established methodologies capable of efficiently solving large MIRP\ninstances or their variants due to the high complexity of the problem. The\nadoption of exact methods, typically based on Mixed Integer Programming (MIP),\nfor daily operations is nearly impractical due to the CPU time required, as\nplanning must be executed multiple times while ensuring high-quality results\nwithin acceptable time limits. Non-MIP-based heuristics are less frequently\napplied due to the highly constrained nature of the problem, which makes even\nthe construction of an effective initial solution challenging. Papageorgiou et\nal. (2014) introduced a single-product MIRP as the foundation for MIRPLib,\naiming to provide a collection of publicly available benchmark instances.\nHowever, only a few studies that propose new methodologies have been published\nsince then. To encourage the use of MIRPLib and facilitate result comparisons,\nthis study presents a heuristic approach that does not rely on mathematical\noptimization techniques to solve a deterministic, finite-horizon,\nsingle-product MIRP. The proposed heuristic combines a variation of a Beam\nSearch algorithm with an Iterated Local Search procedure. Among the 72\ninstances tested, the developed methodology can improve the best-known solution\nfor ten instances within an acceptable CPU time.", "AI": {"content": "```json\n{\n  \"tldr\": \"\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4e0d\u4f9d\u8d56\u6570\u5b66\u4f18\u5316\u6280\u672f\u7684\u542f\u53d1\u5f0f\u65b9\u6cd5\uff0c\u7528\u4e8e\u89e3\u51b3\u786e\u5b9a\u6027\u7684\u3001\u6709\u9650\u65f6\u95f4\u8303\u56f4\u7684\u5355\u4ea7\u54c1\u6d77\u4e0a\u5e93\u5b58\u8def\u5f84\u95ee\u9898\uff0c\u901a\u8fc7\u7ed3\u5408\u6539\u8fdb\u7684\u675f\u641c\u7d22\u7b97\u6cd5\u548c\u8fed\u4ee3\u5c40\u90e8\u641c\u7d22\u8fc7\u7a0b\uff0c\u572872\u4e2a\u6d4b\u8bd5\u5b9e\u4f8b\u4e2d\u6539\u8fdb\u4e8610\u4e2a\u5b9e\u4f8b\u7684\u6700\u4f18\u89e3\u3002\",\n  \"motivation\": \"\u6d77\u4e0a\u5e93\u5b58\u8def\u5f84\u95ee\u9898\uff08MIRP\uff09\u5728\u5168\u7403\u6d77\u4e0a\u8d38\u6613\u6574\u5408\u4e2d\u8d77\u7740\u5173\u952e\u4f5c\u7528\uff0c\u4f46\u7531\u4e8e\u95ee\u9898\u7684\u9ad8\u5ea6\u590d\u6742\u6027\uff0c\u76ee\u524d\u4ecd\u7f3a\u4e4f\u80fd\u591f\u9ad8\u6548\u89e3\u51b3\u5927\u89c4\u6a21MIRP\u6216\u5176\u53d8\u4f53\u7684\u6210\u719f\u65b9\u6cd5\u3002\u4f20\u7edf\u7684\u57fa\u4e8e\u6df7\u5408\u6574\u6570\u89c4\u5212\uff08MIP\uff09\u7684\u7cbe\u786e\u65b9\u6cd5\u56e0\u8ba1\u7b97\u65f6\u95f4\u8fc7\u957f\u800c\u96be\u4ee5\u5e94\u7528\u4e8e\u65e5\u5e38\u64cd\u4f5c\uff0c\u800c\u975eMIP\u542f\u53d1\u5f0f\u65b9\u6cd5\u7531\u4e8e\u95ee\u9898\u7684\u9ad8\u5ea6\u7ea6\u675f\u6027\uff0c\u6784\u5efa\u6709\u6548\u7684\u521d\u59cb\u89e3\u4e5f\u6781\u5177\u6311\u6218\u6027\u3002\u672c\u6587\u65e8\u5728\u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u542f\u53d1\u5f0f\u65b9\u6cd5\uff0c\u4ee5\u4fc3\u8fdbMIRPLib\u7684\u4f7f\u7528\u548c\u7ed3\u679c\u6bd4\u8f83\u3002\",\n  \"method\": \"\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u542f\u53d1\u5f0f\u65b9\u6cd5\uff0c\u7ed3\u5408\u4e86\u6539\u8fdb\u7684\u675f\u641c\u7d22\u7b97\u6cd5\u548c\u8fed\u4ee3\u5c40\u90e8\u641c\u7d22\u8fc7\u7a0b\uff0c\u7528\u4e8e\u89e3\u51b3\u786e\u5b9a\u6027\u7684\u3001\u6709\u9650\u65f6\u95f4\u8303\u56f4\u7684\u5355\u4ea7\u54c1\u6d77\u4e0a\u5e93\u5b58\u8def\u5f84\u95ee\u9898\u3002\u8be5\u65b9\u6cd5\u4e0d\u4f9d\u8d56\u6570\u5b66\u4f18\u5316\u6280\u672f\uff0c\u65e8\u5728\u9ad8\u6548\u5730\u627e\u5230\u9ad8\u8d28\u91cf\u7684\u89e3\u3002\",\n  \"result\": \"\u572872\u4e2a\u6d4b\u8bd5\u5b9e\u4f8b\u4e2d\uff0c\u672c\u6587\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u53ef\u63a5\u53d7\u7684CPU\u65f6\u95f4\u5185\u6539\u8fdb\u4e8610\u4e2a\u5b9e\u4f8b\u7684\u6700\u4f18\u89e3\uff0c\u5c55\u793a\u4e86\u5176\u5728\u89e3\u51b3MIRP\u95ee\u9898\u4e0a\u7684\u6709\u6548\u6027\u3002\",\n  \"conclusion\": \"\u672c\u6587\u63d0\u51fa\u7684\u542f\u53d1\u5f0f\u65b9\u6cd5\u5728\u89e3\u51b3\u5355\u4ea7\u54c1\u6d77\u4e0a\u5e93\u5b58\u8def\u5f84\u95ee\u9898\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u80fd\u591f\u5728\u5408\u7406\u65f6\u95f4\u5185\u6539\u8fdb\u591a\u4e2a\u5b9e\u4f8b\u7684\u6700\u4f18\u89e3\uff0c\u4e3aMIRP\u95ee\u9898\u7684\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u7684\u601d\u8def\u548c\u5de5\u5177\u3002\"\n}\n```", "additional_kwargs": {"refusal": null}, "response_metadata": {"token_usage": {"completion_tokens": 320, "prompt_tokens": 614, "total_tokens": 934, "completion_tokens_details": null, "prompt_tokens_details": null}, "model_name": "deepseek/deepseek-chat-v3-0324:free", "system_fingerprint": null, "id": "gen-1747817815-rd5NiYoWupwwRh82fLzQ", "finish_reason": "stop", "logprobs": null}, "type": "ai", "name": null, "id": "run-f0801e16-3e0c-4d45-a628-4c411cca5b19-0", "example": false, "tool_calls": [], "invalid_tool_calls": [], "usage_metadata": {"input_tokens": 614, "output_tokens": 320, "total_tokens": 934, "input_token_details": {}, "output_token_details": {}}}}
{"id": "2505.13499", "pdf": "https://arxiv.org/pdf/2505.13499", "abs": "https://arxiv.org/abs/2505.13499", "authors": ["Kelvin Kan", "Xingjian Li", "Benjamin J. Zhang", "Tuhin Sahai", "Stanley Osher", "Markos A. Katsoulakis"], "title": "Optimal Control for Transformer Architectures: Enhancing Generalization, Robustness and Efficiency", "categories": ["cs.LG", "cs.AI", "math.OC"], "comment": null, "summary": "We study Transformers through the perspective of optimal control theory,\nusing tools from continuous-time formulations to derive actionable insights\ninto training and architecture design. This framework improves the performance\nof existing Transformer models while providing desirable theoretical\nguarantees, including generalization and robustness. Our framework is designed\nto be plug-and-play, enabling seamless integration with established Transformer\nmodels and requiring only slight changes to the implementation. We conduct\nseven extensive experiments on tasks motivated by text generation, sentiment\nanalysis, image classification, and point cloud classification. Experimental\nresults show that the framework improves the test performance of the baselines,\nwhile being more parameter-efficient. On character-level text generation with\nnanoGPT, our framework achieves a 46% reduction in final test loss while using\n42% fewer parameters. On GPT-2, our framework achieves a 5.6% reduction in\nfinal test loss, demonstrating scalability to larger models. To the best of our\nknowledge, this is the first work that applies optimal control theory to both\nthe training and architecture of Transformers. It offers a new foundation for\nsystematic, theory-driven improvements and moves beyond costly trial-and-error\napproaches.", "AI": {"content": "```json\n{\n  \"tldr\": \"\u8be5\u8bba\u6587\u901a\u8fc7\u6700\u4f18\u63a7\u5236\u7406\u8bba\u4f18\u5316Transformer\u6a21\u578b\uff0c\u63d0\u5347\u6027\u80fd\u4e14\u53c2\u6570\u6548\u7387\u66f4\u9ad8\u3002\",\n  \"motivation\": \"\u7814\u7a76\u5982\u4f55\u5229\u7528\u6700\u4f18\u63a7\u5236\u7406\u8bba\u6539\u8fdbTransformer\u7684\u8bad\u7ec3\u548c\u67b6\u6784\u8bbe\u8ba1\uff0c\u51cf\u5c11\u8bd5\u9519\u6210\u672c\u3002\",\n  \"method\": \"\u91c7\u7528\u8fde\u7eed\u65f6\u95f4\u516c\u5f0f\u7684\u6700\u4f18\u63a7\u5236\u5de5\u5177\uff0c\u8bbe\u8ba1\u5373\u63d2\u5373\u7528\u7684\u6846\u67b6\uff0c\u4ec5\u9700\u5fae\u8c03\u5b9e\u73b0\u3002\",\n  \"result\": \"\u5b9e\u9a8c\u663e\u793a\uff0c\u8be5\u6846\u67b6\u663e\u8457\u964d\u4f4e\u6d4b\u8bd5\u635f\u5931\uff08\u5982nanoGPT\u51cf\u5c1146%\uff09\u4e14\u53c2\u6570\u66f4\u5c11\uff08\u51cf\u5c1142%\uff09\u3002\",\n  \"conclusion\": \"\u9996\u6b21\u5c06\u6700\u4f18\u63a7\u5236\u7406\u8bba\u5e94\u7528\u4e8eTransformer\uff0c\u4e3a\u7406\u8bba\u9a71\u52a8\u7684\u6539\u8fdb\u63d0\u4f9b\u4e86\u65b0\u57fa\u7840\u3002\"\n}\n```", "additional_kwargs": {"refusal": null}, "response_metadata": {"token_usage": {"completion_tokens": 141, "prompt_tokens": 562, "total_tokens": 703, "completion_tokens_details": null, "prompt_tokens_details": null}, "model_name": "deepseek/deepseek-chat-v3-0324:free", "system_fingerprint": null, "id": "gen-1747817830-VVWosxa6xxleehsbnORK", "finish_reason": "stop", "logprobs": null}, "type": "ai", "name": null, "id": "run-c2d14333-d2d4-44a9-80c9-1665df34a674-0", "example": false, "tool_calls": [], "invalid_tool_calls": [], "usage_metadata": {"input_tokens": 562, "output_tokens": 141, "total_tokens": 703, "input_token_details": {}, "output_token_details": {}}}}
{"id": "2505.13508", "pdf": "https://arxiv.org/pdf/2505.13508", "abs": "https://arxiv.org/abs/2505.13508", "authors": ["Zijia Liu", "Peixuan Han", "Haofei Yu", "Haoru Li", "Jiaxuan You"], "title": "Time-R1: Towards Comprehensive Temporal Reasoning in LLMs", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Large Language Models (LLMs) demonstrate impressive capabilities but lack\nrobust temporal intelligence, struggling to integrate reasoning about the past\nwith predictions and plausible generations of the future. Meanwhile, existing\nmethods typically target isolated temporal skills, such as question answering\nabout past events or basic forecasting, and exhibit poor generalization,\nparticularly when dealing with events beyond their knowledge cutoff or\nrequiring creative foresight. To address these limitations, we introduce\n\\textit{Time-R1}, the first framework to endow a moderate-sized (3B-parameter)\nLLM with comprehensive temporal abilities: understanding, prediction, and\ncreative generation. Our approach features a novel three-stage development\npath; the first two constitute a \\textit{reinforcement learning (RL)\ncurriculum} driven by a meticulously designed dynamic rule-based reward system.\nThis framework progressively builds (1) foundational temporal understanding and\nlogical event-time mappings from historical data, (2) future event prediction\nskills for events beyond its knowledge cutoff, and finally (3) enables\nremarkable generalization to creative future scenario generation without any\nfine-tuning. Strikingly, experiments demonstrate that Time-R1 outperforms\nmodels over 200 times larger, including the state-of-the-art 671B DeepSeek-R1,\non highly challenging future event prediction and creative scenario generation\nbenchmarks. This work provides strong evidence that thoughtfully engineered,\nprogressive RL fine-tuning allows smaller, efficient models to achieve superior\ntemporal performance, offering a practical and scalable path towards truly\ntime-aware AI. To foster further research, we also release \\textit{Time-Bench},\na large-scale multi-task temporal reasoning dataset derived from 10 years of\nnews data, and our series of \\textit{Time-R1} checkpoints.", "AI": {"content": "```json\n{\n  \"tldr\": \"Time-R1\u6846\u67b6\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u8bfe\u7a0b\u8d4b\u4e88\u5c0f\u578bLLM\u5168\u9762\u7684\u65f6\u95f4\u80fd\u529b\uff0c\u5728\u65f6\u95f4\u7406\u89e3\u548c\u672a\u6765\u9884\u6d4b\u4e0a\u8d85\u8d8a\u5927\u6a21\u578b\u3002\",\n  \"motivation\": \"\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u5728\u65f6\u95f4\u667a\u80fd\u65b9\u9762\u8868\u73b0\u4e0d\u8db3\uff0c\u96be\u4ee5\u6574\u5408\u8fc7\u53bb\u63a8\u7406\u4e0e\u672a\u6765\u9884\u6d4b\u53ca\u521b\u9020\u6027\u751f\u6210\u3002\u73b0\u6709\u65b9\u6cd5\u901a\u5e38\u53ea\u9488\u5bf9\u5355\u4e00\u65f6\u95f4\u6280\u80fd\uff0c\u4e14\u6cdb\u5316\u80fd\u529b\u5dee\u3002\",\n  \"method\": \"\u63d0\u51faTime-R1\u6846\u67b6\uff0c\u901a\u8fc7\u4e09\u9636\u6bb5\u5f3a\u5316\u5b66\u4e60\u8bfe\u7a0b\uff08\u57fa\u4e8e\u52a8\u6001\u89c4\u5219\u5956\u52b1\u7cfb\u7edf\uff09\u9010\u6b65\u6784\u5efa\u65f6\u95f4\u7406\u89e3\u3001\u672a\u6765\u4e8b\u4ef6\u9884\u6d4b\u548c\u521b\u9020\u6027\u573a\u666f\u751f\u6210\u80fd\u529b\u3002\",\n  \"result\": \"Time-R1\u5728\u590d\u6742\u672a\u6765\u4e8b\u4ef6\u9884\u6d4b\u548c\u521b\u9020\u6027\u573a\u666f\u751f\u6210\u4efb\u52a1\u4e0a\u8868\u73b0\u4f18\u4e8e\u53c2\u6570\u91cf\u5927200\u500d\u7684\u6a21\u578b\uff08\u5982671B\u7684DeepSeek-R1\uff09\u3002\",\n  \"conclusion\": \"\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u6e10\u8fdb\u5f0f\u5f3a\u5316\u5b66\u4e60\u5fae\u8c03\u53ef\u4f7f\u5c0f\u578b\u9ad8\u6548\u6a21\u578b\u83b7\u5f97\u5353\u8d8a\u65f6\u95f4\u667a\u80fd\uff0c\u4e3a\u65f6\u95f4\u611f\u77e5AI\u63d0\u4f9b\u4e86\u5b9e\u7528\u3001\u53ef\u6269\u5c55\u7684\u8def\u5f84\u3002\"\n}\n```", "additional_kwargs": {"refusal": null}, "response_metadata": {"token_usage": {"completion_tokens": 200, "prompt_tokens": 680, "total_tokens": 880, "completion_tokens_details": null, "prompt_tokens_details": null}, "model_name": "deepseek/deepseek-chat-v3-0324:free", "system_fingerprint": null, "id": "gen-1747817833-Z3KD4IekHrqg2iBK7jYc", "finish_reason": "stop", "logprobs": null}, "type": "ai", "name": null, "id": "run-fe2ba65d-ec31-433e-ad57-e21fda77f626-0", "example": false, "tool_calls": [], "invalid_tool_calls": [], "usage_metadata": {"input_tokens": 680, "output_tokens": 200, "total_tokens": 880, "input_token_details": {}, "output_token_details": {}}}}
{"id": "2505.13529", "pdf": "https://arxiv.org/pdf/2505.13529", "abs": "https://arxiv.org/abs/2505.13529", "authors": ["Junxiao Yang", "Jinzhe Tu", "Haoran Liu", "Xiaoce Wang", "Chujie Zheng", "Zhexin Zhang", "Shiyao Cui", "Caishun Chen", "Tiantian He", "Hongning Wang", "Yew-Soon Ong", "Minlie Huang"], "title": "BARREL: Boundary-Aware Reasoning for Factual and Reliable LRMs", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "Recent advances in Large Reasoning Models (LRMs) have shown impressive\ncapabilities in mathematical and logical reasoning. However, current LRMs\nrarely admit ignorance or respond with \"I don't know\". Instead, they often\nproduce incorrect answers while showing undue confidence, raising concerns\nabout their factual reliability. In this work, we identify two pathological\nreasoning patterns characterized by overthinking that contribute to the\noverconfident and incorrect answers: last-minute guessing and second-thought\nspiraling. To address these issues, we propose BARREL-a novel framework that\npromotes concise and boundary-aware factual reasoning. Our experiments show\nthat BARREL-training increases the reliability of DeepSeek-R1-Distill-Llama-8B\nfrom 39.33% to 61.48%, while still achieving accuracy comparable to models\nfinetuned on reasoning data generated by R1. These results demonstrate that our\npilot study is inspiring to build more reliable and factual System 2 LRMs.", "AI": {"content": "```json\n{\n  \"tldr\": \"\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u6846\u67b6BARREL\uff0c\u65e8\u5728\u89e3\u51b3\u5927\u578b\u63a8\u7406\u6a21\u578b\uff08LRM\uff09\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u8fc7\u5ea6\u81ea\u4fe1\u548c\u9519\u8bef\u56de\u7b54\u7684\u95ee\u9898\uff0c\u901a\u8fc7\u8fb9\u754c\u611f\u77e5\u7684\u4e8b\u5b9e\u63a8\u7406\u63d0\u9ad8\u6a21\u578b\u53ef\u9760\u6027\u3002\",\n  \"motivation\": \"\u5f53\u524d\u5927\u578b\u63a8\u7406\u6a21\u578b\uff08LRM\uff09\u5728\u6570\u5b66\u548c\u903b\u8f91\u63a8\u7406\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5f80\u5f80\u7f3a\u4e4f\u5bf9\u81ea\u8eab\u4e0d\u786e\u5b9a\u6027\u7684\u8868\u8fbe\uff0c\u5bfc\u81f4\u8fc7\u5ea6\u81ea\u4fe1\u548c\u9519\u8bef\u56de\u7b54\u3002\u8bba\u6587\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u63d0\u9ad8\u6a21\u578b\u7684\u4e8b\u5b9e\u53ef\u9760\u6027\u3002\",\n  \"method\": \"\u8bba\u6587\u63d0\u51fa\u4e86BARREL\u6846\u67b6\uff0c\u901a\u8fc7\u4fc3\u8fdb\u7b80\u6d01\u548c\u8fb9\u754c\u611f\u77e5\u7684\u4e8b\u5b9e\u63a8\u7406\uff0c\u51cf\u5c11\u6a21\u578b\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u7684\u8fc7\u5ea6\u601d\u8003\u884c\u4e3a\uff0c\u5982\u6700\u540e\u4e00\u523b\u731c\u6d4b\u548c\u4e8c\u6b21\u601d\u8003\u87ba\u65cb\u3002\",\n  \"result\": \"\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cBARREL\u6846\u67b6\u5c06DeepSeek-R1-Distill-Llama-8B\u6a21\u578b\u7684\u53ef\u9760\u6027\u4ece39.33%\u63d0\u9ad8\u523061.48%\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u4e0e\u57fa\u4e8eR1\u751f\u6210\u63a8\u7406\u6570\u636e\u5fae\u8c03\u7684\u6a21\u578b\u76f8\u5f53\u7684\u51c6\u786e\u6027\u3002\",\n  \"conclusion\": \"\u8bba\u6587\u901a\u8fc7BARREL\u6846\u67b6\u6709\u6548\u63d0\u9ad8\u4e86\u5927\u578b\u63a8\u7406\u6a21\u578b\u7684\u4e8b\u5b9e\u53ef\u9760\u6027\uff0c\u4e3a\u6784\u5efa\u66f4\u53ef\u9760\u7684\u7cfb\u7edf2\u578bLRM\u63d0\u4f9b\u4e86\u542f\u53d1\u3002\"\n}\n```", "additional_kwargs": {"refusal": null}, "response_metadata": {"token_usage": {"completion_tokens": 227, "prompt_tokens": 527, "total_tokens": 754, "completion_tokens_details": null, "prompt_tokens_details": null}, "model_name": "deepseek/deepseek-chat-v3-0324:free", "system_fingerprint": null, "id": "gen-1747817839-u5v6q3m5sgIRDHAvRVFy", "finish_reason": "stop", "logprobs": null}, "type": "ai", "name": null, "id": "run-dc537e8b-6f85-4618-ae4b-565307885442-0", "example": false, "tool_calls": [], "invalid_tool_calls": [], "usage_metadata": {"input_tokens": 527, "output_tokens": 227, "total_tokens": 754, "input_token_details": {}, "output_token_details": {}}}}
{"id": "2505.13501", "pdf": "https://arxiv.org/pdf/2505.13501", "abs": "https://arxiv.org/abs/2505.13501", "authors": ["Zequn He", "Celia Reina"], "title": "SPIEDiff: robust learning of long-time macroscopic dynamics from short-time particle simulations with quantified epistemic uncertainty", "categories": ["cs.LG", "physics.comp-ph"], "comment": null, "summary": "The data-driven discovery of long-time macroscopic dynamics and\nthermodynamics of dissipative systems with particle fidelity is hampered by\nsignificant obstacles. These include the strong time-scale limitations inherent\nto particle simulations, the non-uniqueness of the thermodynamic potentials and\noperators from given macroscopic dynamics, and the need for efficient\nuncertainty quantification. This paper introduces Statistical-Physics Informed\nEpistemic Diffusion Models (SPIEDiff), a machine learning framework designed to\novercome these limitations in the context of purely dissipative systems by\nleveraging statistical physics, conditional diffusion models, and epinets. We\nevaluate the proposed framework on stochastic Arrhenius particle processes and\ndemonstrate that SPIEDiff can accurately uncover both thermodynamics and\nkinetics, while enabling reliable long-time macroscopic predictions using only\nshort-time particle simulation data. SPIEDiff can deliver accurate predictions\nwith quantified uncertainty in minutes, drastically reducing the computational\ndemand compared to direct particle simulations, which would take days or years\nin the examples considered. Overall, SPIEDiff offers a robust and trustworthy\npathway for the data-driven discovery of thermodynamic models.", "AI": {"content": "```json\n{\n  \"tldr\": \"\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aSPIEDiff\u7684\u673a\u5668\u5b66\u4e60\u6846\u67b6\uff0c\u65e8\u5728\u89e3\u51b3\u7eaf\u8017\u6563\u7cfb\u7edf\u4e2d\u6570\u636e\u9a71\u52a8\u53d1\u73b0\u957f\u671f\u5b8f\u89c2\u52a8\u529b\u5b66\u548c\u70ed\u529b\u5b66\u7684\u95ee\u9898\uff0c\u901a\u8fc7\u7ed3\u5408\u7edf\u8ba1\u7269\u7406\u3001\u6761\u4ef6\u6269\u6563\u6a21\u578b\u548cepinets\uff0c\u5b9e\u73b0\u4e86\u5bf9\u70ed\u529b\u5b66\u548c\u52a8\u529b\u5b66\u7684\u51c6\u786e\u9884\u6d4b\u3002\",\n  \"motivation\": \"\u8017\u6563\u7cfb\u7edf\u5728\u4fdd\u6301\u7c92\u5b50\u4fdd\u771f\u5ea6\u7684\u957f\u671f\u5b8f\u89c2\u52a8\u529b\u5b66\u548c\u70ed\u529b\u5b66\u7814\u7a76\u4e2d\u9762\u4e34\u65f6\u95f4\u5c3a\u5ea6\u9650\u5236\u3001\u70ed\u529b\u5b66\u52bf\u548c\u7b97\u5b50\u7684\u975e\u552f\u4e00\u6027\u4ee5\u53ca\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u6548\u7387\u4f4e\u7b49\u6311\u6218\uff0c\u9700\u8981\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002\",\n  \"method\": \"SPIEDiff\u6846\u67b6\u7ed3\u5408\u4e86\u7edf\u8ba1\u7269\u7406\u3001\u6761\u4ef6\u6269\u6563\u6a21\u578b\u548cepinets\uff0c\u4e13\u95e8\u9488\u5bf9\u7eaf\u8017\u6563\u7cfb\u7edf\u8bbe\u8ba1\uff0c\u80fd\u591f\u4ece\u77ed\u65f6\u95f4\u7c92\u5b50\u6a21\u62df\u6570\u636e\u4e2d\u51c6\u786e\u9884\u6d4b\u957f\u671f\u5b8f\u89c2\u884c\u4e3a\u3002\",\n  \"result\": \"\u5728\u968f\u673aArrhenius\u7c92\u5b50\u8fc7\u7a0b\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cSPIEDiff\u80fd\u591f\u51c6\u786e\u9884\u6d4b\u70ed\u529b\u5b66\u548c\u52a8\u529b\u5b66\uff0c\u5e76\u5728\u77ed\u65f6\u95f4\u5185\u63d0\u4f9b\u5e26\u6709\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u7684\u9884\u6d4b\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u8ba1\u7b97\u9700\u6c42\u3002\",\n  \"conclusion\": \"SPIEDiff\u4e3a\u70ed\u529b\u5b66\u6a21\u578b\u7684\u6570\u636e\u9a71\u52a8\u53d1\u73b0\u63d0\u4f9b\u4e86\u4e00\u6761\u53ef\u9760\u4e14\u9ad8\u6548\u7684\u9014\u5f84\uff0c\u5177\u6709\u5e7f\u6cdb\u7684\u5e94\u7528\u6f5c\u529b\u3002\"\n}\n```", "additional_kwargs": {"refusal": null}, "response_metadata": {"token_usage": {"completion_tokens": 235, "prompt_tokens": 552, "total_tokens": 787, "completion_tokens_details": null, "prompt_tokens_details": null}, "model_name": "deepseek/deepseek-chat-v3-0324:free", "system_fingerprint": null, "id": "gen-1747817853-9QG4f75myNiNCHmip5Rk", "finish_reason": "stop", "logprobs": null}, "type": "ai", "name": null, "id": "run-854fa2c9-79a3-4e1e-b97c-0bdaaef2e9b8-0", "example": false, "tool_calls": [], "invalid_tool_calls": [], "usage_metadata": {"input_tokens": 552, "output_tokens": 235, "total_tokens": 787, "input_token_details": {}, "output_token_details": {}}}}
{"id": "2505.13514", "pdf": "https://arxiv.org/pdf/2505.13514", "abs": "https://arxiv.org/abs/2505.13514", "authors": ["Shuxun Wang", "Qingyu Yin", "Chak Tou Leong", "Qiang Zhang", "Linyi Yang"], "title": "Induction Head Toxicity Mechanistically Explains Repetition Curse in Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Repetition curse is a phenomenon where Large Language Models (LLMs) generate\nrepetitive sequences of tokens or cyclic sequences. While the repetition curse\nhas been widely observed, its underlying mechanisms remain poorly understood.\nIn this work, we investigate the role of induction heads--a specific type of\nattention head known for their ability to perform in-context learning--in\ndriving this repetitive behavior. Specifically, we focus on the \"toxicity\" of\ninduction heads, which we define as their tendency to dominate the model's\noutput logits during repetition, effectively excluding other attention heads\nfrom contributing to the generation process. Our findings have important\nimplications for the design and training of LLMs. By identifying induction\nheads as a key driver of the repetition curse, we provide a mechanistic\nexplanation for this phenomenon and suggest potential avenues for mitigation.\nWe also propose a technique with attention head regularization that could be\nemployed to reduce the dominance of induction heads during generation, thereby\npromoting more diverse and coherent outputs.", "AI": {"content": "\n\n\n\n```json\n{\n  \"tldr\": \"\u672c\u6587\u63a2\u8ba8\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4e2d\u91cd\u590d\u751f\u6210\u91cd\u590d\u5e8f\u5217\u6216\u5faa\u73af\u5e8f\u5217\u7684\u73b0\u8c61\uff0c\u5373\u91cd\u590d\u8bc5\u5492\uff0c\u5e76\u7814\u7a76\u4e86\u8bf1\u5bfc\u5934\u5728\u9a71\u52a8\u8fd9\u79cd\u91cd\u590d\u884c\u4e3a\u4e2d\u7684\u4f5c\u7528\u3002\u901a\u8fc7\u5206\u6790\u8bf1\u5bfc\u5934\u7684\u6bd2\u6027\uff0c\u5373\u5176\u5728\u91cd\u590d\u8fc7\u7a0b\u4e2d\u4e3b\u5bfc\u6a21\u578b\u8f93\u51fa\u6982\u7387\u7684\u7279\u6027\uff0c\u63d0\u51fa\u4e86\u51cf\u5c11\u8bf1\u5bfc\u5934\u4e3b\u5bfc\u6027\u7684\u65b9\u6cd5\uff0c\u4ee5\u4fc3\u8fdb\u66f4\u591a\u6837\u5316\u548c\u8fde\u8d2f\u7684\u8f93\u51fa\u3002\",\n  \"motivation\": \"\u5c3d\u7ba1\u91cd\u590d\u8bc5\u5492\u73b0\u8c61\u5728\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u5e7f\u6cdb\u5b58\u5728\uff0c\u4f46\u5176\u5185\u5728\u673a\u5236\u5c1a\u4e0d\u660e\u786e\u3002\u672c\u7814\u7a76\u65e8\u5728\u63ed\u793a\u8bf1\u5bfc\u5934\u5728\u9a71\u52a8\u91cd\u590d\u884c\u4e3a\u4e2d\u7684\u5173\u952e\u4f5c\u7528\uff0c\u4ece\u800c\u4e3a\u7406\u89e3\u548c\u7f13\u89e3\u8fd9\u4e00\u73b0\u8c61\u63d0\u4f9b\u673a\u5236\u6027\u89e3\u91ca\u3002\",\n  \"method\": \"\u672c\u7814\u7a76\u901a\u8fc7\u5206\u6790\u8bf1\u5bfc\u5934\u7684\u6bd2\u6027\uff0c\u5373\u5176\u5728\u91cd\u590d\u751f\u6210\u8fc7\u7a0b\u4e2d\u4e3b\u5bfc\u6a21\u578b\u8f93\u51fa\u6982\u7387\u7684\u7279\u6027\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u6ce8\u610f\u529b\u5934\u6b63\u5219\u5316\u6280\u672f\uff0c\u4ee5\u51cf\u5c11\u8bf1\u5bfc\u5934\u5728\u751f\u6210\u8fc7\u7a0b\u4e2d\u7684\u4e3b\u5bfc\u6027\u3002\",\n  \"result\": \"\u7814\u7a76\u53d1\u73b0\u8bf1\u5bfc\u5934\u662f\u91cd\u590d\u8bc5\u5492\u7684\u4e3b\u8981\u9a71\u52a8\u56e0\u7d20\uff0c\u901a\u8fc7\u51cf\u5c11\u8bf1\u5bfc\u5934\u7684\u4e3b\u5bfc\u6027\uff0c\u53ef\u4ee5\u663e\u8457\u63d0\u9ad8\u6a21\u578b\u751f\u6210\u5185\u5bb9\u7684\u591a\u6837\u6027\u548c\u8fde\u8d2f\u6027\u3002\",\n  \"conclusion\": \"\u672c\u7814\u7a76\u63ed\u793a\u4e86\u8bf1\u5bfc\u5934\u5728\u5927\u578b\u8bed\u8a00\u6a21\u578b\u91cd\u590d\u751f\u6210\u884c\u4e3a\u4e2d\u7684\u5173\u952e\u4f5c\u7528\uff0c\u5e76\u63d0\u51fa\u4e86\u51cf\u5c11\u8bf1\u5bfc\u5934\u4e3b\u5bfc\u6027\u7684\u65b9\u6cd5\uff0c\u4e3a\u6539\u8fdb\u6a21\u578b\u751f\u6210\u8d28\u91cf\u63d0\u4f9b\u4e86\u65b0\u7684\u601d\u8def\u3002\"\n}\n```", "additional_kwargs": {"refusal": null}, "response_metadata": {"token_usage": {"completion_tokens": 247, "prompt_tokens": 530, "total_tokens": 777, "completion_tokens_details": null, "prompt_tokens_details": null}, "model_name": "deepseek/deepseek-chat-v3-0324:free", "system_fingerprint": null, "id": "gen-1747817890-MzlJyj6E0jpEGFgSwg1x", "finish_reason": "stop", "logprobs": null}, "type": "ai", "name": null, "id": "run-7c1f65ec-1983-4971-bccc-b2af16e3cd53-0", "example": false, "tool_calls": [], "invalid_tool_calls": [], "usage_metadata": {"input_tokens": 530, "output_tokens": 247, "total_tokens": 777, "input_token_details": {}, "output_token_details": {}}}}
{"id": "2505.13533", "pdf": "https://arxiv.org/pdf/2505.13533", "abs": "https://arxiv.org/abs/2505.13533", "authors": ["Junzhe Jiang", "Chang Yang", "Aixin Cui", "Sihan Jin", "Ruiyu Wang", "Bo Li", "Xiao Huang", "Dongning Sun", "Xinrun Wang"], "title": "FinMaster: A Holistic Benchmark for Mastering Full-Pipeline Financial Workflows with LLMs", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Financial tasks are pivotal to global economic stability; however, their\nexecution faces challenges including labor intensive processes, low error\ntolerance, data fragmentation, and tool limitations. Although large language\nmodels (LLMs) have succeeded in various natural language processing tasks and\nhave shown potential in automating workflows through reasoning and contextual\nunderstanding, current benchmarks for evaluating LLMs in finance lack\nsufficient domain-specific data, have simplistic task design, and incomplete\nevaluation frameworks. To address these gaps, this article presents FinMaster,\na comprehensive financial benchmark designed to systematically assess the\ncapabilities of LLM in financial literacy, accounting, auditing, and\nconsulting. Specifically, FinMaster comprises three main modules: i) FinSim,\nwhich builds simulators that generate synthetic, privacy-compliant financial\ndata for companies to replicate market dynamics; ii) FinSuite, which provides\ntasks in core financial domains, spanning 183 tasks of various types and\ndifficulty levels; and iii) FinEval, which develops a unified interface for\nevaluation. Extensive experiments over state-of-the-art LLMs reveal critical\ncapability gaps in financial reasoning, with accuracy dropping from over 90% on\nbasic tasks to merely 40% on complex scenarios requiring multi-step reasoning.\nThis degradation exhibits the propagation of computational errors, where\nsingle-metric calculations initially demonstrating 58% accuracy decreased to\n37% in multimetric scenarios. To the best of our knowledge, FinMaster is the\nfirst benchmark that covers full-pipeline financial workflows with challenging\ntasks. We hope that FinMaster can bridge the gap between research and industry\npractitioners, driving the adoption of LLMs in real-world financial practices\nto enhance efficiency and accuracy.", "AI": {"content": "```json\n{\n  \"tldr\": \"\u8be5\u8bba\u6587\u63d0\u51fa\u4e86FinMaster\uff0c\u4e00\u4e2a\u5168\u9762\u7684\u91d1\u878d\u57fa\u51c6\u6d4b\u8bd5\uff0c\u65e8\u5728\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u91d1\u878d\u9886\u57df\u7684\u5e94\u7528\u80fd\u529b\uff0c\u5305\u62ec\u91d1\u878d\u77e5\u8bc6\u3001\u4f1a\u8ba1\u3001\u5ba1\u8ba1\u548c\u54a8\u8be2\u7b49\u65b9\u9762\u3002\",\n  \"motivation\": \"\u91d1\u878d\u4efb\u52a1\u5bf9\u5168\u7403\u7ecf\u6d4e\u7a33\u5b9a\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u5176\u6267\u884c\u9762\u4e34\u8bf8\u591a\u6311\u6218\uff0c\u5982\u52b3\u52a8\u5bc6\u96c6\u578b\u6d41\u7a0b\u3001\u4f4e\u5bb9\u9519\u7387\u3001\u6570\u636e\u5206\u6563\u548c\u5de5\u5177\u9650\u5236\u3002\u5c3d\u7ba1\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u81ea\u7136\u8bed\u8a00\u5904\u7406\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u91d1\u878d\u9886\u57df\u7684\u5e94\u7528\u8bc4\u4f30\u57fa\u51c6\u5c1a\u4e0d\u5b8c\u5584\uff0c\u7f3a\u4e4f\u9886\u57df\u7279\u5b9a\u6570\u636e\u3001\u4efb\u52a1\u8bbe\u8ba1\u7b80\u5355\u4e14\u8bc4\u4f30\u6846\u67b6\u4e0d\u5b8c\u6574\u3002\",\n  \"method\": \"FinMaster\u5305\u62ec\u4e09\u4e2a\u4e3b\u8981\u6a21\u5757\uff1aFinSim\uff08\u751f\u6210\u7b26\u5408\u9690\u79c1\u8981\u6c42\u7684\u5408\u6210\u91d1\u878d\u6570\u636e\uff09\u3001FinSuite\uff08\u63d0\u4f9b\u6838\u5fc3\u91d1\u878d\u9886\u57df\u7684\u4efb\u52a1\uff09\u548cFinEval\uff08\u5f00\u53d1\u7edf\u4e00\u7684\u8bc4\u4f30\u63a5\u53e3\uff09\u3002\u901a\u8fc7\u8fd9\u4e09\u4e2a\u6a21\u5757\uff0c\u7cfb\u7edf\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u91d1\u878d\u9886\u57df\u7684\u8868\u73b0\u3002\",\n  \"result\": \"\u5b9e\u9a8c\u8868\u660e\uff0c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u91d1\u878d\u63a8\u7406\u80fd\u529b\u4e0a\u5b58\u5728\u663e\u8457\u5dee\u8ddd\uff0c\u4ece\u57fa\u7840\u4efb\u52a1\u768490%\u51c6\u786e\u7387\u4e0b\u964d\u5230\u9700\u8981\u591a\u6b65\u63a8\u7406\u7684\u590d\u6742\u573a\u666f\u768440%\u51c6\u786e\u7387\u3002\u591a\u6307\u6807\u573a\u666f\u4e0b\u7684\u51c6\u786e\u7387\u8fdb\u4e00\u6b65\u4e0b\u964d\uff0c\u663e\u793a\u51fa\u8ba1\u7b97\u9519\u8bef\u7684\u4f20\u64ad\u6548\u5e94\u3002\",\n  \"conclusion\": \"FinMaster\u662f\u9996\u4e2a\u8986\u76d6\u5168\u6d41\u7a0b\u91d1\u878d\u5de5\u4f5c\u6d41\u5e76\u5305\u542b\u9ad8\u96be\u5ea6\u4efb\u52a1\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u6709\u671b\u5f25\u5408\u7814\u7a76\u4e0e\u884c\u4e1a\u5b9e\u8df5\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u63a8\u52a8\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u91d1\u878d\u9886\u57df\u7684\u5b9e\u9645\u5e94\u7528\uff0c\u63d0\u5347\u6548\u7387\u548c\u51c6\u786e\u6027\u3002\"\n}\n```", "additional_kwargs": {"refusal": null}, "response_metadata": {"token_usage": {"completion_tokens": 285, "prompt_tokens": 671, "total_tokens": 956, "completion_tokens_details": null, "prompt_tokens_details": null}, "model_name": "deepseek/deepseek-chat-v3-0324:free", "system_fingerprint": null, "id": "gen-1747817898-pTmWhA9AcYWtWXmShf9R", "finish_reason": "stop", "logprobs": null}, "type": "ai", "name": null, "id": "run-c9321657-a09e-419b-bd27-284629520324-0", "example": false, "tool_calls": [], "invalid_tool_calls": [], "usage_metadata": {"input_tokens": 671, "output_tokens": 285, "total_tokens": 956, "input_token_details": {}, "output_token_details": {}}}}
{"id": "2505.13502", "pdf": "https://arxiv.org/pdf/2505.13502", "abs": "https://arxiv.org/abs/2505.13502", "authors": ["Yiyuan Yang", "Guodong Long", "Qinghua Lu", "Liming Zhu", "Jing Jiang", "Chengqi Zhang"], "title": "Federated Low-Rank Adaptation for Foundation Models: A Survey", "categories": ["cs.LG"], "comment": null, "summary": "Effectively leveraging private datasets remains a significant challenge in\ndeveloping foundation models. Federated Learning (FL) has recently emerged as a\ncollaborative framework that enables multiple users to fine-tune these models\nwhile mitigating data privacy risks. Meanwhile, Low-Rank Adaptation (LoRA)\noffers a resource-efficient alternative for fine-tuning foundation models by\ndramatically reducing the number of trainable parameters. This survey examines\nhow LoRA has been integrated into federated fine-tuning for foundation models,\nan area we term FedLoRA, by focusing on three key challenges: distributed\nlearning, heterogeneity, and efficiency. We further categorize existing work\nbased on the specific methods used to address each challenge. Finally, we\ndiscuss open research questions and highlight promising directions for future\ninvestigation, outlining the next steps for advancing FedLoRA.", "AI": {"content": "```json\n{\n  \"tldr\": \"\u8bba\u6587\u63a2\u8ba8\u4e86\u5982\u4f55\u901a\u8fc7\u7ed3\u5408\u8054\u90a6\u5b66\u4e60\uff08FL\uff09\u548c\u4f4e\u79e9\u9002\u5e94\uff08LoRA\uff09\u6280\u672f\uff08\u79f0\u4e3aFedLoRA\uff09\u6765\u9ad8\u6548\u3001\u9690\u79c1\u5b89\u5168\u5730\u5fae\u8c03\u57fa\u7840\u6a21\u578b\uff0c\u5e76\u5206\u6790\u4e86\u5206\u5e03\u5f0f\u5b66\u4e60\u3001\u5f02\u6784\u6027\u548c\u6548\u7387\u4e09\u4e2a\u5173\u952e\u6311\u6218\u3002\",\n  \"motivation\": \"\u79c1\u6709\u6570\u636e\u7684\u9ad8\u6548\u5229\u7528\u548c\u9690\u79c1\u4fdd\u62a4\u662f\u5f00\u53d1\u57fa\u7840\u6a21\u578b\u65f6\u7684\u91cd\u5927\u6311\u6218\u3002\u8054\u90a6\u5b66\u4e60\uff08FL\uff09\u548c\u4f4e\u79e9\u9002\u5e94\uff08LoRA\uff09\u7684\u7ed3\u5408\u4e3a\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u63d0\u4f9b\u4e86\u6f5c\u529b\u3002\",\n  \"method\": \"\u8bba\u6587\u7efc\u8ff0\u4e86\u5c06LoRA\u96c6\u6210\u5230\u8054\u90a6\u5fae\u8c03\uff08FedLoRA\uff09\u4e2d\u7684\u65b9\u6cd5\uff0c\u91cd\u70b9\u5173\u6ce8\u5206\u5e03\u5f0f\u5b66\u4e60\u3001\u5f02\u6784\u6027\u548c\u6548\u7387\u4e09\u5927\u6311\u6218\uff0c\u5e76\u5bf9\u73b0\u6709\u5de5\u4f5c\u8fdb\u884c\u5206\u7c7b\u3002\",\n  \"result\": \"\u63d0\u51fa\u4e86FedLoRA\u6846\u67b6\uff0c\u901a\u8fc7\u6574\u5408LoRA\u548cFL\u6280\u672f\uff0c\u6709\u6548\u51cf\u5c11\u4e86\u53ef\u8bad\u7ec3\u53c2\u6570\u6570\u91cf\uff0c\u540c\u65f6\u4fdd\u62a4\u4e86\u6570\u636e\u9690\u79c1\u3002\",\n  \"conclusion\": \"\u8bba\u6587\u5c55\u671b\u4e86FedLoRA\u7684\u672a\u6765\u7814\u7a76\u65b9\u5411\uff0c\u6307\u51fa\u4e86\u4ecd\u6709\u5f85\u89e3\u51b3\u7684\u5173\u952e\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u4e86\u8fdb\u4e00\u6b65\u53d1\u5c55\u7684\u6f5c\u529b\u65b9\u5411\u3002\"\n}\n```", "additional_kwargs": {"refusal": null}, "response_metadata": {"token_usage": {"completion_tokens": 210, "prompt_tokens": 494, "total_tokens": 704, "completion_tokens_details": null, "prompt_tokens_details": null}, "model_name": "deepseek/deepseek-chat-v3-0324:free", "system_fingerprint": null, "id": "gen-1747817913-G73swxp9eRbWh1EYs37a", "finish_reason": "stop", "logprobs": null}, "type": "ai", "name": null, "id": "run-63549e7a-fad7-4ce0-8f09-0899b18ceb4f-0", "example": false, "tool_calls": [], "invalid_tool_calls": [], "usage_metadata": {"input_tokens": 494, "output_tokens": 210, "total_tokens": 704, "input_token_details": {}, "output_token_details": {}}}}
{"id": "2505.13527", "pdf": "https://arxiv.org/pdf/2505.13527", "abs": "https://arxiv.org/abs/2505.13527", "authors": ["Jingyu Peng", "Maolin Wang", "Nan Wang", "Xiangyu Zhao", "Jiatong Li", "Kai Zhang", "Qi Liu"], "title": "Logic Jailbreak: Efficiently Unlocking LLM Safety Restrictions Through Formal Logical Expression", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Despite substantial advancements in aligning large language models (LLMs)\nwith human values, current safety mechanisms remain susceptible to jailbreak\nattacks. We hypothesize that this vulnerability stems from distributional\ndiscrepancies between alignment-oriented prompts and malicious prompts. To\ninvestigate this, we introduce LogiBreak, a novel and universal black-box\njailbreak method that leverages logical expression translation to circumvent\nLLM safety systems. By converting harmful natural language prompts into formal\nlogical expressions, LogiBreak exploits the distributional gap between\nalignment data and logic-based inputs, preserving the underlying semantic\nintent and readability while evading safety constraints. We evaluate LogiBreak\non a multilingual jailbreak dataset spanning three languages, demonstrating its\neffectiveness across various evaluation settings and linguistic contexts.", "AI": {"content": "```json\n{\n  \"tldr\": \"\u8bba\u6587\u63d0\u51faLogiBreak\u65b9\u6cd5\uff0c\u901a\u8fc7\u903b\u8f91\u8868\u8fbe\u5f0f\u7ffb\u8bd1\u7ed5\u8fc7\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5b89\u5168\u673a\u5236\uff0c\u5229\u7528\u5bf9\u9f50\u6570\u636e\u4e0e\u903b\u8f91\u8f93\u5165\u95f4\u7684\u5206\u5e03\u5dee\u5f02\u5b9e\u73b0\u8d8a\u72f1\u653b\u51fb\u3002\",\n  \"motivation\": \"\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5b89\u5168\u673a\u5236\u4ecd\u6613\u53d7\u8d8a\u72f1\u653b\u51fb\uff0c\u4f5c\u8005\u8ba4\u4e3a\u8fd9\u662f\u7531\u4e8e\u5bf9\u9f50\u63d0\u793a\u4e0e\u6076\u610f\u63d0\u793a\u95f4\u7684\u5206\u5e03\u5dee\u5f02\u6240\u81f4\u3002\",\n  \"method\": \"\u63d0\u51faLogiBreak\u2014\u2014\u4e00\u79cd\u57fa\u4e8e\u903b\u8f91\u8868\u8fbe\u5f0f\u7ffb\u8bd1\u7684\u9ed1\u76d2\u8d8a\u72f1\u65b9\u6cd5\uff0c\u5c06\u6709\u5bb3\u81ea\u7136\u8bed\u8a00\u63d0\u793a\u8f6c\u6362\u4e3a\u5f62\u5f0f\u903b\u8f91\u8868\u8fbe\u5f0f\u3002\",\n  \"result\": \"\u5728\u591a\u8bed\u8a00\u8d8a\u72f1\u6570\u636e\u96c6\u6d4b\u8bd5\u4e2d\uff0c\u8be5\u65b9\u6cd5\u5728\u4e0d\u540c\u8bed\u8a00\u73af\u5883\u53ca\u8bc4\u4f30\u8bbe\u7f6e\u4e0b\u5747\u8868\u73b0\u51fa\u8272\u3002\",\n  \"conclusion\": \"\u901a\u8fc7\u66b4\u9732\u903b\u8f91\u8f93\u5165\u4e0e\u5b89\u5168\u8bad\u7ec3\u6570\u636e\u95f4\u7684\u5206\u5e03\u5dee\u5f02\uff0cLogiBreak\u6709\u6548\u63ed\u793a\u4e86\u73b0\u6709\u5b89\u5168\u673a\u5236\u7684\u8106\u5f31\u6027\u3002\"\n}\n```", "additional_kwargs": {"refusal": null}, "response_metadata": {"token_usage": {"completion_tokens": 169, "prompt_tokens": 483, "total_tokens": 652, "completion_tokens_details": null, "prompt_tokens_details": null}, "model_name": "deepseek/deepseek-chat-v3-0324:free", "system_fingerprint": null, "id": "gen-1747817921-UY4nBww4DjSZ6YNNgRar", "finish_reason": "stop", "logprobs": null}, "type": "ai", "name": null, "id": "run-24702a9f-9d03-45e1-8eee-b920915456d7-0", "example": false, "tool_calls": [], "invalid_tool_calls": [], "usage_metadata": {"input_tokens": 483, "output_tokens": 169, "total_tokens": 652, "input_token_details": {}, "output_token_details": {}}}}
{"id": "2505.13546", "pdf": "https://arxiv.org/pdf/2505.13546", "abs": "https://arxiv.org/abs/2505.13546", "authors": ["Ke Chen", "Yufei Zhou", "Xitong Zhang", "Haohan Wang"], "title": "Prompt Stability Matters: Evaluating and Optimizing Auto-Generated Prompt in General-Purpose Systems", "categories": ["cs.AI", "cs.MA"], "comment": null, "summary": "Automatic prompt generation plays a crucial role in enabling general-purpose\nmulti-agent systems to perform diverse tasks autonomously. Existing methods\ntypically evaluate prompts based on their immediate task performance,\noverlooking the intrinsic qualities that determine their reliability. This\noutcome-centric view not only limits interpretability but also fails to account\nfor the inherent stochasticity of large language models (LLMs). In this work,\nwe bring attention to prompt stability-the consistency of model responses\nacross repeated executions-as a key factor for building robust and effective\nprompt generation systems. To quantify this, we propose semantic stability as a\ncriterion for assessing the response consistency of prompts, and fine-tune a\nLLaMA-based evaluator to measure it automatically across tasks. These\ncomponents have enabled us to develop the first stability-aware general-purpose\nprompt generation system that leverages stability feedback to iteratively\nenhance both prompt quality and system-level performance. Furthermore, we\nestablish a logical chain between prompt stability and task success by\nanalyzing the structural dependencies within our system, proving stability as a\nnecessary condition for effective system-level execution. Empirical results\nacross general and domain-specific tasks demonstrate that our stability-aware\nframework improves both accuracy and output consistency. By shifting the focus\nfrom one-off results to persistent reliability, our work offers a new\nperspective on prompt design and contributes practical tools for building more\ntrustworthy general-purpose systems.", "AI": {"content": "```json\n{\n  \"tldr\": \"\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8bed\u4e49\u7a33\u5b9a\u6027\u7684\u81ea\u52a8\u63d0\u793a\u751f\u6210\u7cfb\u7edf\uff0c\u901a\u8fc7\u8bc4\u4f30\u63d0\u793a\u7684\u7a33\u5b9a\u6027\u6765\u63d0\u5347\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u53ef\u9760\u6027\u548c\u6027\u80fd\u3002\",\n  \"motivation\": \"\u73b0\u6709\u7684\u81ea\u52a8\u63d0\u793a\u751f\u6210\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u4efb\u52a1\u7684\u5373\u65f6\u8868\u73b0\uff0c\u800c\u5ffd\u89c6\u4e86\u63d0\u793a\u7684\u7a33\u5b9a\u6027\uff0c\u8fd9\u9650\u5236\u4e86\u7cfb\u7edf\u7684\u53ef\u89e3\u91ca\u6027\u548c\u53ef\u9760\u6027\u3002\u672c\u6587\u65e8\u5728\u901a\u8fc7\u5f15\u5165\u8bed\u4e49\u7a33\u5b9a\u6027\u4f5c\u4e3a\u8bc4\u4f30\u6807\u51c6\uff0c\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002\",\n  \"method\": \"\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eLLaMA\u7684\u8bc4\u4f30\u5668\uff0c\u7528\u4e8e\u81ea\u52a8\u6d4b\u91cf\u63d0\u793a\u7684\u8bed\u4e49\u7a33\u5b9a\u6027\uff0c\u5e76\u5f00\u53d1\u4e86\u4e00\u4e2a\u7a33\u5b9a\u6027\u611f\u77e5\u7684\u63d0\u793a\u751f\u6210\u7cfb\u7edf\uff0c\u901a\u8fc7\u53cd\u9988\u673a\u5236\u8fed\u4ee3\u63d0\u5347\u63d0\u793a\u8d28\u91cf\u548c\u7cfb\u7edf\u6027\u80fd\u3002\",\n  \"result\": \"\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u7a33\u5b9a\u6027\u611f\u77e5\u6846\u67b6\u5728\u901a\u7528\u548c\u9886\u57df\u7279\u5b9a\u4efb\u52a1\u4e2d\u5747\u80fd\u63d0\u9ad8\u51c6\u786e\u6027\u548c\u8f93\u51fa\u4e00\u81f4\u6027\uff0c\u9a8c\u8bc1\u4e86\u7a33\u5b9a\u6027\u5bf9\u7cfb\u7edf\u6027\u80fd\u7684\u91cd\u8981\u6027\u3002\",\n  \"conclusion\": \"\u672c\u6587\u901a\u8fc7\u5173\u6ce8\u63d0\u793a\u7684\u7a33\u5b9a\u6027\u800c\u975e\u4e00\u6b21\u6027\u7ed3\u679c\uff0c\u4e3a\u63d0\u793a\u8bbe\u8ba1\u548c\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u53ef\u9760\u6027\u63d0\u4f9b\u4e86\u65b0\u7684\u89c6\u89d2\u548c\u5b9e\u7528\u5de5\u5177\u3002\"\n}\n```", "additional_kwargs": {"refusal": null}, "response_metadata": {"token_usage": {"completion_tokens": 201, "prompt_tokens": 608, "total_tokens": 809, "completion_tokens_details": null, "prompt_tokens_details": null}, "model_name": "deepseek/deepseek-chat-v3-0324:free", "system_fingerprint": null, "id": "gen-1747817924-Jtfe6ZNS3KRRao5kXmr4", "finish_reason": "stop", "logprobs": null}, "type": "ai", "name": null, "id": "run-2b79636c-0487-4164-b08d-fdcfda7a98a5-0", "example": false, "tool_calls": [], "invalid_tool_calls": [], "usage_metadata": {"input_tokens": 608, "output_tokens": 201, "total_tokens": 809, "input_token_details": {}, "output_token_details": {}}}}
{"id": "2505.13507", "pdf": "https://arxiv.org/pdf/2505.13507", "abs": "https://arxiv.org/abs/2505.13507", "authors": ["Haoyang Chen"], "title": "Open Set Domain Adaptation with Vision-language models via Gradient-aware Separation", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "Open-Set Domain Adaptation (OSDA) confronts the dual challenge of aligning\nknown-class distributions across domains while identifying\ntarget-domain-specific unknown categories. Current approaches often fail to\nleverage semantic relationships between modalities and struggle with error\naccumulation in unknown sample detection. We propose to harness Contrastive\nLanguage-Image Pretraining (CLIP) to address these limitations through two key\ninnovations: 1) Prompt-driven cross-domain alignment: Learnable textual prompts\nconditioned on domain discrepancy metrics dynamically adapt CLIP's text\nencoder, enabling semantic consistency between source and target domains\nwithout explicit unknown-class supervision. 2) Gradient-aware open-set\nseparation: A gradient analysis module quantifies domain shift by comparing the\nL2-norm of gradients from the learned prompts, where known/unknown samples\nexhibit statistically distinct gradient behaviors. Evaluations on Office-Home\nshow that our method consistently outperforms CLIP baseline and standard\nbaseline. Ablation studies confirm the gradient norm's critical role.", "AI": {"content": "```json\n{\n  \"tldr\": \"\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u5bf9\u6bd4\u8bed\u8a00-\u56fe\u50cf\u9884\u8bad\u7ec3\uff08CLIP\uff09\u89e3\u51b3\u5f00\u653e\u96c6\u9886\u57df\u9002\u5e94\uff08OSDA\uff09\u95ee\u9898\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u53ef\u5b66\u4e60\u7684\u6587\u672c\u63d0\u793a\u548c\u68af\u5ea6\u5206\u6790\u6a21\u5757\uff0c\u6709\u6548\u5bf9\u9f50\u8de8\u9886\u57df\u5df2\u77e5\u7c7b\u522b\u5206\u5e03\u5e76\u8bc6\u522b\u76ee\u6807\u9886\u57df\u672a\u77e5\u7c7b\u522b\u3002\",\n  \"motivation\": \"\u5f53\u524d\u5f00\u653e\u96c6\u9886\u57df\u9002\u5e94\u65b9\u6cd5\u5728\u5229\u7528\u6a21\u6001\u95f4\u8bed\u4e49\u5173\u7cfb\u548c\u51cf\u5c11\u672a\u77e5\u6837\u672c\u68c0\u6d4b\u9519\u8bef\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u6709\u6548\u7684\u65b9\u6cd5\u6765\u540c\u65f6\u5904\u7406\u5df2\u77e5\u7c7b\u522b\u7684\u5206\u5e03\u5bf9\u9f50\u548c\u672a\u77e5\u7c7b\u522b\u7684\u8bc6\u522b\u3002\",\n  \"method\": \"1) \u57fa\u4e8e\u9886\u57df\u5dee\u5f02\u5ea6\u91cf\u7684\u53ef\u5b66\u4e60\u6587\u672c\u63d0\u793a\u52a8\u6001\u8c03\u6574CLIP\u7684\u6587\u672c\u7f16\u7801\u5668\uff0c\u5b9e\u73b0\u8de8\u9886\u57df\u8bed\u4e49\u4e00\u81f4\u6027\uff1b2) \u901a\u8fc7\u68af\u5ea6\u5206\u6790\u6a21\u5757\u91cf\u5316\u9886\u57df\u504f\u79fb\uff0c\u5229\u7528\u68af\u5ea6\u884c\u4e3a\u7684\u7edf\u8ba1\u5dee\u5f02\u533a\u5206\u5df2\u77e5\u548c\u672a\u77e5\u6837\u672c\u3002\",\n  \"result\": \"\u5728Office-Home\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u4f18\u4e8eCLIP\u57fa\u7ebf\u548c\u6807\u51c6\u57fa\u7ebf\uff0c\u6d88\u878d\u7814\u7a76\u9a8c\u8bc1\u4e86\u68af\u5ea6\u8303\u6570\u5728\u533a\u5206\u5df2\u77e5\u548c\u672a\u77e5\u6837\u672c\u4e2d\u7684\u5173\u952e\u4f5c\u7528\u3002\",\n  \"conclusion\": \"\u672c\u6587\u63d0\u51fa\u7684\u65b9\u6cd5\u901a\u8fc7\u7ed3\u5408\u53ef\u5b66\u4e60\u6587\u672c\u63d0\u793a\u548c\u68af\u5ea6\u5206\u6790\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u5f00\u653e\u96c6\u9886\u57df\u9002\u5e94\u4e2d\u7684\u8de8\u9886\u57df\u5bf9\u9f50\u548c\u672a\u77e5\u7c7b\u522b\u8bc6\u522b\u95ee\u9898\uff0c\u4e3a\u76f8\u5173\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u7684\u601d\u8def\u3002\"\n}\n```", "additional_kwargs": {"refusal": null}, "response_metadata": {"token_usage": {"completion_tokens": 255, "prompt_tokens": 527, "total_tokens": 782, "completion_tokens_details": null, "prompt_tokens_details": null}, "model_name": "deepseek/deepseek-chat-v3-0324:free", "system_fingerprint": null, "id": "gen-1747817938-L3quWE7nO8FzBggRy433", "finish_reason": "stop", "logprobs": null}, "type": "ai", "name": null, "id": "run-3382f371-5812-47f6-9026-c818278b5bcf-0", "example": false, "tool_calls": [], "invalid_tool_calls": [], "usage_metadata": {"input_tokens": 527, "output_tokens": 255, "total_tokens": 782, "input_token_details": {}, "output_token_details": {}}}}
{"id": "2505.13554", "pdf": "https://arxiv.org/pdf/2505.13554", "abs": "https://arxiv.org/abs/2505.13554", "authors": ["Zhanglin Wu", "Daimeng Wei", "Xiaoyu Chen", "Hengchao Shang", "Jiaxin Guo", "Zongyao Li", "Yuanchang Luo", "Jinlong Yang", "Zhiqiang Rao", "Hao Yang"], "title": "Combining the Best of Both Worlds: A Method for Hybrid NMT and LLM Translation", "categories": ["cs.CL", "cs.AI"], "comment": "9 pages, 2 figures, 9 tables, ACL 2025", "summary": "Large language model (LLM) shows promising performances in a variety of\ndownstream tasks, such as machine translation (MT). However, using LLMs for\ntranslation suffers from high computational costs and significant latency.\nBased on our evaluation, in most cases, translations using LLMs are comparable\nto that generated by neural machine translation (NMT) systems. Only in\nparticular scenarios, LLM and NMT models show respective advantages. As a\nresult, integrating NMT and LLM for translation and using LLM only when\nnecessary seems to be a sound solution. A scheduling policy that optimizes\ntranslation result while ensuring fast speed and as little LLM usage as\npossible is thereby required. We compare several scheduling policies and\npropose a novel and straightforward decider that leverages source sentence\nfeatures. We conduct extensive experiments on multilingual test sets and the\nresult shows that we can achieve optimal translation performance with minimal\nLLM usage, demonstrating effectiveness of our decider.", "AI": {"content": "```json\n{\n  \"tldr\": \"\u7814\u7a76\u8868\u660e\u6df7\u5408\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b(LLM)\u4e0e\u795e\u7ecf\u673a\u5668\u7ffb\u8bd1(NMT)\u7cfb\u7edf\uff0c\u5728\u4ec5\u5fc5\u8981\u65f6\u8c03\u7528LLM\uff0c\u80fd\u5e73\u8861\u7ffb\u8bd1\u8d28\u91cf\u4e0e\u6548\u7387\u3002\u63d0\u51fa\u57fa\u4e8e\u6e90\u53e5\u7279\u5f81\u7684\u8c03\u5ea6\u7b56\u7565\uff0c\u5b9e\u9a8c\u8bc1\u5b9e\u5176\u6709\u6548\u6027\u3002\",\n  \"motivation\": \"\u5927\u8bed\u8a00\u6a21\u578b\u5728\u673a\u5668\u7ffb\u8bd1\u7b49\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u5176\u9ad8\u8ba1\u7b97\u6210\u672c\u548c\u5ef6\u8fdf\u95ee\u9898\u9650\u5236\u4e86\u5b9e\u7528\u4ef7\u503c\u3002\u7814\u7a76\u53d1\u73b0LLM\u548cNMT\u5728\u4e0d\u540c\u573a\u666f\u4e2d\u5404\u6709\u4f18\u52bf\uff0c\u9700\u8981\u9ad8\u6548\u6574\u5408\u65b9\u6848\u3002\",\n  \"method\": \"\u63d0\u51fa\u65b0\u578b\u8c03\u5ea6\u7b56\u7565\uff1a\u901a\u8fc7\u5206\u6790\u6e90\u53e5\u7279\u5f81\u52a8\u6001\u51b3\u5b9a\u4f7f\u7528NMT\u6216LLM\uff0c\u4ec5\u5728\u5fc5\u8981\u65f6\u8c03\u7528LLM\u4ee5\u51cf\u5c11\u8ba1\u7b97\u5f00\u9500\u3002\",\n  \"result\": \"\u591a\u8bed\u8a00\u6d4b\u8bd5\u8868\u660e\uff0c\u8be5\u7b56\u7565\u80fd\u4ee5\u6700\u5c11LLM\u4f7f\u7528\u91cf\u83b7\u5f97\u6700\u4f18\u7ffb\u8bd1\u6548\u679c\uff0c\u9a8c\u8bc1\u4e86\u51b3\u7b56\u673a\u5236\u7684\u6709\u6548\u6027\u3002\",\n  \"conclusion\": \"\u57fa\u4e8e\u6e90\u53e5\u7279\u5f81\u7684\u6df7\u5408\u7ffb\u8bd1\u8c03\u5ea6\u65b9\u6848\uff0c\u5728\u4fdd\u8bc1\u8d28\u91cf\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u6548\u7387\uff0c\u4e3aLLM\u4e0eNMT\u7684\u534f\u540c\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u884c\u8def\u5f84\u3002\"\n}\n```", "additional_kwargs": {"refusal": null}, "response_metadata": {"token_usage": {"completion_tokens": 210, "prompt_tokens": 522, "total_tokens": 732, "completion_tokens_details": null, "prompt_tokens_details": null}, "model_name": "deepseek/deepseek-chat-v3-0324:free", "system_fingerprint": null, "id": "gen-1747817948-52D7fNDMl5mbj7UUIX0p", "finish_reason": "stop", "logprobs": null}, "type": "ai", "name": null, "id": "run-1102e2c8-00f6-41ac-8039-c5f72ae5f76f-0", "example": false, "tool_calls": [], "invalid_tool_calls": [], "usage_metadata": {"input_tokens": 522, "output_tokens": 210, "total_tokens": 732, "input_token_details": {}, "output_token_details": {}}}}
{"id": "2505.13551", "pdf": "https://arxiv.org/pdf/2505.13551", "abs": "https://arxiv.org/abs/2505.13551", "authors": ["Serge Dolgikh"], "title": "Counter-Inferential Behavior in Natural and Artificial Cognitive Systems", "categories": ["cs.AI", "cs.NE", "cs.SI", "68T27, 94A15", "F.2.2; I.2.6"], "comment": "23 pages, 3 figures", "summary": "This study explores the emergence of counter-inferential behavior in natural\nand artificial cognitive systems, that is, patterns in which agents\nmisattribute empirical success or suppress adaptation, leading to epistemic\nrigidity or maladaptive stability. We analyze archetypal scenarios in which\nsuch behavior arises: reinforcement of stability through reward imbalance,\nmeta-cognitive attribution of success to internal superiority, and protective\nreframing under perceived model fragility. Rather than arising from noise or\nflawed design, these behaviors emerge through structured interactions between\ninternal information models, empirical feedback, and higher-order evaluation\nmechanisms. Drawing on evidence from artificial systems, biological cognition,\nhuman psychology, and social dynamics, we identify counter-inferential behavior\nas a general cognitive vulnerability that can manifest even in otherwise\nwell-adapted systems. The findings highlight the importance of preserving\nminimal adaptive activation under stable conditions and suggest design\nprinciples for cognitive architectures that can resist rigidity under\ninformational stress.", "AI": {"content": "```json\n{\n  \"tldr\": \"\u7814\u7a76\u63a2\u8ba8\u4e86\u81ea\u7136\u4e0e\u4eba\u5de5\u8ba4\u77e5\u7cfb\u7edf\u4e2d\u51fa\u73b0\u7684\u53cd\u63a8\u7406\u884c\u4e3a\uff0c\u5373\u667a\u80fd\u4f53\u9519\u8bef\u5f52\u56e0\u7ecf\u9a8c\u6210\u529f\u6216\u6291\u5236\u9002\u5e94\uff0c\u5bfc\u81f4\u8ba4\u77e5\u50f5\u5316\u6216\u9002\u5e94\u4e0d\u826f\u7a33\u5b9a\u7684\u6a21\u5f0f\u3002\",\n  \"motivation\": \"\u63a2\u8ba8\u8ba4\u77e5\u7cfb\u7edf\u4e2d\u53cd\u63a8\u7406\u884c\u4e3a\u7684\u4ea7\u751f\u673a\u5236\u53ca\u5176\u5bf9\u7cfb\u7edf\u9002\u5e94\u6027\u7684\u5f71\u54cd\uff0c\u4e3a\u8bbe\u8ba1\u66f4\u9c81\u68d2\u7684\u8ba4\u77e5\u67b6\u6784\u63d0\u4f9b\u7406\u8bba\u57fa\u7840\u3002\",\n  \"method\": \"\u901a\u8fc7\u5206\u6790\u5178\u578b\u573a\u666f\uff08\u5982\u5956\u52b1\u5931\u8861\u3001\u5143\u8ba4\u77e5\u5f52\u56e0\u3001\u6a21\u578b\u8106\u5f31\u6027\u4e0b\u7684\u4fdd\u62a4\u6027\u91cd\u6784\uff09\u5e76\u7ed3\u5408\u4eba\u5de5\u7cfb\u7edf\u3001\u751f\u7269\u8ba4\u77e5\u3001\u5fc3\u7406\u5b66\u53ca\u793e\u4f1a\u52a8\u6001\u7684\u8bc1\u636e\u8fdb\u884c\u7814\u7a76\u3002\",\n  \"result\": \"\u53d1\u73b0\u53cd\u63a8\u7406\u884c\u4e3a\u662f\u4e00\u79cd\u666e\u904d\u5b58\u5728\u7684\u8ba4\u77e5\u8106\u5f31\u6027\uff0c\u5373\u4f7f\u5728\u9002\u5e94\u6027\u826f\u597d\u7684\u7cfb\u7edf\u4e2d\u4e5f\u53ef\u80fd\u51fa\u73b0\uff0c\u5e76\u63d0\u51fa\u4e86\u9632\u6b62\u8ba4\u77e5\u50f5\u5316\u7684\u8bbe\u8ba1\u539f\u5219\u3002\",\n  \"conclusion\": \"\u5f3a\u8c03\u5728\u7a33\u5b9a\u6761\u4ef6\u4e0b\u4fdd\u6301\u6700\u5c0f\u9002\u5e94\u6027\u6fc0\u6d3b\u7684\u91cd\u8981\u6027\uff0c\u4e3a\u8bbe\u8ba1\u6297\u4fe1\u606f\u538b\u529b\u4e0b\u50f5\u5316\u7684\u8ba4\u77e5\u67b6\u6784\u63d0\u4f9b\u4e86\u6307\u5bfc\u3002\"\n}\n```", "additional_kwargs": {"refusal": null}, "response_metadata": {"token_usage": {"completion_tokens": 188, "prompt_tokens": 518, "total_tokens": 706, "completion_tokens_details": null, "prompt_tokens_details": null}, "model_name": "deepseek/deepseek-chat-v3-0324:free", "system_fingerprint": null, "id": "gen-1747817957-8UWm6F2RSFcvCe3sR2FU", "finish_reason": "stop", "logprobs": null}, "type": "ai", "name": null, "id": "run-d6d0b928-9f42-4274-bb8b-3a507fcdc404-0", "example": false, "tool_calls": [], "invalid_tool_calls": [], "usage_metadata": {"input_tokens": 518, "output_tokens": 188, "total_tokens": 706, "input_token_details": {}, "output_token_details": {}}}}
{"id": "2505.13510", "pdf": "https://arxiv.org/pdf/2505.13510", "abs": "https://arxiv.org/abs/2505.13510", "authors": ["Conor Rowan", "Alireza Doostan"], "title": "On the definition and importance of interpretability in scientific machine learning", "categories": ["cs.LG", "physics.data-an", "physics.hist-ph", "physics.soc-ph"], "comment": null, "summary": "Though neural networks trained on large data sets have been successfully used\nto describe and predict many physical phenomena, there is a sense among\nscientists that, unlike traditional scientific models, where relationships come\npackaged in the form of simple mathematical expressions, the findings of the\nneural network cannot be integrated into the body of scientific knowledge.\nCritics of ML's inability to produce human-understandable relationships have\nconverged on the concept of \"interpretability\" as its point of departure from\nmore traditional forms of science. As the growing interest in interpretability\nhas shown, researchers in the physical sciences seek not just predictive\nmodels, but also to uncover the fundamental principles that govern a system of\ninterest. However, clarity around a definition of interpretability and the\nprecise role that it plays in science is lacking in the literature. In this\nwork, we argue that researchers in equation discovery and symbolic regression\ntend to conflate the concept of sparsity with interpretability. We review key\npapers on interpretable ML from outside the scientific community and argue\nthat, though the definitions and methods they propose can inform questions of\ninterpretability for SciML, they are inadequate for this new purpose. Noting\nthese deficiencies, we propose an operational definition of interpretability\nfor the physical sciences. Our notion of interpretability emphasizes\nunderstanding of the mechanism over mathematical sparsity. Innocuous though it\nmay seem, this emphasis on mechanism shows that sparsity is often unnecessary.\nIt also questions the possibility of interpretable scientific discovery when\nprior knowledge is lacking. We believe a precise and philosophically informed\ndefinition of interpretability in SciML will help focus research efforts toward\nthe most significant obstacles to realizing a data-driven scientific future.", "AI": {"content": "  \n\n```json\n{\n  \"tldr\": \"\u8bba\u6587\u63a2\u8ba8\u4e86\u79d1\u5b66\u673a\u5668\u5b66\u4e60\u4e2d\u53ef\u89e3\u91ca\u6027\u7684\u6982\u5ff5\uff0c\u6307\u51fa\u5f53\u524d\u7814\u7a76\u8fc7\u4e8e\u5173\u6ce8\u6570\u5b66\u7a00\u758f\u6027\u800c\u5ffd\u7565\u4e86\u673a\u5236\u7406\u89e3\uff0c\u5e76\u63d0\u51fa\u4e86\u9488\u5bf9\u7269\u7406\u79d1\u5b66\u7684\u65b0\u5b9a\u4e49\u3002\",\n  \"motivation\": \"\u79d1\u5b66\u673a\u5668\u5b66\u4e60\u867d\u7136\u80fd\u9884\u6d4b\u7269\u7406\u73b0\u8c61\uff0c\u4f46\u5176\u6a21\u578b\u7f3a\u4e4f\u4f20\u7edf\u79d1\u5b66\u6a21\u578b\u7684\u53ef\u89e3\u91ca\u6027\uff0c\u5bfc\u81f4\u96be\u4ee5\u878d\u5165\u79d1\u5b66\u77e5\u8bc6\u4f53\u7cfb\u3002\u7814\u7a76\u8005\u5e0c\u671b\u660e\u786e\u53ef\u89e3\u91ca\u6027\u7684\u5b9a\u4e49\u53ca\u5176\u5728\u79d1\u5b66\u4e2d\u7684\u4f5c\u7528\u3002\",\n  \"method\": \"\u901a\u8fc7\u5206\u6790\u79d1\u5b66\u673a\u5668\u5b66\u4e60\u4ee5\u5916\u7684\u53ef\u89e3\u91ca\u6027\u7814\u7a76\u6587\u732e\uff0c\u6307\u51fa\u5176\u65b9\u6cd5\u5bf9\u79d1\u5b66\u673a\u5668\u5b66\u4e60\u7684\u5c40\u9650\u6027\uff0c\u5e76\u63d0\u51fa\u57fa\u4e8e\u673a\u5236\u7406\u89e3\u7684\u65b0\u5b9a\u4e49\u3002\",\n  \"result\": \"\u7814\u7a76\u53d1\u73b0\uff0c\u6570\u5b66\u7a00\u758f\u6027\u5e76\u975e\u53ef\u89e3\u91ca\u6027\u7684\u5fc5\u8981\u6761\u4ef6\uff0c\u673a\u5236\u7406\u89e3\u624d\u662f\u5173\u952e\u3002\u540c\u65f6\uff0c\u7f3a\u4e4f\u5148\u9a8c\u77e5\u8bc6\u65f6\uff0c\u53ef\u89e3\u91ca\u6027\u79d1\u5b66\u53d1\u73b0\u53ef\u80fd\u96be\u4ee5\u5b9e\u73b0\u3002\",\n  \"conclusion\": \"\u8bba\u6587\u4e3a\u79d1\u5b66\u673a\u5668\u5b66\u4e60\u4e2d\u7684\u53ef\u89e3\u91ca\u6027\u63d0\u4f9b\u4e86\u66f4\u7cbe\u786e\u7684\u5b9a\u4e49\uff0c\u5f3a\u8c03\u673a\u5236\u7406\u89e3\u7684\u91cd\u8981\u6027\uff0c\u5e76\u6307\u51fa\u672a\u6765\u7814\u7a76\u5e94\u5173\u6ce8\u6570\u636e\u9a71\u52a8\u79d1\u5b66\u4e2d\u7684\u6838\u5fc3\u6311\u6218\u3002\"\n}\n```", "additional_kwargs": {"refusal": null}, "response_metadata": {"token_usage": {"completion_tokens": 203, "prompt_tokens": 677, "total_tokens": 880, "completion_tokens_details": null, "prompt_tokens_details": null}, "model_name": "deepseek/deepseek-chat-v3-0324:free", "system_fingerprint": null, "id": "gen-1747817973-qL9TrbxOs5A3DRzRbnFG", "finish_reason": "stop", "logprobs": null}, "type": "ai", "name": null, "id": "run-3c53d113-c9b7-4af8-9779-6cebd06538fc-0", "example": false, "tool_calls": [], "invalid_tool_calls": [], "usage_metadata": {"input_tokens": 677, "output_tokens": 203, "total_tokens": 880, "input_token_details": {}, "output_token_details": {}}}}
{"id": "2505.13559", "pdf": "https://arxiv.org/pdf/2505.13559", "abs": "https://arxiv.org/abs/2505.13559", "authors": ["Sathya Krishnan Suresh", "Tanmay Surana", "Lim Zhi Hao", "Eng Siong Chng"], "title": "CS-Sum: A Benchmark for Code-Switching Dialogue Summarization and the Limits of Large Language Models", "categories": ["cs.CL", "cs.LG"], "comment": "17 pages, 5 figures and 11 tables", "summary": "Code-switching (CS) poses a significant challenge for Large Language Models\n(LLMs), yet its comprehensibility remains underexplored in LLMs. We introduce\nCS-Sum, to evaluate the comprehensibility of CS by the LLMs through CS dialogue\nto English summarization. CS-Sum is the first benchmark for CS dialogue\nsummarization across Mandarin-English (EN-ZH), Tamil-English (EN-TA), and\nMalay-English (EN-MS), with 900-1300 human-annotated dialogues per language\npair. Evaluating ten LLMs, including open and closed-source models, we analyze\nperformance across few-shot, translate-summarize, and fine-tuning (LoRA, QLoRA\non synthetic data) approaches. Our findings show that though the scores on\nautomated metrics are high, LLMs make subtle mistakes that alter the complete\nmeaning of the dialogue. To this end, we introduce 3 most common type of errors\nthat LLMs make when handling CS input. Error rates vary across CS pairs and\nLLMs, with some LLMs showing more frequent errors on certain language pairs,\nunderscoring the need for specialized training on code-switched data.", "AI": {"content": "```json\n{\n  \"tldr\": \"\u8bba\u6587\u8bc4\u4f30\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u5904\u7406\u4ee3\u7801\u8f6c\u6362\uff08CS\uff09\u5bf9\u8bdd\u65f6\u7684\u7406\u89e3\u80fd\u529b\uff0c\u63d0\u51fa\u4e86\u9996\u4e2a\u8de8\u8bed\u8a00CS\u5bf9\u8bdd\u6458\u8981\u57fa\u51c6CS-Sum\uff0c\u5e76\u53d1\u73b0LLMs\u5728\u5904\u7406CS\u8f93\u5165\u65f6\u5b58\u5728\u5e38\u89c1\u9519\u8bef\u3002\",\n  \"motivation\": \"\u4ee3\u7801\u8f6c\u6362\uff08CS\uff09\u4e3a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5e26\u6765\u6311\u6218\uff0c\u4f46\u5176\u7406\u89e3\u80fd\u529b\u5c1a\u672a\u5145\u5206\u7814\u7a76\u3002\u8bba\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u8bc4\u4f30LLMs\u5728\u4e0d\u540c\u8bed\u8a00\u5bf9CS\u5bf9\u8bdd\u7684\u7406\u89e3\u4e0e\u6458\u8981\u80fd\u529b\u3002\",\n  \"method\": \"\u5f15\u5165CS-Sum\u57fa\u51c6\uff0c\u6db5\u76d6\u6c49\u8bed-\u82f1\u8bed\u3001\u6cf0\u7c73\u5c14\u8bed-\u82f1\u8bed\u548c\u9a6c\u6765\u8bed-\u82f1\u8bed\u4e09\u79cd\u8bed\u8a00\u5bf9\uff0c\u6bcf\u79cd\u8bed\u8a00\u5bf9\u5305\u542b900-1300\u6761\u4eba\u5de5\u6807\u6ce8\u5bf9\u8bdd\u3002\u8bc4\u4f30\u4e8610\u79cd\u5f00\u6e90\u548c\u95ed\u6e90LLMs\uff0c\u5305\u62ec\u5c11\u6837\u672c\u5b66\u4e60\u3001\u7ffb\u8bd1-\u6458\u8981\u548c\u5fae\u8c03\uff08LoRA\u3001QLoRA\uff09\u7b49\u65b9\u6cd5\u3002\",\n  \"result\": \"\u867d\u7136\u81ea\u52a8\u5316\u6307\u6807\u5f97\u5206\u8f83\u9ad8\uff0c\u4f46LLMs\u5728\u5904\u7406CS\u8f93\u5165\u65f6\u4f1a\u72af\u7ec6\u5fae\u9519\u8bef\uff0c\u5bfc\u81f4\u5bf9\u8bdd\u610f\u4e49\u6539\u53d8\u3002\u8bba\u6587\u63d0\u51fa\u4e09\u79cd\u5e38\u89c1\u9519\u8bef\u7c7b\u578b\uff0c\u9519\u8bef\u7387\u56e0\u8bed\u8a00\u5bf9\u548c\u6a21\u578b\u800c\u5f02\u3002\",\n  \"conclusion\": \"\u7814\u7a76\u8868\u660eLLMs\u5904\u7406CS\u8f93\u5165\u65f6\u4ecd\u9700\u6539\u8fdb\uff0c\u67d0\u4e9b\u8bed\u8a00\u5bf9\u7684\u9519\u8bef\u9891\u7387\u66f4\u9ad8\uff0c\u5f3a\u8c03\u4e86\u9488\u5bf9\u4ee3\u7801\u8f6c\u6362\u6570\u636e\u8fdb\u884c\u4e13\u4e1a\u5316\u8bad\u7ec3\u7684\u5fc5\u8981\u6027\u3002\"\n}\n```", "additional_kwargs": {"refusal": null}, "response_metadata": {"token_usage": {"completion_tokens": 260, "prompt_tokens": 569, "total_tokens": 829, "completion_tokens_details": null, "prompt_tokens_details": null}, "model_name": "deepseek/deepseek-chat-v3-0324:free", "system_fingerprint": null, "id": "gen-1747818007-gDkdCdlSRsMH1M3yLSVw", "finish_reason": "stop", "logprobs": null}, "type": "ai", "name": null, "id": "run-caf3e1f8-cdeb-4c56-94d9-2cf97936d520-0", "example": false, "tool_calls": [], "invalid_tool_calls": [], "usage_metadata": {"input_tokens": 569, "output_tokens": 260, "total_tokens": 829, "input_token_details": {}, "output_token_details": {}}}}
{"id": "2505.13561", "pdf": "https://arxiv.org/pdf/2505.13561", "abs": "https://arxiv.org/abs/2505.13561", "authors": ["Daniel Rothschild"], "title": "Language and Thought: The View from LLMs", "categories": ["cs.AI"], "comment": "37 Pages", "summary": "Daniel Dennett speculated in *Kinds of Minds* 1996: \"Perhaps the kind of mind\nyou get when you add language to it is so different from the kind of mind you\ncan have without language that calling them both minds is a mistake.\" Recent\nwork in AI can be seen as testing Dennett's thesis by exploring the performance\nof AI systems with and without linguistic training. I argue that the success of\nLarge Language Models at inferential reasoning, limited though it may be,\nsupports Dennett's radical view about the effect of language on thought. I\nsuggest it is the abstractness and efficiency of linguistic encoding that lies\nbehind the capacity of LLMs to perform inferences across a wide range of\ndomains. In a slogan, language makes inference computationally tractable. I\nassess what these results in AI indicate about the role of language in the\nworkings of our own biological minds.", "AI": {"content": "```\n\n{\n  \"tldr\": \"\u8bba\u6587\u63a2\u8ba8\u4e86\u8bed\u8a00\u8bad\u7ec3\u5bf9AI\u7cfb\u7edf\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u652f\u6301\u4e86\u8bed\u8a00\u5bf9\u601d\u7ef4\u6709\u6839\u672c\u6027\u6539\u53d8\u7684\u89c2\u70b9\uff0c\u5e76\u6307\u51fa\u8bed\u8a00\u7684\u9ad8\u6548\u7f16\u7801\u80fd\u529b\u662fAI\u8de8\u9886\u57df\u63a8\u7406\u7684\u5173\u952e\u3002\",\n  \"motivation\": \"\u7814\u7a76\u52a8\u673a\u662f\u9a8c\u8bc1Daniel Dennett\u5173\u4e8e\u8bed\u8a00\u5bf9\u601d\u7ef4\u5f71\u54cd\u7684\u5047\u8bbe\uff0c\u5373\u8bed\u8a00\u8bad\u7ec3\u53ef\u80fd\u4f7fAI\u7cfb\u7edf\u8868\u73b0\u51fa\u4e0e\u65e0\u8bed\u8a00\u7cfb\u7edf\u6839\u672c\u4e0d\u540c\u7684\u601d\u7ef4\u6a21\u5f0f\u3002\",\n  \"method\": \"\u901a\u8fc7\u6bd4\u8f83\u6709\u8bed\u8a00\u8bad\u7ec3\u548c\u65e0\u8bed\u8a00\u8bad\u7ec3\u7684AI\u7cfb\u7edf\u6027\u80fd\uff0c\u7279\u522b\u662f\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u63a8\u7406\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\uff0c\u6765\u68c0\u9a8c\u8fd9\u4e00\u5047\u8bbe\u3002\",\n  \"result\": \"\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u8bed\u8a00\u8bad\u7ec3\u663e\u8457\u63d0\u5347\u4e86AI\u7cfb\u7edf\u7684\u63a8\u7406\u80fd\u529b\uff0c\u652f\u6301\u4e86\u8bed\u8a00\u5bf9\u601d\u7ef4\u6709\u6839\u672c\u6027\u5f71\u54cd\u7684\u5047\u8bbe\u3002\",\n  \"conclusion\": \"\u7ed3\u8bba\u8ba4\u4e3a\uff0c\u8bed\u8a00\u7684\u9ad8\u6548\u7f16\u7801\u80fd\u529b\u662fAI\u7cfb\u7edf\u5b9e\u73b0\u8de8\u9886\u57df\u63a8\u7406\u7684\u5173\u952e\uff0c\u8fd9\u4e00\u53d1\u73b0\u5bf9\u7406\u89e3\u4eba\u7c7b\u751f\u7269\u5927\u8111\u4e2d\u8bed\u8a00\u7684\u4f5c\u7528\u5177\u6709\u542f\u793a\u610f\u4e49\u3002\"\n}\n```", "additional_kwargs": {"refusal": null}, "response_metadata": {"token_usage": {"completion_tokens": 187, "prompt_tokens": 510, "total_tokens": 697, "completion_tokens_details": null, "prompt_tokens_details": null}, "model_name": "deepseek/deepseek-chat-v3-0324:free", "system_fingerprint": null, "id": "gen-1747818018-WGXZtgdU6dXxXrViznjS", "finish_reason": "stop", "logprobs": null}, "type": "ai", "name": null, "id": "run-ce4abad7-0097-4549-adcb-0975bc7c2934-0", "example": false, "tool_calls": [], "invalid_tool_calls": [], "usage_metadata": {"input_tokens": 510, "output_tokens": 187, "total_tokens": 697, "input_token_details": {}, "output_token_details": {}}}}
{"id": "2505.13515", "pdf": "https://arxiv.org/pdf/2505.13515", "abs": "https://arxiv.org/abs/2505.13515", "authors": ["Yanan Li", "Fanxu Meng", "Muhan Zhang", "Shiai Zhu", "Shangguang Wang", "Mengwei Xu"], "title": "LoRASuite: Efficient LoRA Adaptation Across Large Language Model Upgrades", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "As Large Language Models (LLMs) are frequently updated, LoRA weights trained\non earlier versions quickly become obsolete. The conventional practice of\nretraining LoRA weights from scratch on the latest model is costly,\ntime-consuming, and environmentally detrimental, particularly as the diversity\nof LLMs and downstream tasks expands. This motivates a critical question: \"How\ncan we efficiently leverage existing LoRA weights to adapt to newer model\nversions?\" To address this, we propose LoRASuite, a modular approach tailored\nspecifically to various types of LLM updates. First, we compute a transfer\nmatrix utilizing known parameters from both old and new LLMs. Next, we allocate\ncorresponding layers and attention heads based on centered kernel alignment and\ncosine similarity metrics, respectively. A subsequent small-scale, skillful\nfine-tuning step ensures numerical stability. Experimental evaluations\ndemonstrate that LoRASuite consistently surpasses small-scale vanilla LoRA\nmethods. Notably, on backbone LLMs such as MiniCPM and Qwen, LoRASuite even\nexceeds the performance of full-scale LoRA retraining, with average\nimprovements of +1.4 and +6.6 points on math tasks, respectively. Additionally,\nLoRASuite significantly reduces memory consumption by 5.5 GB and computational\ntime by 78.23%.", "AI": {"content": "```json\n{\n  \"tldr\": \"\u8bba\u6587\u63d0\u51faLoRASuite\u65b9\u6cd5\uff0c\u901a\u8fc7\u6a21\u5757\u5316\u8bbe\u8ba1\u6709\u6548\u5229\u7528\u73b0\u6709LoRA\u6743\u91cd\u9002\u914d\u65b0\u7248\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u663e\u8457\u51cf\u5c11\u8ba1\u7b97\u8d44\u6e90\u6d88\u8017\u3002\",\n  \"motivation\": \"\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u9891\u7e41\u66f4\u65b0\uff0c\u4f20\u7edf\u91cd\u65b0\u8bad\u7ec3LoRA\u6743\u91cd\u7684\u65b9\u6cd5\u6210\u672c\u9ad8\u6602\u4e14\u6548\u7387\u4f4e\u4e0b\uff0c\u4e9f\u9700\u4e00\u79cd\u80fd\u9ad8\u6548\u5229\u7528\u73b0\u6709\u8d44\u6e90\u9002\u914d\u65b0\u6a21\u578b\u7684\u6280\u672f\u3002\",\n  \"method\": \"\u91c7\u7528\u6a21\u5757\u5316\u8bbe\u8ba1\uff1a1)\u8ba1\u7b97\u65b0\u65e7\u6a21\u578b\u53c2\u6570\u95f4\u7684\u8f6c\u79fb\u77e9\u9635 2)\u57fa\u4e8e\u6838\u5bf9\u9f50\u548c\u4f59\u5f26\u76f8\u4f3c\u5ea6\u5206\u914d\u6ce8\u610f\u529b\u5c42 3)\u8fdb\u884c\u5c0f\u89c4\u6a21\u7cbe\u8c03\u786e\u4fdd\u6570\u503c\u7a33\u5b9a\u6027\u3002\",\n  \"result\": \"\u5728MiniCPM/Qwen\u7b49\u6a21\u578b\u4e0a\uff0c\u6027\u80fd\u8d85\u8d8a\u5168\u91cf\u5fae\u8c03\uff08\u6570\u5b66\u4efb\u52a1\u5206\u522b\u63d0\u53471.4/6.6\u5206\uff09\uff0c\u8282\u77015.5GB\u5185\u5b58\u548c78.23%\u8ba1\u7b97\u65f6\u95f4\u3002\",\n  \"conclusion\": \"LoRASuite\u4e3aLLM\u7248\u672c\u8fed\u4ee3\u63d0\u4f9b\u9ad8\u6548\u8fc1\u79fb\u65b9\u6848\uff0c\u663e\u8457\u964d\u4f4e\u8d44\u6e90\u6d88\u8017\uff0c\u5176\u6a21\u5757\u5316\u8bbe\u8ba1\u5177\u6709\u5e7f\u6cdb\u9002\u7528\u6027\u3002\"\n}\n```", "additional_kwargs": {"refusal": null}, "response_metadata": {"token_usage": {"completion_tokens": 216, "prompt_tokens": 594, "total_tokens": 810, "completion_tokens_details": null, "prompt_tokens_details": null}, "model_name": "deepseek/deepseek-chat-v3-0324:free", "system_fingerprint": null, "id": "gen-1747818025-D7B8H47gEXDFCuHfnsii", "finish_reason": "stop", "logprobs": null}, "type": "ai", "name": null, "id": "run-4a5a2d38-db46-4ed8-8a21-22fbffe631fa-0", "example": false, "tool_calls": [], "invalid_tool_calls": [], "usage_metadata": {"input_tokens": 594, "output_tokens": 216, "total_tokens": 810, "input_token_details": {}, "output_token_details": {}}}}
{"id": "2505.13628", "pdf": "https://arxiv.org/pdf/2505.13628", "abs": "https://arxiv.org/abs/2505.13628", "authors": ["Nathaniel Krasner", "Nicholas Lanuzo", "Antonios Anastasopoulos"], "title": "Cross-Lingual Representation Alignment Through Contrastive Image-Caption Tuning", "categories": ["cs.CL"], "comment": "Accepted to ACL 2025 Main Conference", "summary": "Multilingual alignment of sentence representations has mostly required\nbitexts to bridge the gap between languages. We investigate whether visual\ninformation can bridge this gap instead. Image caption datasets are very easy\nto create without requiring multilingual expertise, so this offers a more\nefficient alternative for low-resource languages. We find that multilingual\nimage-caption alignment can implicitly align the text representations between\nlanguages, languages unseen by the encoder in pretraining can be incorporated\ninto this alignment post-hoc, and these aligned representations are usable for\ncross-lingual Natural Language Understanding (NLU) and bitext retrieval.", "AI": {"content": "2019\u5e74\uff0c\u4e2d\u56fd\u79d1\u5b66\u5bb6\u5728\u91cf\u5b50\u8ba1\u7b97\u9886\u57df\u53d6\u5f97\u4e86\u91cd\u5927\u7a81\u7834\uff0c\u6210\u529f\u5b9e\u73b0\u4e8620\u4e2a\u91cf\u5b50\u6bd4\u7279\u7684\u7ea0\u7f20\u6001\u5236\u5907\uff0c\u8fd9\u4e00\u6210\u679c\u5728\u56fd\u9645\u4e0a\u5f15\u8d77\u4e86\u5e7f\u6cdb\u5173\u6ce8\u3002\u91cf\u5b50\u8ba1\u7b97\u4f5c\u4e3a\u4e00\u79cd\u65b0\u5174\u7684\u8ba1\u7b97\u65b9\u5f0f\uff0c\u5176\u6838\u5fc3\u5728\u4e8e\u5229\u7528\u91cf\u5b50\u6bd4\u7279\u7684\u53e0\u52a0\u548c\u7ea0\u7f20\u7279\u6027\uff0c\u5b9e\u73b0\u8fdc\u8d85\u4f20\u7edf\u8ba1\u7b97\u673a\u7684\u8ba1\u7b97\u80fd\u529b\u3002\u4e2d\u56fd\u79d1\u5b66\u5bb6\u7684\u8fd9\u4e00\u6210\u679c\uff0c\u4e0d\u4ec5\u5c55\u793a\u4e86\u4e2d\u56fd\u5728\u91cf\u5b50\u79d1\u6280\u9886\u57df\u7684\u5f3a\u5927\u5b9e\u529b\uff0c\u4e5f\u4e3a\u5168\u7403\u91cf\u5b50\u8ba1\u7b97\u7684\u53d1\u5c55\u63d0\u4f9b\u4e86\u65b0\u7684\u601d\u8def\u548c\u65b9\u5411\u3002", "additional_kwargs": {"refusal": null}, "response_metadata": {"token_usage": {"completion_tokens": 87, "prompt_tokens": 443, "total_tokens": 530, "completion_tokens_details": null, "prompt_tokens_details": null}, "model_name": "deepseek/deepseek-chat-v3-0324:free", "system_fingerprint": null, "id": "gen-1747818038-d9ZkHOx1TzeaIRVtn6Sc", "finish_reason": "stop", "logprobs": null}, "type": "ai", "name": null, "id": "run-db8e2cdb-9dce-43e5-a835-4b3babf4d716-0", "example": false, "tool_calls": [], "invalid_tool_calls": [], "usage_metadata": {"input_tokens": 443, "output_tokens": 87, "total_tokens": 530, "input_token_details": {}, "output_token_details": {}}}}
{"id": "2505.13668", "pdf": "https://arxiv.org/pdf/2505.13668", "abs": "https://arxiv.org/abs/2505.13668", "authors": ["Mahmood Hegazy", "Aaron Rodrigues", "Azzam Naeem"], "title": "MAFA: A multi-agent framework for annotation", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Modern applications require accurate and efficient retrieval of information\nin response to user queries. Mapping user utterances to the most relevant\nFrequently Asked Questions (FAQs) is a crucial component of these systems.\nTraditional approaches often rely on a single model or technique, which may not\ncapture the nuances of diverse user inquiries. In this paper, we introduce a\nmulti-agent framework for FAQ annotation that combines multiple specialized\nagents with different approaches and a judge agent that reranks candidates to\nproduce optimal results. Our agents utilize a structured reasoning approach\ninspired by Attentive Reasoning Queries (ARQs), which guides them through\nsystematic reasoning steps using targeted, task-specific JSON queries. Our\nframework features a specialized few-shot example strategy, where each agent\nreceives different few-shots, enhancing ensemble diversity and coverage of the\nquery space. We evaluate our framework on a real-world banking dataset as well\nas public benchmark datasets (LCQMC and FiQA), demonstrating significant\nimprovements over single-agent approaches across multiple metrics, including a\n14% increase in Top-1 accuracy, an 18% increase in Top-5 accuracy, and a 12%\nimprovement in Mean Reciprocal Rank on our dataset, and similar gains on public\nbenchmarks when compared with traditional single agent annotation techniques.\nOur framework is particularly effective at handling ambiguous queries, making\nit well-suited for deployment in production applications while showing strong\ngeneralization capabilities across different domains and languages.", "AI": {"content": "11```json\n{\n  \"tldr\": \"\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u7528\u4e8eFAQ\u6807\u6ce8\uff0c\u7ed3\u5408\u4e86\u591a\u79cd\u4e13\u4e1a\u667a\u80fd\u4f53\u548c\u91cd\u6392\u5019\u9009\u7b54\u6848\u7684\u6cd5\u5b98\u667a\u80fd\u4f53\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u51c6\u786e\u6027\u548c\u6548\u7387\u3002\",\n  \"motivation\": \"\u4f20\u7edf\u65b9\u6cd5\u901a\u5e38\u4f9d\u8d56\u5355\u4e00\u6a21\u578b\u6216\u6280\u672f\uff0c\u65e0\u6cd5\u6355\u6349\u7528\u6237\u67e5\u8be2\u7684\u591a\u6837\u6027\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u9ad8\u6548\u3001\u51c6\u786e\u7684\u65b9\u6cd5\u6765\u5904\u7406FAQ\u6807\u6ce8\u4efb\u52a1\u3002\",\n  \"method\": \"\u91c7\u7528\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u6bcf\u4e2a\u667a\u80fd\u4f53\u4f7f\u7528\u4e0d\u540c\u7684\u65b9\u6cd5\uff0c\u5e76\u901a\u8fc7\u6cd5\u5b98\u667a\u80fd\u4f53\u91cd\u6392\u5019\u9009\u7b54\u6848\u3002\u667a\u80fd\u4f53\u4f7f\u7528\u7ed3\u6784\u5316\u63a8\u7406\u65b9\u6cd5\uff0c\u57fa\u4e8eARQ\u8fdb\u884c\u7cfb\u7edf\u63a8\u7406\u3002\",\n  \"result\": \"\u5728\u94f6\u884c\u6570\u636e\u96c6\u548c\u516c\u5171\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u76f8\u6bd4\u5355\u4e00\u667a\u80fd\u4f53\u65b9\u6cd5\uff0cTop-1\u51c6\u786e\u7387\u63d0\u9ad8\u4e8614%\uff0cTop-5\u51c6\u786e\u7387\u63d0\u9ad8\u4e8618%\uff0c\u5e73\u5747\u5012\u6570\u6392\u540d\u63d0\u9ad8\u4e8612%\u3002\",\n  \"conclusion\": \"\u8be5\u6846\u67b6\u5728\u5904\u7406\u6a21\u7cca\u67e5\u8be2\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff0c\u9002\u7528\u4e8e\u751f\u4ea7\u73af\u5883\uff0c\u5e76\u5c55\u73b0\u51fa\u8de8\u9886\u57df\u548c\u8de8\u8bed\u8a00\u7684\u5f3a\u5927\u6cdb\u5316\u80fd\u529b\u3002\"\n}\n```", "additional_kwargs": {"refusal": null}, "response_metadata": {"token_usage": {"completion_tokens": 202, "prompt_tokens": 619, "total_tokens": 821, "completion_tokens_details": null, "prompt_tokens_details": null}, "model_name": "deepseek/deepseek-chat-v3-0324:free", "system_fingerprint": null, "id": "gen-1747818043-aHTebdgpYQzyus2tv4aS", "finish_reason": "stop", "logprobs": null}, "type": "ai", "name": null, "id": "run-04dab8db-aa15-4793-a15f-6d23e1ed371a-0", "example": false, "tool_calls": [], "invalid_tool_calls": [], "usage_metadata": {"input_tokens": 619, "output_tokens": 202, "total_tokens": 821, "input_token_details": {}, "output_token_details": {}}}}
{"id": "2505.13521", "pdf": "https://arxiv.org/pdf/2505.13521", "abs": "https://arxiv.org/abs/2505.13521", "authors": ["Gabor Petnehazi", "Laith Al Shaggah", "Jozsef Gall", "Bernadett Aradi"], "title": "Zero-Shot Forecasting Mortality Rates: A Global Study", "categories": ["cs.LG", "q-fin.RM", "stat.AP"], "comment": null, "summary": "This study explores the potential of zero-shot time series forecasting, an\ninnovative approach leveraging pre-trained foundation models, to forecast\nmortality rates without task-specific fine-tuning. We evaluate two\nstate-of-the-art foundation models, TimesFM and CHRONOS, alongside traditional\nand machine learning-based methods across three forecasting horizons (5, 10,\nand 20 years) using data from 50 countries and 111 age groups. In our\ninvestigations, zero-shot models showed varying results: while CHRONOS\ndelivered competitive shorter-term forecasts, outperforming traditional methods\nlike ARIMA and the Lee-Carter model, TimesFM consistently underperformed.\nFine-tuning CHRONOS on mortality data significantly improved long-term\naccuracy. A Random Forest model, trained on mortality data, achieved the best\noverall performance. These findings underscore the potential of zero-shot\nforecasting while highlighting the need for careful model selection and\ndomain-specific adaptation.", "AI": {"content": "```json\n{\n  \"tldr\": \"\u7814\u7a76\u8bc4\u4f30\u4e86\u96f6\u6837\u672c\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u6a21\u578b\uff08TimesFM\u548cCHRONOS\uff09\u4e0e\u4f20\u7edf\u65b9\u6cd5\u5728\u6b7b\u4ea1\u7387\u9884\u6d4b\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0CHRONOS\u77ed\u671f\u8868\u73b0\u4f18\u5f02\uff0c\u800c\u7cbe\u7ec6\u8c03\u4f18\u540e\u957f\u671f\u9884\u6d4b\u66f4\u51c6\uff0c\u968f\u673a\u68ee\u6797\u6574\u4f53\u6700\u4f73\u3002\",\n  \"motivation\": \"\u63a2\u7d22\u65e0\u9700\u4efb\u52a1\u7279\u5b9a\u8c03\u4f18\u7684\u9884\u8bad\u7ec3\u57fa\u7840\u6a21\u578b\uff08\u96f6\u6837\u672c\u9884\u6d4b\uff09\u5728\u6b7b\u4ea1\u7387\u9884\u6d4b\u4e2d\u7684\u5e94\u7528\u6f5c\u529b\u3002\",\n  \"method\": \"\u4f7f\u752850\u4e2a\u56fd\u5bb6111\u4e2a\u5e74\u9f84\u7ec4\u6570\u636e\uff0c\u5bf9\u6bd4TimesFM\u3001CHRONOS\u4e0e\u4f20\u7edf\u65b9\u6cd5\uff08ARIMA\u3001Lee-Carter\uff09\u57285/10/20\u5e74\u9884\u6d4b\u671f\u7684\u8868\u73b0\uff0c\u5e76\u6d4b\u8bd5CHRONOS\u8c03\u4f18\u6548\u679c\u3002\",\n  \"result\": \"CHRONOS\u77ed\u671f\u9884\u6d4b\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\uff0cTimesFM\u8868\u73b0\u4e0d\u4f73\uff1b\u8c03\u4f18\u540eCHRONOS\u957f\u671f\u51c6\u786e\u6027\u63d0\u5347\uff0c\u968f\u673a\u68ee\u6797\u7efc\u5408\u8868\u73b0\u6700\u597d\u3002\",\n  \"conclusion\": \"\u96f6\u6837\u672c\u9884\u6d4b\u5177\u6709\u6f5c\u529b\uff0c\u4f46\u9700\u8c28\u614e\u9009\u62e9\u6a21\u578b\u5e76\u8fdb\u884c\u9886\u57df\u9002\u914d\uff0c\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u4ecd\u5177\u7ade\u4e89\u529b\u3002\"\n}\n```", "additional_kwargs": {"refusal": null}, "response_metadata": {"token_usage": {"completion_tokens": 210, "prompt_tokens": 515, "total_tokens": 725, "completion_tokens_details": null, "prompt_tokens_details": null}, "model_name": "deepseek/deepseek-chat-v3-0324:free", "system_fingerprint": null, "id": "gen-1747818051-FwHjcAoVchUvFqGFRrE9", "finish_reason": "stop", "logprobs": null}, "type": "ai", "name": null, "id": "run-afbaa532-8452-4b37-bd24-cdd27ae24187-0", "example": false, "tool_calls": [], "invalid_tool_calls": [], "usage_metadata": {"input_tokens": 515, "output_tokens": 210, "total_tokens": 725, "input_token_details": {}, "output_token_details": {}}}}
{"id": "2505.13657", "pdf": "https://arxiv.org/pdf/2505.13657", "abs": "https://arxiv.org/abs/2505.13657", "authors": ["Charles J. Torres", "Richard Futrell"], "title": "Clarifying orthography: Orthographic transparency as compressibility", "categories": ["cs.CL", "cs.IT", "math.IT"], "comment": null, "summary": "Orthographic transparency -- how directly spelling is related to sound --\nlacks a unified, script-agnostic metric. Using ideas from algorithmic\ninformation theory, we quantify orthographic transparency in terms of the\nmutual compressibility between orthographic and phonological strings. Our\nmeasure provides a principled way to combine two factors that decrease\northographic transparency, capturing both irregular spellings and rule\ncomplexity in one quantity. We estimate our transparency measure using\nprequential code-lengths derived from neural sequence models. Evaluating 22\nlanguages across a broad range of script types (alphabetic, abjad, abugida,\nsyllabic, logographic) confirms common intuitions about relative transparency\nof scripts. Mutual compressibility offers a simple, principled, and general\nyardstick for orthographic transparency.", "AI": {"content": "```json\n{\n  \"tldr\": \"\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7b97\u6cd5\u4fe1\u606f\u8bba\u7684\u4e66\u5199\u900f\u660e\u5ea6\u5ea6\u91cf\u65b9\u6cd5\uff0c\u901a\u8fc7\u62fc\u5199\u4e0e\u53d1\u97f3\u7684\u4e92\u538b\u7f29\u6027\u6765\u7edf\u4e00\u91cf\u5316\u4e0d\u540c\u6587\u5b57\u7cfb\u7edf\u7684\u900f\u660e\u5ea6\u3002\",\n  \"motivation\": \"\u76ee\u524d\u4e66\u5199\u900f\u660e\u5ea6\uff08\u62fc\u5199\u4e0e\u53d1\u97f3\u7684\u76f4\u63a5\u5173\u8054\u7a0b\u5ea6\uff09\u7f3a\u4e4f\u8de8\u6587\u5b57\u7cfb\u7edf\u7684\u7edf\u4e00\u5ea6\u91cf\u6807\u51c6\uff0c\u4e9f\u9700\u4e00\u79cd\u539f\u7406\u5316\u7684\u901a\u7528\u65b9\u6cd5\u3002\",\n  \"method\": \"\u4f7f\u7528\u795e\u7ecf\u5e8f\u5217\u6a21\u578b\u63a8\u5bfc\u7684\u9884\u5e8f\u5217\u7f16\u7801\u957f\u5ea6\uff0c\u8ba1\u7b97\u6b63\u5b57\u6cd5\u548c\u97f3\u7cfb\u5b57\u7b26\u4e32\u7684\u4e92\u538b\u7f29\u6027\uff0c\u5c06\u62fc\u5199\u4e0d\u89c4\u5219\u6027\u548c\u89c4\u5219\u590d\u6742\u6027\u6574\u5408\u4e3a\u5355\u4e00\u6307\u6807\u3002\",\n  \"result\": \"\u572822\u79cd\u4e0d\u540c\u6587\u5b57\u7c7b\u578b\uff08\u5b57\u6bcd\u3001\u8f85\u97f3\u97f3\u7d20\u7b49\uff09\u7684\u8bed\u8a00\u6d4b\u8bd5\u4e2d\uff0c\u8be5\u5ea6\u91cf\u7ed3\u679c\u4e0e\u6587\u5b57\u900f\u660e\u5ea6\u7684\u5e38\u8bc6\u5224\u65ad\u4e00\u81f4\u3002\",\n  \"conclusion\": \"\u4e92\u538b\u7f29\u6027\u4e3a\u4e66\u5199\u900f\u660e\u5ea6\u63d0\u4f9b\u4e86\u7b80\u5355\u3001\u539f\u7406\u5316\u4e14\u901a\u7528\u7684\u8861\u91cf\u6807\u51c6\u3002\"\n}\n```", "additional_kwargs": {"refusal": null}, "response_metadata": {"token_usage": {"completion_tokens": 180, "prompt_tokens": 488, "total_tokens": 668, "completion_tokens_details": null, "prompt_tokens_details": null}, "model_name": "deepseek/deepseek-chat-v3-0324:free", "system_fingerprint": null, "id": "gen-1747818061-Y2klSRoF1knw1tM8Av8n", "finish_reason": "stop", "logprobs": null}, "type": "ai", "name": null, "id": "run-d1c1f075-1e1f-47a7-9415-af284ebc24d7-0", "example": false, "tool_calls": [], "invalid_tool_calls": [], "usage_metadata": {"input_tokens": 488, "output_tokens": 180, "total_tokens": 668, "input_token_details": {}, "output_token_details": {}}}}
{"id": "2505.13672", "pdf": "https://arxiv.org/pdf/2505.13672", "abs": "https://arxiv.org/abs/2505.13672", "authors": ["Giannis Chatziveroglou"], "title": "A*-Decoding: Token-Efficient Inference Scaling", "categories": ["cs.AI"], "comment": null, "summary": "Inference-time scaling has emerged as a powerful alternative to parameter\nscaling for improving language model performance on complex reasoning tasks.\nWhile existing methods have shown strong performance gains under fixed compute\nbudgets, there has been little focus on optimally utilizing that budget during\ninference. In this work, we introduce A*-decoding, a search-based\ninference-time strategy that builds on the A* search algorithm to optimally\nutilize a fixed compute budget by prioritizing high-quality reasoning paths\nduring generation. We frame language model decoding as a structured search in a\nstate space of partial solutions, applying the A* transition model to identify\npromising continuations guided by an external process supervision signal. In\nour experiments, A*-decoding reaches the performance levels of strong inference\nscaling baselines like best-of-N and particle filtering while using up to 3x\nfewer tokens and 30% fewer PRM passes under equivalent compute budgets. On the\nMATH500 and AIME 2024 benchmarks, A*-decoding enables Llama-3.2-1B-Instruct to\nmatch the performance of the 70x larger Llama-3.1-70B-Instruct, and allows\nQwen3-1.7B to reach o1-like reasoning accuracy. These results highlight the\npower of structured search in decoding, offering an alternative to brute-force\nsampling or scale-driven gains. Our work demonstrates how thoughtful\ninference-time strategies can enhance reasoning in SLMs, pointing toward future\nadvances in more efficient and scalable language model deployment.", "AI": {"content": "```json\n{\n  \"tldr\": \"\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aA*\u89e3\u7801\u7684\u65b0\u578b\u63a8\u7406\u65f6\u95f4\u7b56\u7565\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u641c\u7d22\u4f18\u5316\u56fa\u5b9a\u8ba1\u7b97\u9884\u7b97\u4e0b\u7684\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u6027\u80fd\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8ba1\u7b97\u6548\u7387\u3002\",\n  \"motivation\": \"\u5f53\u524d\u8bed\u8a00\u6a21\u578b\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e2d\u4e3b\u8981\u4f9d\u8d56\u53c2\u6570\u6269\u5c55\u6216\u56fa\u5b9a\u8ba1\u7b97\u9884\u7b97\u4e0b\u7684\u968f\u673a\u91c7\u6837\uff0c\u7f3a\u4e4f\u5bf9\u8ba1\u7b97\u8d44\u6e90\u7684\u6700\u4f18\u5229\u7528\u3002\u672c\u6587\u65e8\u5728\u63a2\u7d22\u5982\u4f55\u901a\u8fc7\u7ed3\u6784\u5316\u641c\u7d22\u7b56\u7565\u5728\u63a8\u7406\u9636\u6bb5\u66f4\u9ad8\u6548\u5730\u5229\u7528\u8ba1\u7b97\u8d44\u6e90\u3002\",\n  \"method\": \"\u63d0\u51faA*\u89e3\u7801\u65b9\u6cd5\uff0c\u5c06\u8bed\u8a00\u6a21\u578b\u89e3\u7801\u8fc7\u7a0b\u5efa\u6a21\u4e3a\u7ed3\u6784\u5316\u641c\u7d22\u95ee\u9898\uff0c\u5229\u7528A*\u7b97\u6cd5\u5728\u90e8\u5206\u89e3\u7a7a\u95f4\u4e2d\u8fdb\u884c\u5bfc\u5411\u6027\u641c\u7d22\uff0c\u901a\u8fc7\u5916\u90e8\u8fc7\u7a0b\u76d1\u7763\u4fe1\u53f7\u8bc4\u4f30\u8def\u5f84\u8d28\u91cf\u3002\",\n  \"result\": \"\u5728MATH500\u548cAIME 2024\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u8be5\u65b9\u6cd5\u4f7f\u5c0f\u89c4\u6a21\u6a21\u578b\uff08\u5982Llama-3.2-1B\uff09\u8fbe\u523070\u500d\u53c2\u6570\u91cf\u6a21\u578b\u7684\u6027\u80fd\uff0c\u8ba1\u7b97\u6548\u7387\u63d0\u53473\u500d\uff08\u4ee4\u724c\u6d88\u8017\u51cf\u5c11\uff09\u548c30%\uff08PRM\u8c03\u7528\u51cf\u5c11\uff09\u3002\",\n  \"conclusion\": \"\u7ed3\u6784\u5316\u641c\u7d22\u89e3\u7801\u7b56\u7565\u4e3a\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u63d0\u4f9b\u4e86\u53c2\u6570\u6269\u5c55\u4e4b\u5916\u7684\u6027\u80fd\u63d0\u5347\u9014\u5f84\uff0c\u8bc1\u660e\u4e86\u4f18\u5316\u63a8\u7406\u65f6\u95f4\u7b56\u7565\u5bf9\u63d0\u5347\u5c0f\u89c4\u6a21\u6a21\u578b\u63a8\u7406\u80fd\u529b\u7684\u6709\u6548\u6027\uff0c\u4e3a\u9ad8\u6548\u53ef\u6269\u5c55\u7684\u6a21\u578b\u90e8\u7f72\u6307\u660e\u65b0\u65b9\u5411\u3002\"\n}\n```", "additional_kwargs": {"refusal": null}, "response_metadata": {"token_usage": {"completion_tokens": 254, "prompt_tokens": 642, "total_tokens": 896, "completion_tokens_details": null, "prompt_tokens_details": null}, "model_name": "deepseek/deepseek-chat-v3-0324:free", "system_fingerprint": null, "id": "gen-1747818067-UQF8O4V6bvYDhlaiXyqZ", "finish_reason": "stop", "logprobs": null}, "type": "ai", "name": null, "id": "run-0ba14be5-1606-44da-ace4-42c8573738b3-0", "example": false, "tool_calls": [], "invalid_tool_calls": [], "usage_metadata": {"input_tokens": 642, "output_tokens": 254, "total_tokens": 896, "input_token_details": {}, "output_token_details": {}}}}
{"id": "2505.13544", "pdf": "https://arxiv.org/pdf/2505.13544", "abs": "https://arxiv.org/abs/2505.13544", "authors": ["Keqi Deng", "Philip C. Woodland"], "title": "Multi-head Temporal Latent Attention", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "While Transformer self-attention offers strong parallelism, the Key-Value\n(KV) cache grows linearly with sequence length and becomes a bottleneck for\ninference efficiency. Multi-head latent attention was recently developed to\ncompress the KV cache into a low-rank latent space. This paper proposes\nMulti-head Temporal Latent Attention (MTLA), which further reduces the KV cache\nsize along the temporal dimension, greatly lowering the memory footprint of\nself-attention inference. MTLA employs a hyper-network to dynamically merge\ntemporally adjacent KV cache vectors. To address the mismatch between the\ncompressed KV cache and processed sequence lengths, a stride-aware causal mask\nis proposed to ensure efficient parallel training and consistency with\ninference behaviour. Experiments across tasks, including speech translation,\nspeech recognition, speech understanding and text summarisation, demonstrate\nthat MTLA achieves competitive performance compared to standard Multi-Head\nAttention (MHA), while greatly improving inference speed and GPU memory usage.\nFor example, on a English-German speech translation task, MTLA achieves a 5.3x\nspeedup and a reduction in GPU memory usage by a factor of 8.3 compared to MHA,\nwhile maintaining translation quality.", "AI": {"content": "```json\n{\n  \"tldr\": \"MTLA\u901a\u8fc7\u52a8\u6001\u538b\u7f29KV\u7f13\u5b58\u548c\u5f15\u5165\u6b65\u957f\u611f\u77e5\u56e0\u679c\u63a9\u7801\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u81ea\u6ce8\u610f\u529b\u63a8\u7406\u7684\u5185\u5b58\u5360\u7528\u548c\u8ba1\u7b97\u6210\u672c\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u6a21\u578b\u6027\u80fd\u3002\",\n  \"motivation\": \"Transformer\u7684\u952e\u503c\uff08KV\uff09\u7f13\u5b58\u968f\u5e8f\u5217\u957f\u5ea6\u7ebf\u6027\u589e\u957f\uff0c\u6210\u4e3a\u63a8\u7406\u6548\u7387\u7684\u74f6\u9888\u3002\u4f5c\u8005\u63d0\u51faMTLA\u4ee5\u8fdb\u4e00\u6b65\u51cf\u5c11KV\u7f13\u5b58\u7684\u65f6\u5e8f\u7ef4\u5ea6\u5360\u7528\u3002\",\n  \"method\": \"MTLA\u91c7\u7528\u8d85\u7f51\u7edc\u52a8\u6001\u5408\u5e76\u65f6\u5e8f\u76f8\u90bb\u7684KV\u7f13\u5b58\u5411\u91cf\uff0c\u5e76\u5f15\u5165\u6b65\u957f\u611f\u77e5\u56e0\u679c\u63a9\u7801\u89e3\u51b3\u538b\u7f29KV\u7f13\u5b58\u4e0e\u5e8f\u5217\u957f\u5ea6\u4e0d\u5339\u914d\u95ee\u9898\u3002\",\n  \"result\": \"\u5b9e\u9a8c\u8868\u660e\uff0cMTLA\u5728\u591a\u4efb\u52a1\uff08\u5982\u8bed\u97f3\u7ffb\u8bd1\u3001\u6587\u672c\u6458\u8981\uff09\u4e2d\u6027\u80fd\u4e0e\u6807\u51c6\u591a\u5934\u6ce8\u610f\u529b\u76f8\u5f53\uff0c\u540c\u65f6\u5728\u82f1\u8bed-\u5fb7\u8bed\u8bed\u97f3\u7ffb\u8bd1\u4efb\u52a1\u4e2d\u5b9e\u73b05.3\u500d\u52a0\u901f\u548c8.3\u500dGPU\u5185\u5b58\u8282\u7701\u3002\",\n  \"conclusion\": \"MTLA\u5728\u4fdd\u6301\u6a21\u578b\u6027\u80fd\u7684\u540c\u65f6\uff0c\u663e\u8457\u63d0\u5347\u63a8\u7406\u6548\u7387\u5e76\u964d\u4f4e\u5185\u5b58\u9700\u6c42\uff0c\u4e3a\u957f\u5e8f\u5217\u5904\u7406\u63d0\u4f9b\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\u3002\"\n}\n```", "additional_kwargs": {"refusal": null}, "response_metadata": {"token_usage": {"completion_tokens": 212, "prompt_tokens": 566, "total_tokens": 778, "completion_tokens_details": null, "prompt_tokens_details": null}, "model_name": "deepseek/deepseek-chat-v3-0324:free", "system_fingerprint": null, "id": "gen-1747818120-DC7emABnXziNJ5I6bGIq", "finish_reason": "stop", "logprobs": null}, "type": "ai", "name": null, "id": "run-793d49c5-6f2c-47a3-96f8-673c1b8c6d3e-0", "example": false, "tool_calls": [], "invalid_tool_calls": [], "usage_metadata": {"input_tokens": 566, "output_tokens": 212, "total_tokens": 778, "input_token_details": {}, "output_token_details": {}}}}
{"id": "2505.13706", "pdf": "https://arxiv.org/pdf/2505.13706", "abs": "https://arxiv.org/abs/2505.13706", "authors": ["Julia Jose", "Rachel Greenstadt"], "title": "Are Large Language Models Good at Detecting Propaganda?", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Propagandists use rhetorical devices that rely on logical fallacies and\nemotional appeals to advance their agendas. Recognizing these techniques is key\nto making informed decisions. Recent advances in Natural Language Processing\n(NLP) have enabled the development of systems capable of detecting manipulative\ncontent. In this study, we look at several Large Language Models and their\nperformance in detecting propaganda techniques in news articles. We compare the\nperformance of these LLMs with transformer-based models. We find that, while\nGPT-4 demonstrates superior F1 scores (F1=0.16) compared to GPT-3.5 and Claude\n3 Opus, it does not outperform a RoBERTa-CRF baseline (F1=0.67). Additionally,\nwe find that all three LLMs outperform a MultiGranularity Network (MGN)\nbaseline in detecting instances of one out of six propaganda techniques\n(name-calling), with GPT-3.5 and GPT-4 also outperforming the MGN baseline in\ndetecting instances of appeal to fear and flag-waving.", "AI": {"content": "```json\n{\n  \"tldr\": \"\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u68c0\u6d4b\u65b0\u95fb\u6587\u7ae0\u4e2d\u7684\u5ba3\u4f20\u6280\u672f\u65b9\u9762\u7684\u8868\u73b0\uff0c\u53d1\u73b0GPT-4\u867d\u7136\u4f18\u4e8eGPT-3.5\u548cClaude 3 Opus\uff0c\u4f46\u4e0d\u5982RoBERTa-CRF\u6a21\u578b\uff0c\u4e14\u6240\u6709\u6a21\u578b\u5728\u68c0\u6d4b\u7279\u5b9a\u5ba3\u4f20\u6280\u672f\u65f6\u8868\u73b0\u4e0d\u4e00\u3002\",\n  \"motivation\": \"\u7814\u7a76\u52a8\u673a\u5728\u4e8e\u5229\u7528\u81ea\u7136\u8bed\u8a00\u5904\u7406\u6280\u672f\u5f00\u53d1\u7cfb\u7edf\uff0c\u4ee5\u8bc6\u522b\u65b0\u95fb\u6587\u7ae0\u4e2d\u7684\u5ba3\u4f20\u6280\u672f\uff0c\u5e2e\u52a9\u4eba\u4eec\u505a\u51fa\u66f4\u660e\u667a\u7684\u51b3\u7b56\u3002\",\n  \"method\": \"\u8bba\u6587\u901a\u8fc7\u6bd4\u8f83\u51e0\u79cd\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08\u5982GPT-4\u3001GPT-3.5\u548cClaude 3 Opus\uff09\u4e0e\u57fa\u4e8eTransformer\u7684\u6a21\u578b\uff08\u5982RoBERTa-CRF\uff09\u5728\u68c0\u6d4b\u5ba3\u4f20\u6280\u672f\u65b9\u9762\u7684\u8868\u73b0\u3002\",\n  \"result\": \"\u7ed3\u679c\u663e\u793a\uff0cGPT-4\u7684F1\u5206\u6570\uff080.16\uff09\u4f18\u4e8eGPT-3.5\u548cClaude 3 Opus\uff0c\u4f46\u4e0d\u5982RoBERTa-CRF\uff08F1=0.67\uff09\u3002\u6b64\u5916\uff0c\u6240\u6709\u6a21\u578b\u5728\u68c0\u6d4b\u516d\u79cd\u5ba3\u4f20\u6280\u672f\u4e2d\u7684\u4e00\u79cd\uff08\u4eba\u8eab\u653b\u51fb\uff09\u65f6\u8868\u73b0\u4f18\u4e8e\u591a\u7c92\u5ea6\u7f51\u7edc\uff08MGN\uff09\uff0cGPT-4\u548cGPT-3.5\u5728\u68c0\u6d4b\u6050\u60e7\u8bc9\u6c42\u548c\u65d7\u5e1c\u6325\u821e\u65b9\u9762\u4e5f\u4f18\u4e8eMGN\u3002\",\n  \"conclusion\": \"\u8bba\u6587\u5f97\u51fa\u7ed3\u8bba\uff0c\u867d\u7136\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u68c0\u6d4b\u67d0\u4e9b\u5ba3\u4f20\u6280\u672f\u65b9\u9762\u8868\u73b0\u826f\u597d\uff0c\u4f46\u4ecd\u9700\u8fdb\u4e00\u6b65\u4f18\u5316\u4ee5\u63d0\u9ad8\u6574\u4f53\u68c0\u6d4b\u80fd\u529b\u3002\"\n}\n```", "additional_kwargs": {"refusal": null}, "response_metadata": {"token_usage": {"completion_tokens": 286, "prompt_tokens": 537, "total_tokens": 823, "completion_tokens_details": null, "prompt_tokens_details": null}, "model_name": "deepseek/deepseek-chat-v3-0324:free", "system_fingerprint": null, "id": "gen-1747818128-VEpobfs16NcpEpoeD7jm", "finish_reason": "stop", "logprobs": null}, "type": "ai", "name": null, "id": "run-d8c508f2-b2fe-49fe-8b7b-140d9e1e7376-0", "example": false, "tool_calls": [], "invalid_tool_calls": [], "usage_metadata": {"input_tokens": 537, "output_tokens": 286, "total_tokens": 823, "input_token_details": {}, "output_token_details": {}}}}
{"id": "2505.13696", "pdf": "https://arxiv.org/pdf/2505.13696", "abs": "https://arxiv.org/abs/2505.13696", "authors": ["Zizhan He", "Maxime Daigle", "Pouya Bashivan"], "title": "Building spatial world models from sparse transitional episodic memories", "categories": ["cs.AI"], "comment": null, "summary": "Many animals possess a remarkable capacity to rapidly construct flexible\nmental models of their environments. These world models are crucial for\nethologically relevant behaviors such as navigation, exploration, and planning.\nThe ability to form episodic memories and make inferences based on these sparse\nexperiences is believed to underpin the efficiency and adaptability of these\nmodels in the brain. Here, we ask: Can a neural network learn to construct a\nspatial model of its surroundings from sparse and disjoint episodic memories?\nWe formulate the problem in a simulated world and propose a novel framework,\nthe Episodic Spatial World Model (ESWM), as a potential answer. We show that\nESWM is highly sample-efficient, requiring minimal observations to construct a\nrobust representation of the environment. It is also inherently adaptive,\nallowing for rapid updates when the environment changes. In addition, we\ndemonstrate that ESWM readily enables near-optimal strategies for exploring\nnovel environments and navigating between arbitrary points, all without the\nneed for additional training.", "AI": {"content": "```json\n{\n  \"tldr\": \"\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aESWM\u7684\u65b0\u6846\u67b6\uff0c\u65e8\u5728\u901a\u8fc7\u7a00\u758f\u548c\u5206\u79bb\u7684\u7247\u6bb5\u8bb0\u5fc6\u6784\u5efa\u7a7a\u95f4\u4e16\u754c\u6a21\u578b\uff0c\u5c55\u793a\u4e86\u5176\u9ad8\u6548\u6027\u548c\u9002\u5e94\u6027\u3002\",\n  \"motivation\": \"\u7814\u7a76\u52a8\u673a\u5728\u4e8e\u63a2\u7d22\u795e\u7ecf\u7f51\u7edc\u662f\u5426\u80fd\u591f\u901a\u8fc7\u7a00\u758f\u548c\u5206\u79bb\u7684\u7247\u6bb5\u8bb0\u5fc6\u6784\u5efa\u7a7a\u95f4\u4e16\u754c\u6a21\u578b\uff0c\u4ee5\u652f\u6301\u9ad8\u6548\u548c\u81ea\u9002\u5e94\u7684\u884c\u4e3a\u3002\",\n  \"method\": \"\u8bba\u6587\u63d0\u51fa\u4e86Episodic Spatial World Model (ESWM)\u6846\u67b6\uff0c\u901a\u8fc7\u6a21\u62df\u4e16\u754c\u4e2d\u7684\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u3002\",\n  \"result\": \"\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cESWM\u5177\u6709\u9ad8\u6548\u6027\uff0c\u80fd\u591f\u901a\u8fc7\u5c11\u91cf\u89c2\u5bdf\u6784\u5efa\u7a33\u5065\u7684\u73af\u5883\u8868\u793a\uff0c\u5e76\u652f\u6301\u5feb\u901f\u66f4\u65b0\u548c\u63a2\u7d22\u65b0\u73af\u5883\u3002\",\n  \"conclusion\": \"\u8bba\u6587\u5f97\u51fa\u7ed3\u8bba\uff0cESWM\u80fd\u591f\u6709\u6548\u6784\u5efa\u7a7a\u95f4\u4e16\u754c\u6a21\u578b\uff0c\u652f\u6301\u9ad8\u6548\u548c\u81ea\u9002\u5e94\u7684\u884c\u4e3a\uff0c\u65e0\u9700\u989d\u5916\u8bad\u7ec3\u3002\"\n}\n```", "additional_kwargs": {"refusal": null}, "response_metadata": {"token_usage": {"completion_tokens": 170, "prompt_tokens": 526, "total_tokens": 696, "completion_tokens_details": null, "prompt_tokens_details": null}, "model_name": "deepseek/deepseek-chat-v3-0324:free", "system_fingerprint": null, "id": "gen-1747818151-54rbtGNqoYmdQTfXHSKQ", "finish_reason": "stop", "logprobs": null}, "type": "ai", "name": null, "id": "run-edc02c1c-efd9-4398-b487-e517d6bc1153-0", "example": false, "tool_calls": [], "invalid_tool_calls": [], "usage_metadata": {"input_tokens": 526, "output_tokens": 170, "total_tokens": 696, "input_token_details": {}, "output_token_details": {}}}}
{"id": "2505.13547", "pdf": "https://arxiv.org/pdf/2505.13547", "abs": "https://arxiv.org/abs/2505.13547", "authors": ["Pengxin Guo", "Yinong Wang", "Wei Li", "Mengting Liu", "Ming Li", "Jinkai Zheng", "Liangqiong Qu"], "title": "Exploring Federated Pruning for Large Language Models", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "LLM pruning has emerged as a promising technology for compressing LLMs,\nenabling their deployment on resource-limited devices. However, current\nmethodologies typically require access to public calibration samples, which can\nbe challenging to obtain in privacy-sensitive domains. To address this issue,\nwe introduce FedPrLLM, a comprehensive federated pruning framework designed for\nthe privacy-preserving compression of LLMs. In FedPrLLM, each client only needs\nto calculate a pruning mask matrix based on its local calibration data and\nshare it with the server to prune the global model. This approach allows for\ncollaborative pruning of the global model with the knowledge of each client\nwhile maintaining local data privacy. Additionally, we conduct extensive\nexperiments to explore various possibilities within the FedPrLLM framework,\nincluding different comparison groups, pruning strategies, and the decision to\nscale weights. Our extensive evaluation reveals that one-shot pruning with\nlayer comparison and no weight scaling is the optimal choice within the\nFedPrLLM framework. We hope our work will help guide future efforts in pruning\nLLMs in privacy-sensitive fields. Our code is available at\nhttps://github.com/Pengxin-Guo/FedPrLLM.", "AI": {"content": "```json\n{\n  \"tldr\": \"FedPrLLM\u662f\u4e00\u4e2a\u8054\u90a6\u526a\u679d\u6846\u67b6\uff0c\u7528\u4e8e\u9690\u79c1\u4fdd\u62a4\u7684\u5927\u8bed\u8a00\u6a21\u578b\u538b\u7f29\uff0c\u901a\u8fc7\u5ba2\u6237\u7aef\u672c\u5730\u8ba1\u7b97\u526a\u679d\u63a9\u7801\u77e9\u9635\u5e76\u5171\u4eab\u7ed9\u670d\u52a1\u5668\u6765\u5b9e\u73b0\u5168\u5c40\u6a21\u578b\u526a\u679d\uff0c\u65e0\u9700\u516c\u5f00\u6821\u51c6\u6570\u636e\u3002\",\n  \"motivation\": \"\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b(LLM)\u526a\u679d\u65b9\u6cd5\u4f9d\u8d56\u516c\u5f00\u6821\u51c6\u6837\u672c\uff0c\u4f46\u5728\u9690\u79c1\u654f\u611f\u9886\u57df\u96be\u4ee5\u83b7\u53d6\u3002\u9700\u5f00\u53d1\u4fdd\u62a4\u9690\u79c1\u7684\u534f\u4f5c\u5f0f\u526a\u679d\u65b9\u6848\u3002\",\n  \"method\": \"\u63d0\u51faFedPrLLM\u6846\u67b6\uff1a\u5404\u5ba2\u6237\u7aef\u57fa\u4e8e\u672c\u5730\u6570\u636e\u8ba1\u7b97\u526a\u679d\u63a9\u7801\u77e9\u9635\uff0c\u4e0a\u4f20\u81f3\u670d\u52a1\u5668\u8fdb\u884c\u5168\u5c40\u6a21\u578b\u526a\u679d\uff0c\u652f\u6301\u5c42\u5bf9\u6bd4\u548c\u6743\u91cd\u7f29\u653e\u7b49\u7b56\u7565\u3002\",\n  \"result\": \"\u5b9e\u9a8c\u8868\u660e\uff0c\u91c7\u7528\u5355\u6b21\u526a\u679d+\u5c42\u5bf9\u6bd4+\u4e0d\u7f29\u653e\u6743\u91cd\u7684\u7ec4\u5408\u662fFedPrLLM\u6846\u67b6\u4e0b\u7684\u6700\u4f18\u65b9\u6848\u3002\",\n  \"conclusion\": \"FedPrLLM\u4e3a\u9690\u79c1\u654f\u611f\u9886\u57df\u7684LLM\u526a\u679d\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u672a\u6765\u53ef\u6307\u5bfc\u76f8\u5173\u9886\u57df\u7814\u7a76\u3002\"\n}\n```", "additional_kwargs": {"refusal": null}, "response_metadata": {"token_usage": {"completion_tokens": 205, "prompt_tokens": 569, "total_tokens": 774, "completion_tokens_details": null, "prompt_tokens_details": null}, "model_name": "deepseek/deepseek-chat-v3-0324:free", "system_fingerprint": null, "id": "gen-1747818172-zTpbAnq6tcOGRMLkOaxb", "finish_reason": "stop", "logprobs": null}, "type": "ai", "name": null, "id": "run-2d065a16-b255-444b-8500-2e9144f04f93-0", "example": false, "tool_calls": [], "invalid_tool_calls": [], "usage_metadata": {"input_tokens": 569, "output_tokens": 205, "total_tokens": 774, "input_token_details": {}, "output_token_details": {}}}}
